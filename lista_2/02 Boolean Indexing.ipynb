{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Subsets of Data in Pandas\n",
    "\n",
    "This notebook is also available as a [blog post on Medium](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-39e811c81a0c).\n",
    "\n",
    "## Part 2: Boolean Indexing\n",
    "This is part 2 of a seven-part series on how to select subsets of data from a pandas DataFrame or Series. Pandas offers a wide variety of options for subset selection which necessitates multiple articles. This series is broken down into the following 7 topics.\n",
    "\n",
    "1. Selection with `[]`, `.loc` and `.iloc`\n",
    "1. Boolean indexing\n",
    "1. Assigning subsets of data\n",
    "1. Selection with a MultiIndex\n",
    "1. Selecting subsets of data with methods\n",
    "1. Selections with other Index types\n",
    "1. Internals, Miscellaneous, and Conclusion\n",
    "\n",
    "## Part 1 vs Part 2 subset selection\n",
    "\n",
    "Part 1 of this series covered subset selection with `[]`, `.loc` and `.iloc`. All three of these **indexers** use either the row/column labels or their integer location to make selections. The actual **data** of the Series/DataFrame is not used at all during the selection. \n",
    "\n",
    "In Part 2 of this series, on **boolean indexing**, we will select subsets of data based on the actual values of the data in the Series/DataFrame and NOT on their row/column labels or integer locations. \n",
    "\n",
    "\n",
    "## Documentation on boolean selection\n",
    "I will always recommend reading the official documentation in addition to this tutorial when learning about boolean selection. The documentation uses more formal examples with dummy data, but is still an excellent resource.\n",
    "\n",
    "The documentation use the term **boolean indexing** but you will also see **boolean selection**.\n",
    "\n",
    "[Boolean Indexing from pandas documentation](http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing)\n",
    "\n",
    "## Stack Overflow Data\n",
    "\n",
    "The data that we will use for this tutorial comes from [Stack Overflow's data explorer](https://data.stackexchange.com/stackoverflow/query/new), which is a fantastic tool to gather an incredible amount of data from the site. You must know SQL in order to use the data explorer. The data explorer allows you to save queries. [Take a look at the query](http://data.stackexchange.com/stackoverflow/query/768430/get-all-questions-and-answerers-from-tag) I used to collect the data. \n",
    "\n",
    "The table below contains data on each question asked on stack overflow [tagged as pandas](https://stackoverflow.com/questions/tagged/pandas). \n",
    "\n",
    "The first question was asked March 30, 2011. Since then, more than 56,000 questions have been added as of December 2, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../../data/stackoverflow_qa.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8d77c2d619e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/stackoverflow_qa.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../../data/stackoverflow_qa.csv' does not exist"
     ]
    }
   ],
   "source": [
    "so = pd.read_csv('../../data/stackoverflow_qa.csv')\n",
    "so.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking simple questions in plain English\n",
    "\n",
    "Before we get to the technical definition of boolean indexing, let's see some examples of the types of questions it can answer.\n",
    "\n",
    "* Find all questions that were created before 2014\n",
    "* Find all questions with a score more than 50\n",
    "* Find all questions with a score between 50 and 100\n",
    "* Find all questions answered by Scott Boston\n",
    "* Find all questions answered by the following 5 users\n",
    "* Find all questions that were created between March, 2014 and October 2014 that were answered by Unutbu and have score less than 5.\n",
    "* Find all questions that have score between 5 and 10 or have a view count of greater than 10,000\n",
    "* Find all questions that are not answered by Scott Boston\n",
    "\n",
    "You will also see examples like this referred to by the term **queries**.\n",
    "\n",
    "## All queries have criteria\n",
    "Each of the above queries have a strict logical criteria that must be checked one row at a time.\n",
    "\n",
    "## Keep or Discard entire row of data\n",
    "If you were to manually answer the above queries, you would need to scan each row and determine whether the row as a whole meets the criterion or not. If the row meets the criteria, then it is kept and if not, then it is discarded.\n",
    "\n",
    "## Each row will have a `True` or `False` value associated with it\n",
    "When you perform boolean indexing, each row of the DataFrame (or value of a Series) will have a `True` or `False` value associated with it depending on whether or not it meets the criterion. True/False values are known as **boolean**. The documentation refers to the entire procedure as **boolean indexing**. \n",
    "\n",
    "Since we are using the booleans to select data, it is sometimes referred to as **boolean selection**. Essentially, we are using booleans to select subsets of data.\n",
    "\n",
    "## Using `[]` and `.loc` for boolean selection\n",
    "We will use the same three indexers, **`[]`** and **`.loc`** from part 1 to complete our boolean selections. We will do so by placing a sequence of booleans inside of these indexer. The sequence will be the same number of rows/values as the DataFrame/Series it is doing the selection on.\n",
    "\n",
    "The **`.iloc`** indexer can be made to work with boolean selection but is almost never used. A small section towards the end will show why it's unnecessary.\n",
    "\n",
    "## Focus on `[]` for now\n",
    "To simplify things, we will only the brackets, **`[]`**, which I called **just the indexing operator** from part 1. We will get to the other indexers a bit later.\n",
    "\n",
    "## Use a small DataFrame to get started\n",
    "Before we make our first boolean selection, let's simplify matters and use the first five rows of the stack overflow data as our starting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_head = so.head()\n",
    "so_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually create a list of booleans\n",
    "For our first boolean selection, we will not answer any interesting 'English' queries and instead just select rows with a list of booleans.\n",
    "\n",
    "For instance, let's select the first and third rows by creating the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [True, False, True, False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass this list of booleans to just the indexing operator and complete our selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_head[criteria]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait a second... Isn't `[]` just for column selection?\n",
    "The primary purpose of *just the indexing operator* for a DataFrame is to select one or more columns by using either a string or a list of strings. Now, all of a sudden, this example is showing that entire rows are selected with boolean values. This is what makes pandas, unfortunately, one of the most confusing libraries to use. \n",
    "\n",
    "## Operator Overloading\n",
    "*Just the indexing* operator is overloaded. This means, that depending on the inputs, pandas will do something completely different. Here are the rules for the different objects you pass to *just the indexing operator*.\n",
    "* string - return a column as a Series\n",
    "* list of strings - return all those columns as a DataFrame\n",
    "* a slice - select rows (can do both label and integer location - confusing!)\n",
    "* a sequence of booleans - select all rows where **`True`**\n",
    "\n",
    "In summary, primarily *just the indexing operator* selects **columns**, but if you pass it a sequence of booleans it will select all **rows** that are **`True`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do you mean by 'sequence'?\n",
    "I keep using the term **sequence of booleans** to refer to the `True/False` values. Technically, the most common built-in [Python sequence](https://docs.python.org/3/library/stdtypes.html#typesseq) types are lists and tuples. In addition to a list, you will most often be using a pandas Series as your 'sequence' of booleans.\n",
    "\n",
    "Let's manually create a boolean Series to select the last three rows of **`so_head`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([False, False, True, True, True])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_head[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take care when creating a boolean Series by hand\n",
    "The above example only worked because the index of both the boolean Series and **`so_head`** were the exact same. Let's output them so you can clearly see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_head.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean selection fails when the index doesn't align\n",
    "When you are using a boolean Series to do boolean selection, the index of both objects must be the exact same. Let's create a slightly different Series with a different index than the DataFrame it is indexing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([False, False, True, True, True], index=[2, 3, 4, 5, 6])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_head[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `IndexingError`: Unalignable boolean Series!\n",
    "If the index of both the boolean Series and the object you are doing boolean selection on don't match exactly, you will get the above error. This is one reason, as you will below, why you will almost never create boolean Series by hand like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also use NumPy arrays\n",
    "You can also use NumPy arrays to do boolean selection. NumPy arrays have no index so you won't get the error above, but your array needs to be the same exact length as the object you are doing boolean selection on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([True, False, False, True, False])\n",
    "so_head[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Never creating boolean Series by hand\n",
    "You will likely never create a boolean Series by hand as was done above. Instead, you will produce them based on the values of your data.\n",
    "\n",
    "## Use the comparison operators to create boolean Series\n",
    "The primary method of creating a Series of booleans is to use one of the six comparison operators: \n",
    "* **`<`**\n",
    "* **`<=`**\n",
    "* **`>`**\n",
    "* **`>=`**\n",
    "* **`==`**\n",
    "* **`!=`** \n",
    "\n",
    "## Use comparison operator with a single column of data\n",
    "You will almost always use the comparison operators on just a single column or Series of data. For instance, let's create a boolean Series from the **`score`** column. Let's determine if the score is at least 10.\n",
    "\n",
    "We select the score column and then test the condition that each value is greater than or equal to 10. Notice that this operations gets applied to each value in the Series. A boolean Series is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'so' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91d5e4dca0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'so' is not defined"
     ]
    }
   ],
   "source": [
    "criteria = so['score'] >= 10\n",
    "criteria.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally making a boolean selection\n",
    "Now that we have our boolean Series stored in the variable **`criteria`**, we can pass this to *just the indexing operator* to select only the rows that have a score of at least 10. \n",
    "\n",
    "We are going to use the entire **`so`** DataFrame for the rest of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_score_10_or_more = so[criteria]\n",
    "so_score_10_or_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many rows have a score of at least ten\n",
    "Just by looking at the head of the resulting DataFrame, we don't know how many rows passed our criterion. Let's output the shape of both our original and our resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_score_10_or_more.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 3% of questions get a score of 10 or more.\n",
    "\n",
    "## Boolean selection in one line\n",
    "Often, you will see boolean selection happen in a single line of code instead of the multiple lines we used above. If the following is confusing for you, then I recommend storing your boolean Series to a variable like I did with **`criteria`** above.\n",
    "\n",
    "It is possible to put the creation of the boolean Series inside of *just the indexing operator* like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[so['score'] >= 10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single condition expression\n",
    "Our first example tested a single condition (whether the score was 10 or more). Let's test a different single condition and look for all the questions that are answered by **Scott Boston**. The **`ans_name`** variable holds the display names of the people who posted the accepted answer to the question.\n",
    "\n",
    "We use the **`==`** operator to test for equality and again store this result to the variable **`criteria`**. Again, we pass this variable to *just the indexing operator* which completes our selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 - create boolean Series\n",
    "criteria = so['ans_name'] == 'Scott Boston'\n",
    "\n",
    "# step 2 - do boolean selection\n",
    "so[criteria].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple condition expression\n",
    "So far, both our boolean selections have involved a single condition. You can, of course, have as many conditions as you would like. To do so, you will need to combine your boolean expressions using the three logical operators **and**, **or** and **not**.\n",
    "\n",
    "## Use `&`, `|`, `~`\n",
    "Although Python uses the syntax **`and`**, **`or`**, and **`not`**, these will not work when testing multiple conditions with pandas. The details of why this is so will be left for part 7 of the Series.\n",
    "\n",
    "You must use the following operators with pandas:\n",
    "* **`&`** for **and**\n",
    "* **`|`** for **or**\n",
    "* **`~`** for **not**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first multiple condition expression\n",
    "Let's find all the questions that have a score of at least 5 and are answered by Scott Boston. To begin, we will create two separate variable to hold each criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_1 = so['score'] >= 5\n",
    "criteria_2 = so['ans_name'] == 'Scott Boston'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use the **and** operator, the ampersand **`&`**, to combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_all = criteria_1 & criteria_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this final criteria to *just the indexing operator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[criteria_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple conditions in one line\n",
    "It is possible to combine the entire expression into a single line. Many pandas users like doing this, others hate it. Regardless, it is a good idea to know how to do so as you will definitely encounter it.\n",
    "\n",
    "## Use parentheses to separate conditions\n",
    "You must encapsulate each condition in a set of parentheses in order to make this work. This again, will be explained in part 7.\n",
    "\n",
    "Each condition will be separated like this:\n",
    "```Python\n",
    "(so['score'] >= 5) & (so['ans_name'] == 'Scott Boston')\n",
    "```\n",
    "\n",
    "We can then drop this expression inside of *just the indexing operator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[(so['score'] >= 5) & (so['ans_name'] == 'Scott Boston')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an `or` condition\n",
    "Let's find all the questions that have a score of at least 100 or have at least 10 answers.\n",
    "\n",
    "For the **or** condition, we use the pipe **`|`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'so' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a0bc9022554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mso\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mso\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mso\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answercount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'so' is not defined"
     ]
    }
   ],
   "source": [
    "so[(so['score'] >= 100) | (so['answercount'] >= 10)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversing a condition with the `not` operator\n",
    "The tilde character **`~`** represents the **not** operator and reverses a condition. For instance, if we wanted all the questions with score greater than 100, we could do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[~(so['score'] <= 100)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there were parentheses around the condition '**`score`** less than equal to 100'. We had to use parentheses here or the operation wouldn't work correctly. \n",
    "\n",
    "Of course, this trivial example has no need for the not operator and can be replaced with the greater than operator, but it's easy to verify.\n",
    "\n",
    "Let's look back up one example and invert the condition of **`score`** at least 100 or number of answers at least 10.  To do this, we will have to wrap our entire expression with parentheses like this:\n",
    "\n",
    "```Python\n",
    "~((so['score'] >= 100) | (so['answercount'] >= 10))\n",
    "```\n",
    "\n",
    "There is a set of parentheses around each inner expression as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex conditions\n",
    "It is possible to build extremely complex conditions to select rows of your DataFrame that meet a very specific criteria. For instance, we can select all questions answered by Scott Boston with **`score`** 5 or more OR questions answered by Ted Petrou with answer count 5 or more.\n",
    "\n",
    "With multiple conditions, its probably best to break out the logic into multiple steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_1 = (so['score'] >= 5) & (so['ans_name'] == 'Scott Boston')\n",
    "criteria_2 = (so['answercount'] >= 5) & (so['ans_name'] == 'Ted Petrou')\n",
    "criteria_all = criteria_1 | criteria_2\n",
    "so[criteria_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of `or` conditions in a single column - use `isin`\n",
    "Occasionally, we will want to test equality in a single column to multiple values. This is most common in string columns. For instance, let's say we wanted to find all the questions answered by Scott Boston, Ted Petrou, MaxU, and unutbu.\n",
    "\n",
    "One way to do this would be with four `or` conditions.\n",
    "\n",
    "```Python\n",
    "criteria = ((so['ans_name'] == 'Scott Boston') | (so['ans_name'] == 'Ted Petrou') | \n",
    "            (so['ans_name'] == 'MaxU') | (so['ans_name'] == 'unutbu'))\n",
    "```\n",
    "\n",
    "An easier way is to use the Series method **`isin`**. Pass it a list of all the items you want to check for equality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = so['ans_name'].isin(['Scott Boston', 'Ted Petrou', 'MaxU', 'unutbu'])\n",
    "criteria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[criteria].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining `isin` with other criteria\n",
    "You can use the resulting boolean Series from the **`isin`** method in the same way you would from the logical operators. For instance, If we wanted to find all the questions answered by the people above and had score greater than 30 we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_1 = so['ans_name'].isin(['Scott Boston', 'Ted Petrou', 'MaxU', 'unutbu'])\n",
    "criteria_2 = so['score'] > 30\n",
    "criteria_all = criteria_1 & criteria_2\n",
    "so[criteria_all].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `isnull` to find rows with missing values\n",
    "The **`isnull`** method returns a boolean Series where True indicates where a missing value is. For instance, questions that do not have an **accepted answer** have missing values for **`ans_name`**. Let's call **`isnull`** on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_answer = so['ans_name'].isnull()\n",
    "no_answer.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just another boolean Series which we can pass to *just the indexing operator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[no_answer].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alias of **`isnull`** is the **`isna`** method. Alias means it is the same exact method with a different name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Selection on a Series\n",
    "All the examples thus far have taken place on the **`so`** DataFrame. Boolean selection on a Series happens almost identically. Since there is only one dimension of data, the queries you ask are usually going to be simpler.\n",
    "\n",
    "First, let's select a single column of data as a Series such as the **`commentcount`** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = so['commentcount']\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test for number of comments greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = s > 10\n",
    "criteria.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is no column selection here as we are already down to a single column. Let's pass this criteria to *just the indexing operator* to select just the values greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[criteria].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have done this in one step like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s > 10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to find those comments greater than 10 but less than 15 we could have used an **and** condition like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[(s > 10) & (s < 15)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another possibility is the `between` method\n",
    "Pandas has lots of duplicate functionality built in to it. Instead of writing two boolean conditions to select all values inside of a range as was done above, you can use the **`between`** method to create a boolean Series. To use, pass it the left and right end points of the range. These endpoints are inclusive.\n",
    "\n",
    "So, to replicate the previous example, you could have done this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s.between(11, 14)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous boolean selection with rows and column labels with `.loc`\n",
    "The **`.loc`** indexer was thoroughly covered in part 1 and will now be covered here to simultaneously select rows and columns. In part 1, it was stated that **`.loc`** made selections only by **label**. This wasn't strictly true as it is also able to do boolean selection along with selection by label.\n",
    "\n",
    "Remember that **`.loc`** takes both a row selection and a column selection separated by a comma. Since the row selection comes first, you can pass it the same exact inputs that you do for *just the indexing operator* and get the same results.\n",
    "\n",
    "Let's take a look at a couple examples from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "so.loc[(so['score'] >= 5) & (so['ans_name'] == 'Scott Boston')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "criteria = so['ans_name'].isin(['Scott Boston', 'Ted Petrou', 'MaxU', 'unutbu'])\n",
    "so.loc[criteria].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate row and column selection with a comma for `.loc`\n",
    "The great benefit of **`.loc`** is that it allows you to simultaneously do boolean selection along the rows and make column selections by label.\n",
    "\n",
    "For instance, let's say we wanted to find all the questions with more than 20k views but only return the **`creationdate`**, **`viewcount`**, and **`ans_name`** columns. You would do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.loc[so['viewcount'] > 20000, ['creationdate', 'viewcount', 'ans_name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could have broken each selection into pieces like this:\n",
    "\n",
    "```Python\n",
    "\n",
    "row_selection = so['viewcount'] > 20000\n",
    "col_selection = ['creationdate', 'viewcount', 'ans_name']\n",
    "so.loc[row_selection, col_selection]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lots of combinations possible with `.loc`\n",
    "Remember that **`.loc`** can take a string, a list of strings or a slice. You can use all three possible ways to select your data. You can also make very complex boolean selections for your rows.\n",
    "\n",
    "Let's select rows with **`favoritecount`** between 30 and 40 and every third column beginning from **`title`** to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird but possible\n",
    "so.loc[so['favoritecount'].between(30, 40), 'title'::3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean selection for the columns?\n",
    "It is actually possible to use a sequence of booleans to select columns. You pass a list, Series, or array of booleans the same length as the number of columns to **`.loc`**.\n",
    "\n",
    "Let's do a simple manual example where we create a list of booleans by hand. First, let's find out how many columns are in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of 12 booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_bools = [True, False, False] * 4\n",
    "col_bools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **`.loc`** to select all rows with just the `True` columns from **`col_bools`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.loc[:, col_bools].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can simultaneously select rows and columns too. Let's select the same columns but for rows that have over 500,000 views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.loc[so['viewcount'] > 500000, col_bools]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more practical example\n",
    "Let's see a slightly more practical example of doing boolean selection on the columns. Let's say we flipped 10 coins one-hundred times and store each trial in a column in the DataFrame below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = pd.DataFrame(np.random.randint(0, 2, (100, 10)), \n",
    "                     columns=list('abcdefghij'))\n",
    "coins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in selecting only the columns that have more than 50% heads, we could first take the mean of each column like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_mean = coins.mean()\n",
    "coin_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the condition that the percentage is greater than .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_mean > .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use this boolean Series to select only the columns that meet our criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins.loc[:, coins.mean() > .5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column to column comparisons\n",
    "All of the previous Series comparisons happened against a single scalar value. It is possible to create a boolean Series by comparing one column to another. For instance, we can find all the questions where there are more answers than **`score`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = so['answercount'] > so['score']\n",
    "so[criteria].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one line, the above would have looked like this:\n",
    "\n",
    "```Python\n",
    "so[so['answercount'] > so['score']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almost never use `.iloc` with boolean selection\n",
    "First, remember that **`.iloc`** uses INTEGER location to make its selections. \n",
    "\n",
    "You will rarely use **`.loc`** to do boolean selection and almost always use *just the indexing operator* or **`.loc`**. To see why, let's try and run a simple boolean selection to find all the rows that have more than 100,000 views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.iloc[so['viewcount'] > 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NotImplementedError`\n",
    "The pandas developers have not decided to boolean selection (with a Series) for **`.iloc`** so it does not work. You can however convert the Series to a list or a NumPy array as a workaround.\n",
    "\n",
    "Let's save our Series to a variable and double-check its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = so['viewcount'] > 100000\n",
    "type(criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the underlying NumPy array with the **`values`** attribute and pass it to **`.iloc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = criteria.values\n",
    "so.iloc[a].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make simultaneous column selection as well with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.iloc[a, [5, 10, 11]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think I have ever used **`.iloc`** for boolean selection as its not implemented for Series. I added because it's one of the three main indexers in pandas and it's important to know that it's not used much at all for boolean selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.loc` and `[]` work the same on a Series for boolean selection\n",
    "Boolean selection will work identically for **`.loc`** as it does with *just the indexing operator* on a Series. Both the indexers do row selection when passed a boolean Series. Since Series don't have columns, the two indexers are identical in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = so['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s > 100].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s > 100].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* **Boolean Indexing** or **Boolean Selection** is the selection of a subset of a Series/DataFrame based on the values themselves and not the row/column labels or integer location\n",
    "* Boolean selection is used to answer common queries like \"find all the female engineers with a salary over 150k/year\"\n",
    "* To do boolean selection, you first create a sequence of True/False values and pass it to a DataFrame/Series indexer\n",
    "* Each row of data is kept or discarded\n",
    "* The indexing operators are **overloaded** - change functionality depending on what is passed to them\n",
    "* Typically, you will first create a boolean Series with one of the 6 comparison operators\n",
    "* You will pass this boolean series to one of the indexers to make your selection\n",
    "* Use the **`isin`** method to test for multiple equalities in the same column\n",
    "* Use **`isnull`** to find all rows with missing values in a particular column\n",
    "* Can use the **`between`** Series method to test whether Series values are within a range\n",
    "* You can create complex criteria with the **and** (**`&`**), **or** (**`|`**), and **not** (**`~`**) logical operators\n",
    "* When you have multiple conditions in a single line, you must wrap each expression with a parentheses\n",
    "* If you have complex criteria, think about storing each set of criteria into its own variable (i.e. don't do everything in one line)\n",
    "* If you are only selecting rows, then you will almost always use *just the indexing operator*\n",
    "* If you are simultaneously doing boolean selection on the rows and selecting column labels then you will use **`.loc`**\n",
    "* You will almost never use **`.iloc`** to do boolean selection\n",
    "* Boolean selection works the same for Series as it does for DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More to the story\n",
    "Believe or not, there is still more to the story when it comes to boolean selection. We will cover more advanced topics in part 7.\n",
    "\n",
    "# Exercises\n",
    "Boolean selection is difficult at first and the syntax is somewhat clunky. It will take some time to master. These questions will start easy and progressively become more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for exercises\n",
    "We will use two datasets for these exercises. The stack overflow dataset which you have seen above and the employee dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5486226</td>\n",
       "      <td>2011-03-30 12:26:50</td>\n",
       "      <td>4</td>\n",
       "      <td>2113</td>\n",
       "      <td>Rolling median in python</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yueerhu</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Mike Pennington</td>\n",
       "      <td>26995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5515021</td>\n",
       "      <td>2011-04-01 14:50:44</td>\n",
       "      <td>8</td>\n",
       "      <td>7015</td>\n",
       "      <td>Compute a compounded return series in Python</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Jason Strimpel</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>Mike Pennington</td>\n",
       "      <td>26995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5558607</td>\n",
       "      <td>2011-04-05 21:13:50</td>\n",
       "      <td>2</td>\n",
       "      <td>7392</td>\n",
       "      <td>Sort a pandas DataMatrix in ascending order</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jason Strimpel</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6467832</td>\n",
       "      <td>2011-06-24 12:31:45</td>\n",
       "      <td>9</td>\n",
       "      <td>13056</td>\n",
       "      <td>How to get the correlation between two timeser...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>user814005</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7577546</td>\n",
       "      <td>2011-09-28 01:58:38</td>\n",
       "      <td>9</td>\n",
       "      <td>2488</td>\n",
       "      <td>Using pandas, how do I subsample a large DataF...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Uri Laserson</td>\n",
       "      <td>958.0</td>\n",
       "      <td>HYRY</td>\n",
       "      <td>54137.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         creationdate  score  viewcount  \\\n",
       "0  5486226  2011-03-30 12:26:50      4       2113   \n",
       "1  5515021  2011-04-01 14:50:44      8       7015   \n",
       "2  5558607  2011-04-05 21:13:50      2       7392   \n",
       "3  6467832  2011-06-24 12:31:45      9      13056   \n",
       "4  7577546  2011-09-28 01:58:38      9       2488   \n",
       "\n",
       "                                               title  answercount  \\\n",
       "0                           Rolling median in python            3   \n",
       "1       Compute a compounded return series in Python            3   \n",
       "2        Sort a pandas DataMatrix in ascending order            2   \n",
       "3  How to get the correlation between two timeser...            1   \n",
       "4  Using pandas, how do I subsample a large DataF...            1   \n",
       "\n",
       "   commentcount  favoritecount      quest_name  quest_rep         ans_name  \\\n",
       "0             4            1.0         yueerhu      125.0  Mike Pennington   \n",
       "1             6            7.0  Jason Strimpel     3301.0  Mike Pennington   \n",
       "2             0            1.0  Jason Strimpel     3301.0     Wes McKinney   \n",
       "3             0            7.0      user814005      117.0     Wes McKinney   \n",
       "4             0            5.0    Uri Laserson      958.0             HYRY   \n",
       "\n",
       "   ans_rep  \n",
       "0  26995.0  \n",
       "1  26995.0  \n",
       "2  43310.0  \n",
       "3  43310.0  \n",
       "4  54137.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so = pd.read_csv('stackoverflow_qa.csv')\n",
    "so.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIBRARY ASSISTANT</td>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>2010-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "      <td>1991-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRICIAN</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-06-19</td>\n",
       "      <td>1994-10-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                POSITION_TITLE                     DEPARTMENT  BASE_SALARY  \\\n",
       "0  ASSISTANT DIRECTOR (EX LVL)    Municipal Courts Department     121862.0   \n",
       "1            LIBRARY ASSISTANT                        Library      26125.0   \n",
       "2               POLICE OFFICER  Houston Police Department-HPD      45279.0   \n",
       "3            ENGINEER/OPERATOR  Houston Fire Department (HFD)      63166.0   \n",
       "4                  ELECTRICIAN    General Services Department      56347.0   \n",
       "\n",
       "              RACE EMPLOYMENT_TYPE  GENDER   HIRE_DATE    JOB_DATE  \n",
       "0  Hispanic/Latino       Full Time  Female  2006-06-12  2012-10-13  \n",
       "1  Hispanic/Latino       Full Time  Female  2000-07-19  2010-09-18  \n",
       "2            White       Full Time    Male  2015-02-03  2015-02-03  \n",
       "3            White       Full Time    Male  1982-02-08  1991-05-25  \n",
       "4            White       Full Time    Male  1989-06-19  1994-10-22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee = pd.read_csv('employee.csv')\n",
    "employee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions that have exactly 5 answers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10373660</td>\n",
       "      <td>2012-04-29 16:10:35</td>\n",
       "      <td>199</td>\n",
       "      <td>207980</td>\n",
       "      <td>Converting a Pandas GroupBy object to DataFrame</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>saveenr</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10791661</td>\n",
       "      <td>2012-05-29 00:06:52</td>\n",
       "      <td>7</td>\n",
       "      <td>12210</td>\n",
       "      <td>How do I discretize values in a pandas DataFra...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Uri Laserson</td>\n",
       "      <td>958.0</td>\n",
       "      <td>lbolla</td>\n",
       "      <td>4552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>10972410</td>\n",
       "      <td>2012-06-10 21:12:43</td>\n",
       "      <td>19</td>\n",
       "      <td>46428</td>\n",
       "      <td>pandas: combine two columns in a DataFrame</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BFTM</td>\n",
       "      <td>895.0</td>\n",
       "      <td>BrenBarn</td>\n",
       "      <td>136870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>11391969</td>\n",
       "      <td>2012-07-09 09:04:33</td>\n",
       "      <td>44</td>\n",
       "      <td>27467</td>\n",
       "      <td>How to group pandas DataFrame entries by date ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Boris Gorelik</td>\n",
       "      <td>9605.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>11811392</td>\n",
       "      <td>2012-08-04 19:25:34</td>\n",
       "      <td>17</td>\n",
       "      <td>20051</td>\n",
       "      <td>How to generate a list from a pandas DataFrame...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>turtle</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>BrenBarn</td>\n",
       "      <td>136870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>11824341</td>\n",
       "      <td>2012-08-06 07:47:34</td>\n",
       "      <td>0</td>\n",
       "      <td>1558</td>\n",
       "      <td>Pandas: date_range error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scry</td>\n",
       "      <td>781.0</td>\n",
       "      <td>scry</td>\n",
       "      <td>781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>12190874</td>\n",
       "      <td>2012-08-30 06:12:46</td>\n",
       "      <td>59</td>\n",
       "      <td>61706</td>\n",
       "      <td>Pandas: Sampling a DataFrame</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Blender</td>\n",
       "      <td>180189.0</td>\n",
       "      <td>Wouter Overmeire</td>\n",
       "      <td>20078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>12200693</td>\n",
       "      <td>2012-08-30 15:45:26</td>\n",
       "      <td>36</td>\n",
       "      <td>31779</td>\n",
       "      <td>Python Pandas How to assign groupby operation ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ely</td>\n",
       "      <td>26102.0</td>\n",
       "      <td>Wouter Overmeire</td>\n",
       "      <td>20078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>12278347</td>\n",
       "      <td>2012-09-05 09:29:34</td>\n",
       "      <td>13</td>\n",
       "      <td>10908</td>\n",
       "      <td>How can I efficiently save a python pandas dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Griffith Rees</td>\n",
       "      <td>811.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>12307099</td>\n",
       "      <td>2012-09-06 19:32:25</td>\n",
       "      <td>89</td>\n",
       "      <td>56876</td>\n",
       "      <td>Modifying a subset of rows in a pandas dataframe</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Arthur B.</td>\n",
       "      <td>977.0</td>\n",
       "      <td>BrenBarn</td>\n",
       "      <td>136870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>12867178</td>\n",
       "      <td>2012-10-12 21:12:33</td>\n",
       "      <td>27</td>\n",
       "      <td>44482</td>\n",
       "      <td>pandas: count things</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Mike Dewar</td>\n",
       "      <td>4437.0</td>\n",
       "      <td>Dani Arribas-Bel</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>13331518</td>\n",
       "      <td>2012-11-11 13:26:27</td>\n",
       "      <td>32</td>\n",
       "      <td>44634</td>\n",
       "      <td>How to add a single item to a Pandas Series</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>eran</td>\n",
       "      <td>4226.0</td>\n",
       "      <td>joaquin</td>\n",
       "      <td>44318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>13439098</td>\n",
       "      <td>2012-11-18 09:56:00</td>\n",
       "      <td>7</td>\n",
       "      <td>17975</td>\n",
       "      <td>How to filter rows of Pandas dataframe by chec...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bigbug</td>\n",
       "      <td>7865.0</td>\n",
       "      <td>Avaris</td>\n",
       "      <td>21067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>13580875</td>\n",
       "      <td>2012-11-27 09:19:07</td>\n",
       "      <td>2</td>\n",
       "      <td>963</td>\n",
       "      <td>Running average / frequency of time series data?</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Prof. Falken</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>Victor K</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>13636592</td>\n",
       "      <td>2012-11-29 23:20:44</td>\n",
       "      <td>23</td>\n",
       "      <td>55230</td>\n",
       "      <td>How to sort a Pandas DataFrame according to mu...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>mpjan</td>\n",
       "      <td>530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>13636848</td>\n",
       "      <td>2012-11-29 23:44:17</td>\n",
       "      <td>28</td>\n",
       "      <td>12539</td>\n",
       "      <td>is it possible to do fuzzy match merge with py...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>pocketfullofcheese</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>13653030</td>\n",
       "      <td>2012-11-30 20:54:35</td>\n",
       "      <td>6</td>\n",
       "      <td>11798</td>\n",
       "      <td>How do I Pass a List of Series to a Pandas Dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rhaskett</td>\n",
       "      <td>323.0</td>\n",
       "      <td>unutbu</td>\n",
       "      <td>464745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>13867294</td>\n",
       "      <td>2012-12-13 19:47:51</td>\n",
       "      <td>6</td>\n",
       "      <td>7603</td>\n",
       "      <td>cleaning big data using python</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Kathirmani Sukumar</td>\n",
       "      <td>3033.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>14059094</td>\n",
       "      <td>2012-12-27 18:02:41</td>\n",
       "      <td>25</td>\n",
       "      <td>46875</td>\n",
       "      <td>I want to multiply two columns in a pandas Dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>486.0</td>\n",
       "      <td>Aman</td>\n",
       "      <td>17046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>18062135</td>\n",
       "      <td>2013-08-05 15:37:39</td>\n",
       "      <td>126</td>\n",
       "      <td>105435</td>\n",
       "      <td>Combining two Series into a DataFrame in pandas</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>user7289</td>\n",
       "      <td>5381.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>18079563</td>\n",
       "      <td>2013-08-06 11:58:31</td>\n",
       "      <td>24</td>\n",
       "      <td>27526</td>\n",
       "      <td>Finding the intersection between two series in...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>user7289</td>\n",
       "      <td>5381.0</td>\n",
       "      <td>Joop</td>\n",
       "      <td>2982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>16852911</td>\n",
       "      <td>2013-05-31 08:23:02</td>\n",
       "      <td>47</td>\n",
       "      <td>62785</td>\n",
       "      <td>How do I convert dates in a Pandas data frame ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>user7289</td>\n",
       "      <td>5381.0</td>\n",
       "      <td>waitingkuo</td>\n",
       "      <td>23950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>16923281</td>\n",
       "      <td>2013-06-04 16:46:56</td>\n",
       "      <td>256</td>\n",
       "      <td>368512</td>\n",
       "      <td>Pandas writing dataframe to CSV file</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>user7289</td>\n",
       "      <td>5381.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>17477979</td>\n",
       "      <td>2013-07-04 20:55:20</td>\n",
       "      <td>67</td>\n",
       "      <td>55481</td>\n",
       "      <td>dropping infinite values from dataframes in pa...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>user248237dfsf</td>\n",
       "      <td>19244.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>14734533</td>\n",
       "      <td>2013-02-06 16:55:54</td>\n",
       "      <td>83</td>\n",
       "      <td>86849</td>\n",
       "      <td>How to access pandas groupby dataframe by key</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>beardc</td>\n",
       "      <td>6122.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>15923826</td>\n",
       "      <td>2013-04-10 10:52:47</td>\n",
       "      <td>44</td>\n",
       "      <td>33349</td>\n",
       "      <td>Random row selection in Pandas dataframe</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>John</td>\n",
       "      <td>8807.0</td>\n",
       "      <td>eumiro</td>\n",
       "      <td>104313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>16396903</td>\n",
       "      <td>2013-05-06 10:35:58</td>\n",
       "      <td>68</td>\n",
       "      <td>75541</td>\n",
       "      <td>Delete the first three rows of a dataframe in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Nilani Algiriyage</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>bdiamante</td>\n",
       "      <td>4507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>17315737</td>\n",
       "      <td>2013-06-26 09:01:24</td>\n",
       "      <td>20</td>\n",
       "      <td>25506</td>\n",
       "      <td>Split a large pandas dataframe</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nilani Algiriyage</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>root</td>\n",
       "      <td>29368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>14742893</td>\n",
       "      <td>2013-02-07 03:13:31</td>\n",
       "      <td>2</td>\n",
       "      <td>598</td>\n",
       "      <td>Interpolation Function</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eWizardII</td>\n",
       "      <td>886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>16327055</td>\n",
       "      <td>2013-05-01 21:46:47</td>\n",
       "      <td>85</td>\n",
       "      <td>83590</td>\n",
       "      <td>How to add an empty column to a dataframe?</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>kjo</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>DSM</td>\n",
       "      <td>164692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49714</th>\n",
       "      <td>46181112</td>\n",
       "      <td>2017-09-12 16:09:13</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>Python Pandas: Finding the index of a pandas s...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PVasish</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>10335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49802</th>\n",
       "      <td>46103426</td>\n",
       "      <td>2017-09-07 19:02:57</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>Filter out rows based on dates and flags from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jeangelj</td>\n",
       "      <td>779.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49896</th>\n",
       "      <td>46105620</td>\n",
       "      <td>2017-09-07 21:51:50</td>\n",
       "      <td>-1</td>\n",
       "      <td>53</td>\n",
       "      <td>Split and tile a pandas dataframe</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abutremutante</td>\n",
       "      <td>857.0</td>\n",
       "      <td>labarna</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49930</th>\n",
       "      <td>45888443</td>\n",
       "      <td>2017-08-25 19:43:31</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>python how to match partial strings between tw...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alwaysaskingquestions</td>\n",
       "      <td>367.0</td>\n",
       "      <td>Han</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50064</th>\n",
       "      <td>46449721</td>\n",
       "      <td>2017-09-27 13:53:38</td>\n",
       "      <td>-2</td>\n",
       "      <td>36</td>\n",
       "      <td>Splitting a dataframe based on the index</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlo Allocca</td>\n",
       "      <td>130.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50452</th>\n",
       "      <td>46229738</td>\n",
       "      <td>2017-09-14 23:49:29</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>Adding rows based on previous condition in ano...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SalN85</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50580</th>\n",
       "      <td>46349345</td>\n",
       "      <td>2017-09-21 16:56:20</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Compare two columns and get unique values in p...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcos Santana</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Alexey Trofimov</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50615</th>\n",
       "      <td>46007571</td>\n",
       "      <td>2017-09-01 20:26:23</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>with python, select repeated elements longer t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jonathan Pacheco</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50704</th>\n",
       "      <td>46185965</td>\n",
       "      <td>2017-09-12 22:01:39</td>\n",
       "      <td>11</td>\n",
       "      <td>657</td>\n",
       "      <td>How can I map the headers to columns in pandas?</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sunny</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50735</th>\n",
       "      <td>46303356</td>\n",
       "      <td>2017-09-19 14:41:18</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>pandas - Count streak of values higher/lower t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bruno Vieira</td>\n",
       "      <td>32.0</td>\n",
       "      <td>benjwadams</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50803</th>\n",
       "      <td>46331210</td>\n",
       "      <td>2017-09-20 20:25:34</td>\n",
       "      <td>8</td>\n",
       "      <td>253</td>\n",
       "      <td>How to assign count of unique values to the re...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Doubt Dhanabalu</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>10335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51148</th>\n",
       "      <td>46148302</td>\n",
       "      <td>2017-09-11 04:41:31</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>What is the best way to access values in a dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chrisckwong821</td>\n",
       "      <td>417.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51257</th>\n",
       "      <td>46201618</td>\n",
       "      <td>2017-09-13 15:37:03</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>Pandas: The best way to create new Frame by sp...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renton</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Zero</td>\n",
       "      <td>25935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51654</th>\n",
       "      <td>46870692</td>\n",
       "      <td>2017-10-22 05:09:30</td>\n",
       "      <td>8</td>\n",
       "      <td>555</td>\n",
       "      <td>How to find first local maximum for every group?</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>user1357015</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51798</th>\n",
       "      <td>46653647</td>\n",
       "      <td>2017-10-09 19:26:05</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "      <td>Pandas: filter on multiple columns</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M. K. Hunter</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51821</th>\n",
       "      <td>46912379</td>\n",
       "      <td>2017-10-24 13:53:38</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>DataFrame transpose from List</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josh</td>\n",
       "      <td>118.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51968</th>\n",
       "      <td>46655202</td>\n",
       "      <td>2017-10-09 21:24:37</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>Probability of a Pandas value</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seano314</td>\n",
       "      <td>336.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52013</th>\n",
       "      <td>47061564</td>\n",
       "      <td>2017-11-01 18:40:36</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>How to create strings from dataframe columns e...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hernanavella</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Scott Boston</td>\n",
       "      <td>23611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52254</th>\n",
       "      <td>46898334</td>\n",
       "      <td>2017-10-23 20:52:59</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>How do I avoid a loop with Python/Pandas to bu...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GC123</td>\n",
       "      <td>40.0</td>\n",
       "      <td>GC123</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52273</th>\n",
       "      <td>47055259</td>\n",
       "      <td>2017-11-01 12:48:36</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>Python dict group and sum multiple values</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ajay Kumar</td>\n",
       "      <td>178.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52967</th>\n",
       "      <td>46816226</td>\n",
       "      <td>2017-10-18 17:48:28</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>Selecting single values from pandas dataframe ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edager</td>\n",
       "      <td>81.0</td>\n",
       "      <td>MaxU</td>\n",
       "      <td>83732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53088</th>\n",
       "      <td>46519539</td>\n",
       "      <td>2017-10-02 04:31:57</td>\n",
       "      <td>6</td>\n",
       "      <td>186</td>\n",
       "      <td>How to select all non-NaN columns and non-NaN ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fang</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Bharath</td>\n",
       "      <td>12877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53365</th>\n",
       "      <td>46697440</td>\n",
       "      <td>2017-10-11 20:57:28</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Add Virgula in front of each word</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rivaldo Hater</td>\n",
       "      <td>18.0</td>\n",
       "      <td>MedAli</td>\n",
       "      <td>5232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53418</th>\n",
       "      <td>46499582</td>\n",
       "      <td>2017-09-30 04:30:26</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>How to make list of list from dataframe pandas?</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satrio Adi Prabowo</td>\n",
       "      <td>98.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53423</th>\n",
       "      <td>46585640</td>\n",
       "      <td>2017-10-05 12:28:22</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>Get one or more column values as a list from P...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pyd</td>\n",
       "      <td>416.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53433</th>\n",
       "      <td>47028601</td>\n",
       "      <td>2017-10-31 05:45:19</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>how to remove 0's in a datacolumn in a datafra...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pyd</td>\n",
       "      <td>416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>46557074</td>\n",
       "      <td>2017-10-04 04:33:51</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Grouping similar values in a dictionary</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ConstantLearner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jeremy McGibbon</td>\n",
       "      <td>1121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53983</th>\n",
       "      <td>46882557</td>\n",
       "      <td>2017-10-23 05:36:29</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>How to split columns faster in python?</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Xu</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Akshay Hegde</td>\n",
       "      <td>11362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54384</th>\n",
       "      <td>47542980</td>\n",
       "      <td>2017-11-29 00:05:31</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Pandas groupby - set of different values</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baron Yugovich</td>\n",
       "      <td>260.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55444</th>\n",
       "      <td>47213771</td>\n",
       "      <td>2017-11-10 00:13:38</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>column operation in csv [python]</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alex</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Bharath</td>\n",
       "      <td>12877.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         creationdate  score  viewcount  \\\n",
       "75     10373660  2012-04-29 16:10:35    199     207980   \n",
       "115    10791661  2012-05-29 00:06:52      7      12210   \n",
       "130    10972410  2012-06-10 21:12:43     19      46428   \n",
       "189    11391969  2012-07-09 09:04:33     44      27467   \n",
       "246    11811392  2012-08-04 19:25:34     17      20051   \n",
       "247    11824341  2012-08-06 07:47:34      0       1558   \n",
       "316    12190874  2012-08-30 06:12:46     59      61706   \n",
       "318    12200693  2012-08-30 15:45:26     36      31779   \n",
       "335    12278347  2012-09-05 09:29:34     13      10908   \n",
       "339    12307099  2012-09-06 19:32:25     89      56876   \n",
       "444    12867178  2012-10-12 21:12:33     27      44482   \n",
       "559    13331518  2012-11-11 13:26:27     32      44634   \n",
       "589    13439098  2012-11-18 09:56:00      7      17975   \n",
       "620    13580875  2012-11-27 09:19:07      2        963   \n",
       "634    13636592  2012-11-29 23:20:44     23      55230   \n",
       "635    13636848  2012-11-29 23:44:17     28      12539   \n",
       "639    13653030  2012-11-30 20:54:35      6      11798   \n",
       "686    13867294  2012-12-13 19:47:51      6       7603   \n",
       "748    14059094  2012-12-27 18:02:41     25      46875   \n",
       "1021   18062135  2013-08-05 15:37:39    126     105435   \n",
       "1023   18079563  2013-08-06 11:58:31     24      27526   \n",
       "1042   16852911  2013-05-31 08:23:02     47      62785   \n",
       "1043   16923281  2013-06-04 16:46:56    256     368512   \n",
       "1122   17477979  2013-07-04 20:55:20     67      55481   \n",
       "1208   14734533  2013-02-06 16:55:54     83      86849   \n",
       "1216   15923826  2013-04-10 10:52:47     44      33349   \n",
       "1263   16396903  2013-05-06 10:35:58     68      75541   \n",
       "1277   17315737  2013-06-26 09:01:24     20      25506   \n",
       "1316   14742893  2013-02-07 03:13:31      2        598   \n",
       "1331   16327055  2013-05-01 21:46:47     85      83590   \n",
       "...         ...                  ...    ...        ...   \n",
       "49714  46181112  2017-09-12 16:09:13      1         54   \n",
       "49802  46103426  2017-09-07 19:02:57      2         75   \n",
       "49896  46105620  2017-09-07 21:51:50     -1         53   \n",
       "49930  45888443  2017-08-25 19:43:31      1         94   \n",
       "50064  46449721  2017-09-27 13:53:38     -2         36   \n",
       "50452  46229738  2017-09-14 23:49:29      2         40   \n",
       "50580  46349345  2017-09-21 16:56:20      0         60   \n",
       "50615  46007571  2017-09-01 20:26:23      8        115   \n",
       "50704  46185965  2017-09-12 22:01:39     11        657   \n",
       "50735  46303356  2017-09-19 14:41:18      2        162   \n",
       "50803  46331210  2017-09-20 20:25:34      8        253   \n",
       "51148  46148302  2017-09-11 04:41:31      1         65   \n",
       "51257  46201618  2017-09-13 15:37:03      3         45   \n",
       "51654  46870692  2017-10-22 05:09:30      8        555   \n",
       "51798  46653647  2017-10-09 19:26:05      1        349   \n",
       "51821  46912379  2017-10-24 13:53:38      2         48   \n",
       "51968  46655202  2017-10-09 21:24:37      4         62   \n",
       "52013  47061564  2017-11-01 18:40:36      5         60   \n",
       "52254  46898334  2017-10-23 20:52:59      0         62   \n",
       "52273  47055259  2017-11-01 12:48:36      3         83   \n",
       "52967  46816226  2017-10-18 17:48:28      7        122   \n",
       "53088  46519539  2017-10-02 04:31:57      6        186   \n",
       "53365  46697440  2017-10-11 20:57:28      2         43   \n",
       "53418  46499582  2017-09-30 04:30:26      2         75   \n",
       "53423  46585640  2017-10-05 12:28:22      1         47   \n",
       "53433  47028601  2017-10-31 05:45:19      2         38   \n",
       "53752  46557074  2017-10-04 04:33:51      0         61   \n",
       "53983  46882557  2017-10-23 05:36:29      3         87   \n",
       "54384  47542980  2017-11-29 00:05:31      2         43   \n",
       "55444  47213771  2017-11-10 00:13:38      1        247   \n",
       "\n",
       "                                                   title  answercount  \\\n",
       "75       Converting a Pandas GroupBy object to DataFrame            5   \n",
       "115    How do I discretize values in a pandas DataFra...            5   \n",
       "130           pandas: combine two columns in a DataFrame            5   \n",
       "189    How to group pandas DataFrame entries by date ...            5   \n",
       "246    How to generate a list from a pandas DataFrame...            5   \n",
       "247                             Pandas: date_range error            5   \n",
       "316                         Pandas: Sampling a DataFrame            5   \n",
       "318    Python Pandas How to assign groupby operation ...            5   \n",
       "335    How can I efficiently save a python pandas dat...            5   \n",
       "339     Modifying a subset of rows in a pandas dataframe            5   \n",
       "444                                 pandas: count things            5   \n",
       "559          How to add a single item to a Pandas Series            5   \n",
       "589    How to filter rows of Pandas dataframe by chec...            5   \n",
       "620     Running average / frequency of time series data?            5   \n",
       "634    How to sort a Pandas DataFrame according to mu...            5   \n",
       "635    is it possible to do fuzzy match merge with py...            5   \n",
       "639    How do I Pass a List of Series to a Pandas Dat...            5   \n",
       "686                       cleaning big data using python            5   \n",
       "748    I want to multiply two columns in a pandas Dat...            5   \n",
       "1021     Combining two Series into a DataFrame in pandas            5   \n",
       "1023   Finding the intersection between two series in...            5   \n",
       "1042   How do I convert dates in a Pandas data frame ...            5   \n",
       "1043                Pandas writing dataframe to CSV file            5   \n",
       "1122   dropping infinite values from dataframes in pa...            5   \n",
       "1208       How to access pandas groupby dataframe by key            5   \n",
       "1216            Random row selection in Pandas dataframe            5   \n",
       "1263   Delete the first three rows of a dataframe in ...            5   \n",
       "1277                      Split a large pandas dataframe            5   \n",
       "1316                              Interpolation Function            5   \n",
       "1331          How to add an empty column to a dataframe?            5   \n",
       "...                                                  ...          ...   \n",
       "49714  Python Pandas: Finding the index of a pandas s...            5   \n",
       "49802  Filter out rows based on dates and flags from ...            5   \n",
       "49896                  Split and tile a pandas dataframe            5   \n",
       "49930  python how to match partial strings between tw...            5   \n",
       "50064           Splitting a dataframe based on the index            5   \n",
       "50452  Adding rows based on previous condition in ano...            5   \n",
       "50580  Compare two columns and get unique values in p...            5   \n",
       "50615  with python, select repeated elements longer t...            5   \n",
       "50704    How can I map the headers to columns in pandas?            5   \n",
       "50735  pandas - Count streak of values higher/lower t...            5   \n",
       "50803  How to assign count of unique values to the re...            5   \n",
       "51148  What is the best way to access values in a dat...            5   \n",
       "51257  Pandas: The best way to create new Frame by sp...            5   \n",
       "51654   How to find first local maximum for every group?            5   \n",
       "51798                 Pandas: filter on multiple columns            5   \n",
       "51821                      DataFrame transpose from List            5   \n",
       "51968                      Probability of a Pandas value            5   \n",
       "52013  How to create strings from dataframe columns e...            5   \n",
       "52254  How do I avoid a loop with Python/Pandas to bu...            5   \n",
       "52273          Python dict group and sum multiple values            5   \n",
       "52967  Selecting single values from pandas dataframe ...            5   \n",
       "53088  How to select all non-NaN columns and non-NaN ...            5   \n",
       "53365                  Add Virgula in front of each word            5   \n",
       "53418    How to make list of list from dataframe pandas?            5   \n",
       "53423  Get one or more column values as a list from P...            5   \n",
       "53433  how to remove 0's in a datacolumn in a datafra...            5   \n",
       "53752            Grouping similar values in a dictionary            5   \n",
       "53983             How to split columns faster in python?            5   \n",
       "54384           Pandas groupby - set of different values            5   \n",
       "55444                   column operation in csv [python]            5   \n",
       "\n",
       "       commentcount  favoritecount             quest_name  quest_rep  \\\n",
       "75                0           90.0                saveenr     2421.0   \n",
       "115               0            3.0           Uri Laserson      958.0   \n",
       "130               0            5.0                   BFTM      895.0   \n",
       "189               1           15.0          Boris Gorelik     9605.0   \n",
       "246               0            6.0                 turtle     1260.0   \n",
       "247               2            NaN                   scry      781.0   \n",
       "316               1           24.0                Blender   180189.0   \n",
       "318               3           20.0                    ely    26102.0   \n",
       "335               3            7.0          Griffith Rees      811.0   \n",
       "339               1           41.0              Arthur B.      977.0   \n",
       "444               4           15.0             Mike Dewar     4437.0   \n",
       "559               0            3.0                   eran     4226.0   \n",
       "589               3            1.0                 bigbug     7865.0   \n",
       "620               9            1.0           Prof. Falken    15061.0   \n",
       "634               0           10.0                  mpjan      530.0   \n",
       "635               2           11.0     pocketfullofcheese     2192.0   \n",
       "639               1            1.0               rhaskett      323.0   \n",
       "686               2            3.0     Kathirmani Sukumar     3033.0   \n",
       "748               0           14.0                    OAK      486.0   \n",
       "1021              0           36.0               user7289     5381.0   \n",
       "1023              0            4.0               user7289     5381.0   \n",
       "1042              0           13.0               user7289     5381.0   \n",
       "1043              0           45.0               user7289     5381.0   \n",
       "1122              0           16.0         user248237dfsf    19244.0   \n",
       "1208              0           25.0                 beardc     6122.0   \n",
       "1216              0            7.0                   John     8807.0   \n",
       "1263              0           13.0      Nilani Algiriyage     4083.0   \n",
       "1277              0            4.0      Nilani Algiriyage     4083.0   \n",
       "1316              0            NaN              eWizardII      886.0   \n",
       "1331              1           20.0                    kjo    10487.0   \n",
       "...             ...            ...                    ...        ...   \n",
       "49714             4            NaN                PVasish        8.0   \n",
       "49802             2            1.0               jeangelj      779.0   \n",
       "49896             1            NaN          abutremutante      857.0   \n",
       "49930             1            NaN  alwaysaskingquestions      367.0   \n",
       "50064             0            NaN          Carlo Allocca      130.0   \n",
       "50452             1            NaN                 SalN85       41.0   \n",
       "50580             0            NaN         Marcos Santana       75.0   \n",
       "50615             0            2.0       Jonathan Pacheco       88.0   \n",
       "50704             0            3.0                  sunny       93.0   \n",
       "50735             0            1.0           Bruno Vieira       32.0   \n",
       "50803             0            4.0        Doubt Dhanabalu      113.0   \n",
       "51148             0            0.0         chrisckwong821      417.0   \n",
       "51257             0            NaN                 Renton       34.0   \n",
       "51654             3            3.0            user1357015     2853.0   \n",
       "51798             3            1.0           M. K. Hunter     1127.0   \n",
       "51821             0            NaN                   Josh      118.0   \n",
       "51968             1            1.0               Seano314      336.0   \n",
       "52013             0            NaN           hernanavella     1890.0   \n",
       "52254             3            NaN                  GC123       40.0   \n",
       "52273             7            1.0             Ajay Kumar      178.0   \n",
       "52967             2            NaN                 edager       81.0   \n",
       "53088             0            NaN                   Fang      308.0   \n",
       "53365             1            NaN          Rivaldo Hater       18.0   \n",
       "53418             0            NaN     Satrio Adi Prabowo       98.0   \n",
       "53423             0            NaN                    pyd      416.0   \n",
       "53433             5            NaN                    pyd      416.0   \n",
       "53752             0            NaN        ConstantLearner        3.0   \n",
       "53983             2            NaN               Steve Xu       23.0   \n",
       "54384             0            NaN         Baron Yugovich      260.0   \n",
       "55444            13            1.0                   Alex       17.0   \n",
       "\n",
       "               ans_name   ans_rep  \n",
       "75         Wes McKinney   43310.0  \n",
       "115              lbolla    4552.0  \n",
       "130            BrenBarn  136870.0  \n",
       "189        Wes McKinney   43310.0  \n",
       "246            BrenBarn  136870.0  \n",
       "247                scry     781.0  \n",
       "316    Wouter Overmeire   20078.0  \n",
       "318    Wouter Overmeire   20078.0  \n",
       "335                 NaN       NaN  \n",
       "339            BrenBarn  136870.0  \n",
       "444    Dani Arribas-Bel     506.0  \n",
       "559             joaquin   44318.0  \n",
       "589              Avaris   21067.0  \n",
       "620            Victor K     332.0  \n",
       "634                 NaN       NaN  \n",
       "635         Andy Hayden  131029.0  \n",
       "639              unutbu  464745.0  \n",
       "686         Andy Hayden  131029.0  \n",
       "748                Aman   17046.0  \n",
       "1021        Andy Hayden  131029.0  \n",
       "1023               Joop    2982.0  \n",
       "1042         waitingkuo   23950.0  \n",
       "1043        Andy Hayden  131029.0  \n",
       "1122        Andy Hayden  131029.0  \n",
       "1208        Andy Hayden  131029.0  \n",
       "1216             eumiro  104313.0  \n",
       "1263          bdiamante    4507.0  \n",
       "1277               root   29368.0  \n",
       "1316                NaN       NaN  \n",
       "1331                DSM  164692.0  \n",
       "...                 ...       ...  \n",
       "49714          Vaishali   10335.0  \n",
       "49802         cs   51675.0  \n",
       "49896           labarna     144.0  \n",
       "49930               Han      26.0  \n",
       "50064         cs   51675.0  \n",
       "50452               NaN       NaN  \n",
       "50580   Alexey Trofimov     533.0  \n",
       "50615               NaN       NaN  \n",
       "50704               NaN       NaN  \n",
       "50735        benjwadams     750.0  \n",
       "50803          Vaishali   10335.0  \n",
       "51148         cs   51675.0  \n",
       "51257              Zero   25935.0  \n",
       "51654        piRSquared  102658.0  \n",
       "51798               NaN       NaN  \n",
       "51821           jezrael  186894.0  \n",
       "51968        piRSquared  102658.0  \n",
       "52013      Scott Boston   23611.0  \n",
       "52254             GC123      40.0  \n",
       "52273         cs   51675.0  \n",
       "52967              MaxU   83732.0  \n",
       "53088           Bharath   12877.0  \n",
       "53365            MedAli    5232.0  \n",
       "53418           jezrael  186894.0  \n",
       "53423           jezrael  186894.0  \n",
       "53433               NaN       NaN  \n",
       "53752   Jeremy McGibbon    1121.0  \n",
       "53983      Akshay Hegde   11362.0  \n",
       "54384           jezrael  186894.0  \n",
       "55444           Bharath   12877.0  \n",
       "\n",
       "[296 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[so['answercount'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions that have less than 10 views</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>26493306</td>\n",
       "      <td>2014-10-21 18:06:10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>How to convert hierarchical DataFrame back fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exp1orer</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17653</th>\n",
       "      <td>33641540</td>\n",
       "      <td>2015-11-10 23:19:36</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Joining Dataframes in Pandas deletes an existi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rahul Biswas</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29414</th>\n",
       "      <td>40062672</td>\n",
       "      <td>2016-10-15 18:24:21</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>Replace one or more sub-strings from multiple ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreuccio</td>\n",
       "      <td>186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36086</th>\n",
       "      <td>42538091</td>\n",
       "      <td>2017-03-01 17:20:37</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Saving box plot pandas python</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user2906657</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36340</th>\n",
       "      <td>42080039</td>\n",
       "      <td>2017-02-07 01:13:30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>pandas: count the non-duplicated elements when...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edamame</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>root</td>\n",
       "      <td>12202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40490</th>\n",
       "      <td>43271693</td>\n",
       "      <td>2017-04-07 07:04:19</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Pandas Unsuccessfully Modify</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mellon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43489</th>\n",
       "      <td>45069021</td>\n",
       "      <td>2017-07-12 23:22:49</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Can ask for strides of k subsequent items from...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user48956</td>\n",
       "      <td>3832.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47371</th>\n",
       "      <td>45212468</td>\n",
       "      <td>2017-07-20 10:43:55</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Pandas reads partial content</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keshav Reddy</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49232</th>\n",
       "      <td>45890470</td>\n",
       "      <td>2017-08-25 23:16:57</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>result of pandas.PeriodIndex(astype(str)) in p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>checker</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50461</th>\n",
       "      <td>45991431</td>\n",
       "      <td>2017-08-31 23:26:20</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Check for excel file on a url link via while l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shyama Sonti</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52518</th>\n",
       "      <td>47091256</td>\n",
       "      <td>2017-11-03 08:20:58</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Unifying columns in the same Pandas dataframe ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anjo</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53794</th>\n",
       "      <td>46628996</td>\n",
       "      <td>2017-10-08 08:22:26</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Trying to aggregate two columns of values into...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lys</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54304</th>\n",
       "      <td>47208273</td>\n",
       "      <td>2017-11-09 17:38:49</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Pandas SettingWithCopyWarning with to_datetime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the tao</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54462</th>\n",
       "      <td>47254707</td>\n",
       "      <td>2017-11-12 22:26:52</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>CSV download from Github link gives tokenizing...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user3059218</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54507</th>\n",
       "      <td>47611836</td>\n",
       "      <td>2017-12-02 19:44:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>pandas: different plot x-values when plotting ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SuperGeo</td>\n",
       "      <td>246.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54855</th>\n",
       "      <td>47126567</td>\n",
       "      <td>2017-11-05 20:58:17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Expanding Int64 data type in dataframe</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>madman</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55041</th>\n",
       "      <td>47440171</td>\n",
       "      <td>2017-11-22 16:58:49</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Multi-index and time-stamps not recognised in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreuccio</td>\n",
       "      <td>186.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55068</th>\n",
       "      <td>47461776</td>\n",
       "      <td>2017-11-23 18:45:23</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>how to drop duplicates in pandas when entries ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>splinter</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>Wen</td>\n",
       "      <td>21789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55166</th>\n",
       "      <td>47550355</td>\n",
       "      <td>2017-11-29 10:20:18</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>pandas HTML rendering of multi-index changes w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campi</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55234</th>\n",
       "      <td>47477606</td>\n",
       "      <td>2017-11-24 17:09:18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Plotly- shading time series regions based on a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dick Thompson</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55285</th>\n",
       "      <td>47553898</td>\n",
       "      <td>2017-11-29 13:23:17</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>Pandas: Delete duplicated items in a specific ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>totyped</td>\n",
       "      <td>224.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55410</th>\n",
       "      <td>47548480</td>\n",
       "      <td>2017-11-29 08:46:06</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>how to store the Pandas nunique value of age i...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sujay</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55554</th>\n",
       "      <td>47462671</td>\n",
       "      <td>2017-11-23 20:06:18</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Create column that makes summation to a scalar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ge00rge</td>\n",
       "      <td>646.0</td>\n",
       "      <td>Wen</td>\n",
       "      <td>21789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55606</th>\n",
       "      <td>47421513</td>\n",
       "      <td>2017-11-21 19:48:44</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Converting CSV to sqlite3 table in pandas - \"8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ifthenifthen</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55636</th>\n",
       "      <td>47428726</td>\n",
       "      <td>2017-11-22 07:06:58</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>How to link a python file with libm?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shashank Simha M R</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55713</th>\n",
       "      <td>47614866</td>\n",
       "      <td>2017-12-03 03:06:05</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>How to convert a List of lists with nested dic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parul</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56326</th>\n",
       "      <td>47607315</td>\n",
       "      <td>2017-12-02 11:16:13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>ModuleNotFoundError: No module named 'pandas._...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sam Kuan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56374</th>\n",
       "      <td>47613361</td>\n",
       "      <td>2017-12-02 22:38:38</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>How to remove duplicate markers in gmaps in pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         creationdate  score  viewcount  \\\n",
       "7787   26493306  2014-10-21 18:06:10      1          6   \n",
       "17653  33641540  2015-11-10 23:19:36      0          9   \n",
       "29414  40062672  2016-10-15 18:24:21     -1          9   \n",
       "36086  42538091  2017-03-01 17:20:37      0          9   \n",
       "36340  42080039  2017-02-07 01:13:30      0          8   \n",
       "40490  43271693  2017-04-07 07:04:19      0          9   \n",
       "43489  45069021  2017-07-12 23:22:49      1          9   \n",
       "47371  45212468  2017-07-20 10:43:55      0          9   \n",
       "49232  45890470  2017-08-25 23:16:57      0          7   \n",
       "50461  45991431  2017-08-31 23:26:20      0          9   \n",
       "52518  47091256  2017-11-03 08:20:58      0          8   \n",
       "53794  46628996  2017-10-08 08:22:26      0          7   \n",
       "54304  47208273  2017-11-09 17:38:49      0          6   \n",
       "54462  47254707  2017-11-12 22:26:52      0          9   \n",
       "54507  47611836  2017-12-02 19:44:00      0          8   \n",
       "54855  47126567  2017-11-05 20:58:17      0          9   \n",
       "55041  47440171  2017-11-22 16:58:49      0          8   \n",
       "55068  47461776  2017-11-23 18:45:23      0          8   \n",
       "55166  47550355  2017-11-29 10:20:18      0          9   \n",
       "55234  47477606  2017-11-24 17:09:18      0          5   \n",
       "55285  47553898  2017-11-29 13:23:17      2          9   \n",
       "55410  47548480  2017-11-29 08:46:06     -2          8   \n",
       "55554  47462671  2017-11-23 20:06:18      1          8   \n",
       "55606  47421513  2017-11-21 19:48:44      0          7   \n",
       "55636  47428726  2017-11-22 07:06:58      0          6   \n",
       "55713  47614866  2017-12-03 03:06:05      0          6   \n",
       "56326  47607315  2017-12-02 11:16:13      0          9   \n",
       "56374  47613361  2017-12-02 22:38:38      0          8   \n",
       "\n",
       "                                                   title  answercount  \\\n",
       "7787   How to convert hierarchical DataFrame back fro...            0   \n",
       "17653  Joining Dataframes in Pandas deletes an existi...            1   \n",
       "29414  Replace one or more sub-strings from multiple ...            1   \n",
       "36086                      Saving box plot pandas python            0   \n",
       "36340  pandas: count the non-duplicated elements when...            1   \n",
       "40490                       Pandas Unsuccessfully Modify            1   \n",
       "43489  Can ask for strides of k subsequent items from...            1   \n",
       "47371                       Pandas reads partial content            0   \n",
       "49232  result of pandas.PeriodIndex(astype(str)) in p...            1   \n",
       "50461  Check for excel file on a url link via while l...            0   \n",
       "52518  Unifying columns in the same Pandas dataframe ...            1   \n",
       "53794  Trying to aggregate two columns of values into...            0   \n",
       "54304     Pandas SettingWithCopyWarning with to_datetime            0   \n",
       "54462  CSV download from Github link gives tokenizing...            1   \n",
       "54507  pandas: different plot x-values when plotting ...            0   \n",
       "54855             Expanding Int64 data type in dataframe            0   \n",
       "55041  Multi-index and time-stamps not recognised in ...            0   \n",
       "55068  how to drop duplicates in pandas when entries ...            1   \n",
       "55166  pandas HTML rendering of multi-index changes w...            0   \n",
       "55234  Plotly- shading time series regions based on a...            0   \n",
       "55285  Pandas: Delete duplicated items in a specific ...            1   \n",
       "55410  how to store the Pandas nunique value of age i...            0   \n",
       "55554     Create column that makes summation to a scalar            1   \n",
       "55606  Converting CSV to sqlite3 table in pandas - \"8...            1   \n",
       "55636               How to link a python file with libm?            0   \n",
       "55713  How to convert a List of lists with nested dic...            0   \n",
       "56326  ModuleNotFoundError: No module named 'pandas._...            0   \n",
       "56374  How to remove duplicate markers in gmaps in pa...            0   \n",
       "\n",
       "       commentcount  favoritecount          quest_name  quest_rep ans_name  \\\n",
       "7787              2            1.0            exp1orer     3551.0      NaN   \n",
       "17653             0            NaN        Rahul Biswas       88.0      NaN   \n",
       "29414             0            NaN          Andreuccio      186.0      NaN   \n",
       "36086             0            NaN         user2906657      119.0      NaN   \n",
       "36340             0            NaN             Edamame     2281.0     root   \n",
       "40490             1            NaN              Mellon        4.0      NaN   \n",
       "43489             0            NaN           user48956     3832.0      NaN   \n",
       "47371             2            NaN        Keshav Reddy       16.0      NaN   \n",
       "49232             0            NaN             checker       18.0      NaN   \n",
       "50461             0            NaN        Shyama Sonti       73.0      NaN   \n",
       "52518             0            NaN                Anjo       13.0      NaN   \n",
       "53794             0            NaN                 lys        1.0      NaN   \n",
       "54304             0            NaN             the tao      110.0      NaN   \n",
       "54462             0            NaN         user3059218        4.0      NaN   \n",
       "54507             1            NaN            SuperGeo      246.0      NaN   \n",
       "54855             2            NaN              madman       54.0      NaN   \n",
       "55041             0            NaN          Andreuccio      186.0      NaN   \n",
       "55068             0            NaN            splinter     1054.0      Wen   \n",
       "55166             0            NaN               Campi       20.0      NaN   \n",
       "55234             0            NaN       Dick Thompson      110.0      NaN   \n",
       "55285             0            0.0             totyped      224.0  jezrael   \n",
       "55410             2            NaN               sujay        1.0      NaN   \n",
       "55554             0            NaN             ge00rge      646.0      Wen   \n",
       "55606             0            NaN        ifthenifthen       92.0      NaN   \n",
       "55636             0            NaN  Shashank Simha M R        3.0      NaN   \n",
       "55713             0            NaN               Parul       11.0      NaN   \n",
       "56326             0            1.0            Sam Kuan        6.0      NaN   \n",
       "56374             0            NaN               Sarah        3.0      NaN   \n",
       "\n",
       "        ans_rep  \n",
       "7787        NaN  \n",
       "17653       NaN  \n",
       "29414       NaN  \n",
       "36086       NaN  \n",
       "36340   12202.0  \n",
       "40490       NaN  \n",
       "43489       NaN  \n",
       "47371       NaN  \n",
       "49232       NaN  \n",
       "50461       NaN  \n",
       "52518       NaN  \n",
       "53794       NaN  \n",
       "54304       NaN  \n",
       "54462       NaN  \n",
       "54507       NaN  \n",
       "54855       NaN  \n",
       "55041       NaN  \n",
       "55068   21789.0  \n",
       "55166       NaN  \n",
       "55234       NaN  \n",
       "55285  186894.0  \n",
       "55410       NaN  \n",
       "55554   21789.0  \n",
       "55606       NaN  \n",
       "55636       NaN  \n",
       "55713       NaN  \n",
       "56326       NaN  \n",
       "56374       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[so['viewcount'] < 10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions where the person asking it is the same as the person answering it</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8273092</td>\n",
       "      <td>2011-11-25 18:39:02</td>\n",
       "      <td>1</td>\n",
       "      <td>2333</td>\n",
       "      <td>python: pandas install errors</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>codingknob</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>codingknob</td>\n",
       "      <td>2279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9721429</td>\n",
       "      <td>2012-03-15 14:08:31</td>\n",
       "      <td>9</td>\n",
       "      <td>5732</td>\n",
       "      <td>How do I read a fix width format text file in ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user1234440</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>user1234440</td>\n",
       "      <td>3369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10020591</td>\n",
       "      <td>2012-04-04 23:17:23</td>\n",
       "      <td>21</td>\n",
       "      <td>20171</td>\n",
       "      <td>How to resample a dataframe with different fun...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>bmu</td>\n",
       "      <td>17129.0</td>\n",
       "      <td>bmu</td>\n",
       "      <td>17129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10175068</td>\n",
       "      <td>2012-04-16 13:27:44</td>\n",
       "      <td>15</td>\n",
       "      <td>7501</td>\n",
       "      <td>Select data at a particular level from a Multi...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>elyase</td>\n",
       "      <td>19551.0</td>\n",
       "      <td>elyase</td>\n",
       "      <td>19551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10264739</td>\n",
       "      <td>2012-04-22 02:35:06</td>\n",
       "      <td>9</td>\n",
       "      <td>2362</td>\n",
       "      <td>major memory problems reading in a csv file us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>vgoklani</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>vgoklani</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>10475488</td>\n",
       "      <td>2012-05-07 00:38:47</td>\n",
       "      <td>5</td>\n",
       "      <td>2263</td>\n",
       "      <td>Calculating crossing (intercept) points of a S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dailyglen</td>\n",
       "      <td>460.0</td>\n",
       "      <td>dailyglen</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10771745</td>\n",
       "      <td>2012-05-27 04:53:45</td>\n",
       "      <td>0</td>\n",
       "      <td>1146</td>\n",
       "      <td>Removing duplicates from dataframe with index ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dailyglen</td>\n",
       "      <td>460.0</td>\n",
       "      <td>dailyglen</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>11264307</td>\n",
       "      <td>2012-06-29 15:09:28</td>\n",
       "      <td>9</td>\n",
       "      <td>7436</td>\n",
       "      <td>Adding levels to MultiIndex, removing without ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Arthur G</td>\n",
       "      <td>987.0</td>\n",
       "      <td>Arthur G</td>\n",
       "      <td>987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>11418192</td>\n",
       "      <td>2012-07-10 16:56:37</td>\n",
       "      <td>42</td>\n",
       "      <td>24109</td>\n",
       "      <td>pandas: complex filter on rows of DataFrame</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>duckworthd</td>\n",
       "      <td>4733.0</td>\n",
       "      <td>duckworthd</td>\n",
       "      <td>4733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>11762815</td>\n",
       "      <td>2012-08-01 15:41:19</td>\n",
       "      <td>6</td>\n",
       "      <td>2945</td>\n",
       "      <td>How to resample a python pandas TimeSeries con...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THM</td>\n",
       "      <td>305.0</td>\n",
       "      <td>THM</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>11824341</td>\n",
       "      <td>2012-08-06 07:47:34</td>\n",
       "      <td>0</td>\n",
       "      <td>1558</td>\n",
       "      <td>Pandas: date_range error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scry</td>\n",
       "      <td>781.0</td>\n",
       "      <td>scry</td>\n",
       "      <td>781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>11848578</td>\n",
       "      <td>2012-08-07 14:50:42</td>\n",
       "      <td>1</td>\n",
       "      <td>452</td>\n",
       "      <td>Pandas messing up dataframe</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user1569050</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>user1569050</td>\n",
       "      <td>2519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>12203901</td>\n",
       "      <td>2012-08-30 19:15:56</td>\n",
       "      <td>13</td>\n",
       "      <td>7032</td>\n",
       "      <td>pandas crashes on repeated DataFrame.reset_ind...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abe</td>\n",
       "      <td>5182.0</td>\n",
       "      <td>Abe</td>\n",
       "      <td>5182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>12329853</td>\n",
       "      <td>2012-09-08 10:16:04</td>\n",
       "      <td>11</td>\n",
       "      <td>36312</td>\n",
       "      <td>How to rearrange Pandas column sequence?</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bigbug</td>\n",
       "      <td>7865.0</td>\n",
       "      <td>bigbug</td>\n",
       "      <td>7865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>12383436</td>\n",
       "      <td>2012-09-12 07:47:20</td>\n",
       "      <td>4</td>\n",
       "      <td>1593</td>\n",
       "      <td>Access Pandas Series item with dot notation li...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhE</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>PhE</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>12569730</td>\n",
       "      <td>2012-09-24 17:11:53</td>\n",
       "      <td>31</td>\n",
       "      <td>7160</td>\n",
       "      <td>Sum all columns with a wildcard name search us...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>jbssm</td>\n",
       "      <td>2620.0</td>\n",
       "      <td>jbssm</td>\n",
       "      <td>2620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>12641606</td>\n",
       "      <td>2012-09-28 14:06:39</td>\n",
       "      <td>0</td>\n",
       "      <td>1341</td>\n",
       "      <td>Pandas: sorting numbers within text by column</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fred</td>\n",
       "      <td>2342.0</td>\n",
       "      <td>fred</td>\n",
       "      <td>2342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>12647811</td>\n",
       "      <td>2012-09-28 21:46:38</td>\n",
       "      <td>1</td>\n",
       "      <td>489</td>\n",
       "      <td>Swap cells strings from 2 dataframe columns</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fred</td>\n",
       "      <td>2342.0</td>\n",
       "      <td>fred</td>\n",
       "      <td>2342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>12720159</td>\n",
       "      <td>2012-10-04 04:10:11</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>pandas alternative to string creation loop</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>12810801</td>\n",
       "      <td>2012-10-10 01:43:11</td>\n",
       "      <td>1</td>\n",
       "      <td>835</td>\n",
       "      <td>Union all type query with python pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dantes_419</td>\n",
       "      <td>119.0</td>\n",
       "      <td>dantes_419</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>12979568</td>\n",
       "      <td>2012-10-19 17:41:14</td>\n",
       "      <td>0</td>\n",
       "      <td>447</td>\n",
       "      <td>basic plotting with pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abhi</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>Abhi</td>\n",
       "      <td>1824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>13013351</td>\n",
       "      <td>2012-10-22 14:17:47</td>\n",
       "      <td>2</td>\n",
       "      <td>1689</td>\n",
       "      <td>Pandas DataFrame with MultiIndex: efficient wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Einar</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>Einar</td>\n",
       "      <td>1561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>13261691</td>\n",
       "      <td>2012-11-07 00:46:05</td>\n",
       "      <td>4</td>\n",
       "      <td>358</td>\n",
       "      <td>understanding MultiIndex</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Calvin Cheng</td>\n",
       "      <td>16132.0</td>\n",
       "      <td>Calvin Cheng</td>\n",
       "      <td>16132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>13576164</td>\n",
       "      <td>2012-11-27 01:40:07</td>\n",
       "      <td>3</td>\n",
       "      <td>3689</td>\n",
       "      <td>How to keep MultiIndex when using pandas merge</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>13628860</td>\n",
       "      <td>2012-11-29 15:15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>637</td>\n",
       "      <td>AttributeError when using numpy.logical_and wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>durden2.0</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>durden2.0</td>\n",
       "      <td>2784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>13924801</td>\n",
       "      <td>2012-12-18 01:01:44</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>ignoring hierarchical index during matrix oper...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>dmvianna</td>\n",
       "      <td>5535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>13965036</td>\n",
       "      <td>2012-12-20 03:51:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1603</td>\n",
       "      <td>Dataframe merge creates duplicate records in p...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user1917577</td>\n",
       "      <td>21.0</td>\n",
       "      <td>user1917577</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>13980516</td>\n",
       "      <td>2012-12-20 21:11:31</td>\n",
       "      <td>-1</td>\n",
       "      <td>368</td>\n",
       "      <td>Issues in printing time series graph from pand...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nom-mon-ir</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>nom-mon-ir</td>\n",
       "      <td>1538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>14225676</td>\n",
       "      <td>2013-01-08 23:12:25</td>\n",
       "      <td>44</td>\n",
       "      <td>26526</td>\n",
       "      <td>Save list of DataFrames to multisheet Excel sp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "      <td>Andy Hayden</td>\n",
       "      <td>131029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>14334898</td>\n",
       "      <td>2013-01-15 09:45:25</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>Maximum number of dependencies in pandas ols?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wiseveri</td>\n",
       "      <td>131.0</td>\n",
       "      <td>wiseveri</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53712</th>\n",
       "      <td>46584622</td>\n",
       "      <td>2017-10-05 11:35:19</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>Fitting a curve while updating a plot using th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Amin Kiany</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Amin Kiany</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53727</th>\n",
       "      <td>47018911</td>\n",
       "      <td>2017-10-30 15:27:50</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Create new dataframe columns from old datafram...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gabriela Catalina</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Gabriela Catalina</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53749</th>\n",
       "      <td>46552587</td>\n",
       "      <td>2017-10-03 20:08:16</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>How can i create a ruleset to assign values to...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suhaib Qazi</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Suhaib Qazi</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53768</th>\n",
       "      <td>46575932</td>\n",
       "      <td>2017-10-05 00:02:15</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>How to iterate over a pandas dataframe while r...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>karakumy</td>\n",
       "      <td>18.0</td>\n",
       "      <td>karakumy</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53968</th>\n",
       "      <td>46943954</td>\n",
       "      <td>2017-10-26 00:21:39</td>\n",
       "      <td>-1</td>\n",
       "      <td>22</td>\n",
       "      <td>Joining dataframe by index. but no data on out...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>subash707</td>\n",
       "      <td>15.0</td>\n",
       "      <td>subash707</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54059</th>\n",
       "      <td>47058412</td>\n",
       "      <td>2017-11-01 15:34:25</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>New column as function result in pandas datafr...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eszter</td>\n",
       "      <td>8.0</td>\n",
       "      <td>eszter</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54078</th>\n",
       "      <td>47178632</td>\n",
       "      <td>2017-11-08 11:32:03</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>How to parse uploaded Excel file?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruipacheco</td>\n",
       "      <td>3547.0</td>\n",
       "      <td>ruipacheco</td>\n",
       "      <td>3547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54176</th>\n",
       "      <td>47191791</td>\n",
       "      <td>2017-11-09 00:00:33</td>\n",
       "      <td>-8</td>\n",
       "      <td>119</td>\n",
       "      <td>How do I filter an empty DataFrame and still k...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Henry Henrinson</td>\n",
       "      <td>2419.0</td>\n",
       "      <td>Henry Henrinson</td>\n",
       "      <td>2419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54273</th>\n",
       "      <td>47310814</td>\n",
       "      <td>2017-11-15 15:08:06</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Pandas to_datetime loses timezone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matthias</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>Matthias</td>\n",
       "      <td>1614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54283</th>\n",
       "      <td>47189212</td>\n",
       "      <td>2017-11-08 20:38:22</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>pandas count unique if condition true</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Robert</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54373</th>\n",
       "      <td>47152691</td>\n",
       "      <td>2017-11-07 08:00:28</td>\n",
       "      <td>51</td>\n",
       "      <td>694</td>\n",
       "      <td>How to pivot a dataframe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54380</th>\n",
       "      <td>47335519</td>\n",
       "      <td>2017-11-16 17:13:40</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>AttributeError: 'PyxImporter' object has no at...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Knifa</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Knifa</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54510</th>\n",
       "      <td>47395944</td>\n",
       "      <td>2017-11-20 15:51:30</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>SettingWithCopyWarning &amp; Hidden Chaining</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chocol8milkman</td>\n",
       "      <td>126.0</td>\n",
       "      <td>chocol8milkman</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54641</th>\n",
       "      <td>47155431</td>\n",
       "      <td>2017-11-07 10:22:12</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Pyarrow from_pandas crashes the interpreter wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adonis</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>Adonis</td>\n",
       "      <td>2215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54666</th>\n",
       "      <td>47477789</td>\n",
       "      <td>2017-11-24 17:24:30</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Pandas concat and OHLC issue</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ajsp</td>\n",
       "      <td>506.0</td>\n",
       "      <td>ajsp</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54697</th>\n",
       "      <td>47376786</td>\n",
       "      <td>2017-11-19 12:21:23</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>python dask dataframe splitting column of tupl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>captain shai</td>\n",
       "      <td>387.0</td>\n",
       "      <td>captain shai</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54792</th>\n",
       "      <td>47132523</td>\n",
       "      <td>2017-11-06 08:23:11</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>Pandas inconsistency with regex \".\" dot metach...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54887</th>\n",
       "      <td>47453050</td>\n",
       "      <td>2017-11-23 10:19:51</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>How to write data of type DataFrame using asks...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aurora_Titanium</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Aurora_Titanium</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54930</th>\n",
       "      <td>47254811</td>\n",
       "      <td>2017-11-12 22:39:32</td>\n",
       "      <td>-3</td>\n",
       "      <td>52</td>\n",
       "      <td>TypeError: len() of unsized object when slicin...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>durbachit</td>\n",
       "      <td>506.0</td>\n",
       "      <td>durbachit</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54999</th>\n",
       "      <td>47116400</td>\n",
       "      <td>2017-11-04 22:50:02</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Parsing py2neo paths into Pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joseph Berry</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Joseph Berry</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55195</th>\n",
       "      <td>47373969</td>\n",
       "      <td>2017-11-19 05:22:24</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Pandas: how to use a function dictionary to as...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artem Yevtushenko</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Artem Yevtushenko</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55377</th>\n",
       "      <td>47529906</td>\n",
       "      <td>2017-11-28 10:59:38</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>Pandas \"read_sql\" UnicodeDecodeError</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ladenkov Vladislav</td>\n",
       "      <td>336.0</td>\n",
       "      <td>Ladenkov Vladislav</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55454</th>\n",
       "      <td>47211319</td>\n",
       "      <td>2017-11-09 20:52:15</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>How To Pull Data From the Adwords API and put ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Christopher_M</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Christopher_M</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55466</th>\n",
       "      <td>47209431</td>\n",
       "      <td>2017-11-09 18:48:45</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Pandas dataframes and PyCharm IntelliSense</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blake</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Blake</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55689</th>\n",
       "      <td>47455323</td>\n",
       "      <td>2017-11-23 12:11:59</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>Weird behavior with datetime: error: time data...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toutsos</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Toutsos</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55767</th>\n",
       "      <td>47419823</td>\n",
       "      <td>2017-11-21 18:06:38</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>Tring to load csv file in Pandas using dataframe</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SaishB93</td>\n",
       "      <td>18.0</td>\n",
       "      <td>SaishB93</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55777</th>\n",
       "      <td>47350412</td>\n",
       "      <td>2017-11-17 12:12:51</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Using .agg in pandas returns 'list object has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nord112</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nord112</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55781</th>\n",
       "      <td>47170051</td>\n",
       "      <td>2017-11-08 01:21:47</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>How can I use a list comprehension to set colors?</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>solub</td>\n",
       "      <td>79.0</td>\n",
       "      <td>solub</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55987</th>\n",
       "      <td>47134254</td>\n",
       "      <td>2017-11-06 10:01:27</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>Merging list elements into one list of datafra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hall</td>\n",
       "      <td>15.0</td>\n",
       "      <td>hall</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56175</th>\n",
       "      <td>47354844</td>\n",
       "      <td>2017-11-17 16:10:26</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Calculating cummulative returns mid-year to mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chris</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         creationdate  score  viewcount  \\\n",
       "10      8273092  2011-11-25 18:39:02      1       2333   \n",
       "33      9721429  2012-03-15 14:08:31      9       5732   \n",
       "58     10020591  2012-04-04 23:17:23     21      20171   \n",
       "68     10175068  2012-04-16 13:27:44     15       7501   \n",
       "74     10264739  2012-04-22 02:35:06      9       2362   \n",
       "84     10475488  2012-05-07 00:38:47      5       2263   \n",
       "114    10771745  2012-05-27 04:53:45      0       1146   \n",
       "169    11264307  2012-06-29 15:09:28      9       7436   \n",
       "195    11418192  2012-07-10 16:56:37     42      24109   \n",
       "239    11762815  2012-08-01 15:41:19      6       2945   \n",
       "247    11824341  2012-08-06 07:47:34      0       1558   \n",
       "249    11848578  2012-08-07 14:50:42      1        452   \n",
       "320    12203901  2012-08-30 19:15:56     13       7032   \n",
       "346    12329853  2012-09-08 10:16:04     11      36312   \n",
       "357    12383436  2012-09-12 07:47:20      4       1593   \n",
       "398    12569730  2012-09-24 17:11:53     31       7160   \n",
       "412    12641606  2012-09-28 14:06:39      0       1341   \n",
       "414    12647811  2012-09-28 21:46:38      1        489   \n",
       "426    12720159  2012-10-04 04:10:11      0        155   \n",
       "434    12810801  2012-10-10 01:43:11      1        835   \n",
       "465    12979568  2012-10-19 17:41:14      0        447   \n",
       "473    13013351  2012-10-22 14:17:47      2       1689   \n",
       "547    13261691  2012-11-07 00:46:05      4        358   \n",
       "619    13576164  2012-11-27 01:40:07      3       3689   \n",
       "631    13628860  2012-11-29 15:15:15      0        637   \n",
       "701    13924801  2012-12-18 01:01:44      1         65   \n",
       "718    13965036  2012-12-20 03:51:52      1       1603   \n",
       "723    13980516  2012-12-20 21:11:31     -1        368   \n",
       "794    14225676  2013-01-08 23:12:25     44      26526   \n",
       "832    14334898  2013-01-15 09:45:25      1         83   \n",
       "...         ...                  ...    ...        ...   \n",
       "53712  46584622  2017-10-05 11:35:19      1         87   \n",
       "53727  47018911  2017-10-30 15:27:50      1         35   \n",
       "53749  46552587  2017-10-03 20:08:16      2         54   \n",
       "53768  46575932  2017-10-05 00:02:15      2         70   \n",
       "53968  46943954  2017-10-26 00:21:39     -1         22   \n",
       "54059  47058412  2017-11-01 15:34:25      0         33   \n",
       "54078  47178632  2017-11-08 11:32:03      0         30   \n",
       "54176  47191791  2017-11-09 00:00:33     -8        119   \n",
       "54273  47310814  2017-11-15 15:08:06      1         35   \n",
       "54283  47189212  2017-11-08 20:38:22      0         43   \n",
       "54373  47152691  2017-11-07 08:00:28     51        694   \n",
       "54380  47335519  2017-11-16 17:13:40      1         62   \n",
       "54510  47395944  2017-11-20 15:51:30      0         16   \n",
       "54641  47155431  2017-11-07 10:22:12      0         42   \n",
       "54666  47477789  2017-11-24 17:24:30      0         21   \n",
       "54697  47376786  2017-11-19 12:21:23      1         70   \n",
       "54792  47132523  2017-11-06 08:23:11      2         44   \n",
       "54887  47453050  2017-11-23 10:19:51      1         26   \n",
       "54930  47254811  2017-11-12 22:39:32     -3         52   \n",
       "54999  47116400  2017-11-04 22:50:02      0         24   \n",
       "55195  47373969  2017-11-19 05:22:24      0         25   \n",
       "55377  47529906  2017-11-28 10:59:38      2         33   \n",
       "55454  47211319  2017-11-09 20:52:15      1         73   \n",
       "55466  47209431  2017-11-09 18:48:45      1         22   \n",
       "55689  47455323  2017-11-23 12:11:59      1         41   \n",
       "55767  47419823  2017-11-21 18:06:38      0         35   \n",
       "55777  47350412  2017-11-17 12:12:51      0         40   \n",
       "55781  47170051  2017-11-08 01:21:47      1        100   \n",
       "55987  47134254  2017-11-06 10:01:27      0         62   \n",
       "56175  47354844  2017-11-17 16:10:26      0         48   \n",
       "\n",
       "                                                   title  answercount  \\\n",
       "10                         python: pandas install errors            2   \n",
       "33     How do I read a fix width format text file in ...            4   \n",
       "58     How to resample a dataframe with different fun...            4   \n",
       "68     Select data at a particular level from a Multi...            2   \n",
       "74     major memory problems reading in a csv file us...            3   \n",
       "84     Calculating crossing (intercept) points of a S...            1   \n",
       "114    Removing duplicates from dataframe with index ...            1   \n",
       "169    Adding levels to MultiIndex, removing without ...            1   \n",
       "195          pandas: complex filter on rows of DataFrame            4   \n",
       "239    How to resample a python pandas TimeSeries con...            2   \n",
       "247                             Pandas: date_range error            5   \n",
       "249                          Pandas messing up dataframe            2   \n",
       "320    pandas crashes on repeated DataFrame.reset_ind...            1   \n",
       "346             How to rearrange Pandas column sequence?            6   \n",
       "357    Access Pandas Series item with dot notation li...            2   \n",
       "398    Sum all columns with a wildcard name search us...            2   \n",
       "412        Pandas: sorting numbers within text by column            3   \n",
       "414          Swap cells strings from 2 dataframe columns            3   \n",
       "426           pandas alternative to string creation loop            1   \n",
       "434              Union all type query with python pandas            1   \n",
       "465                           basic plotting with pandas            1   \n",
       "473    Pandas DataFrame with MultiIndex: efficient wa...            1   \n",
       "547                             understanding MultiIndex            2   \n",
       "619       How to keep MultiIndex when using pandas merge            1   \n",
       "631    AttributeError when using numpy.logical_and wi...            1   \n",
       "701    ignoring hierarchical index during matrix oper...            1   \n",
       "718    Dataframe merge creates duplicate records in p...            2   \n",
       "723    Issues in printing time series graph from pand...            1   \n",
       "794    Save list of DataFrames to multisheet Excel sp...            1   \n",
       "832        Maximum number of dependencies in pandas ols?            1   \n",
       "...                                                  ...          ...   \n",
       "53712  Fitting a curve while updating a plot using th...            1   \n",
       "53727  Create new dataframe columns from old datafram...            1   \n",
       "53749  How can i create a ruleset to assign values to...            2   \n",
       "53768  How to iterate over a pandas dataframe while r...            3   \n",
       "53968  Joining dataframe by index. but no data on out...            1   \n",
       "54059  New column as function result in pandas datafr...            1   \n",
       "54078                  How to parse uploaded Excel file?            1   \n",
       "54176  How do I filter an empty DataFrame and still k...            3   \n",
       "54273                  Pandas to_datetime loses timezone            1   \n",
       "54283              pandas count unique if condition true            1   \n",
       "54373                           How to pivot a dataframe            1   \n",
       "54380  AttributeError: 'PyxImporter' object has no at...            1   \n",
       "54510           SettingWithCopyWarning & Hidden Chaining            1   \n",
       "54641  Pyarrow from_pandas crashes the interpreter wh...            1   \n",
       "54666                       Pandas concat and OHLC issue            1   \n",
       "54697  python dask dataframe splitting column of tupl...            1   \n",
       "54792  Pandas inconsistency with regex \".\" dot metach...            1   \n",
       "54887  How to write data of type DataFrame using asks...            1   \n",
       "54930  TypeError: len() of unsized object when slicin...            1   \n",
       "54999                   Parsing py2neo paths into Pandas            1   \n",
       "55195  Pandas: how to use a function dictionary to as...            1   \n",
       "55377               Pandas \"read_sql\" UnicodeDecodeError            1   \n",
       "55454  How To Pull Data From the Adwords API and put ...            1   \n",
       "55466         Pandas dataframes and PyCharm IntelliSense            1   \n",
       "55689  Weird behavior with datetime: error: time data...            1   \n",
       "55767   Tring to load csv file in Pandas using dataframe            1   \n",
       "55777  Using .agg in pandas returns 'list object has ...            1   \n",
       "55781  How can I use a list comprehension to set colors?            1   \n",
       "55987  Merging list elements into one list of datafra...            1   \n",
       "56175  Calculating cummulative returns mid-year to mi...            1   \n",
       "\n",
       "       commentcount  favoritecount          quest_name  quest_rep  \\\n",
       "10                0            NaN          codingknob     2279.0   \n",
       "33                2            NaN         user1234440     3369.0   \n",
       "58                0           15.0                 bmu    17129.0   \n",
       "68                3            5.0              elyase    19551.0   \n",
       "74                2            7.0            vgoklani     1752.0   \n",
       "84                1            3.0           dailyglen      460.0   \n",
       "114               2            1.0           dailyglen      460.0   \n",
       "169               0            4.0            Arthur G      987.0   \n",
       "195               0            6.0          duckworthd     4733.0   \n",
       "239               1            NaN                 THM      305.0   \n",
       "247               2            NaN                scry      781.0   \n",
       "249               3            NaN         user1569050     2519.0   \n",
       "320               0            NaN                 Abe     5182.0   \n",
       "346               0            4.0              bigbug     7865.0   \n",
       "357               0            1.0                 PhE     1988.0   \n",
       "398               4            6.0               jbssm     2620.0   \n",
       "412               0            NaN                fred     2342.0   \n",
       "414               1            0.0                fred     2342.0   \n",
       "426               2            NaN            dmvianna     5535.0   \n",
       "434               0            NaN          dantes_419      119.0   \n",
       "465               3            NaN                Abhi     1824.0   \n",
       "473               0            NaN               Einar     1561.0   \n",
       "547               0            2.0        Calvin Cheng    16132.0   \n",
       "619               0            1.0            dmvianna     5535.0   \n",
       "631               5            NaN           durden2.0     2784.0   \n",
       "701               0            NaN            dmvianna     5535.0   \n",
       "718               4            NaN         user1917577       21.0   \n",
       "723               2            NaN          nom-mon-ir     1538.0   \n",
       "794               0           18.0         Andy Hayden   131029.0   \n",
       "832               0            NaN            wiseveri      131.0   \n",
       "...             ...            ...                 ...        ...   \n",
       "53712             2            0.0          Amin Kiany        6.0   \n",
       "53727             4            NaN   Gabriela Catalina       20.0   \n",
       "53749             0            NaN         Suhaib Qazi       21.0   \n",
       "53768             0            1.0            karakumy       18.0   \n",
       "53968             8            1.0           subash707       15.0   \n",
       "54059             4            NaN              eszter        8.0   \n",
       "54078             2            NaN          ruipacheco     3547.0   \n",
       "54176             1            NaN     Henry Henrinson     2419.0   \n",
       "54273             0            NaN            Matthias     1614.0   \n",
       "54283             0            NaN              Robert        8.0   \n",
       "54373             0           32.0          piRSquared   102658.0   \n",
       "54380             5            NaN               Knifa      185.0   \n",
       "54510             3            NaN      chocol8milkman      126.0   \n",
       "54641             3            NaN              Adonis     2215.0   \n",
       "54666             2            NaN                ajsp      506.0   \n",
       "54697             0            NaN        captain shai      387.0   \n",
       "54792             0            1.0           cs    51675.0   \n",
       "54887             0            NaN     Aurora_Titanium      184.0   \n",
       "54930            12            NaN           durbachit      506.0   \n",
       "54999             0            NaN        Joseph Berry       83.0   \n",
       "55195             0            NaN   Artem Yevtushenko       86.0   \n",
       "55377             2            NaN  Ladenkov Vladislav      336.0   \n",
       "55454             0            1.0       Christopher_M       43.0   \n",
       "55466             0            NaN               Blake      151.0   \n",
       "55689             3            NaN             Toutsos       25.0   \n",
       "55767             3            NaN            SaishB93       18.0   \n",
       "55777             4            NaN             Nord112        3.0   \n",
       "55781             8            1.0               solub       79.0   \n",
       "55987             0            NaN                hall       15.0   \n",
       "56175             0            NaN               Chris       13.0   \n",
       "\n",
       "                 ans_name   ans_rep  \n",
       "10             codingknob    2279.0  \n",
       "33            user1234440    3369.0  \n",
       "58                    bmu   17129.0  \n",
       "68                 elyase   19551.0  \n",
       "74               vgoklani    1752.0  \n",
       "84              dailyglen     460.0  \n",
       "114             dailyglen     460.0  \n",
       "169              Arthur G     987.0  \n",
       "195            duckworthd    4733.0  \n",
       "239                   THM     305.0  \n",
       "247                  scry     781.0  \n",
       "249           user1569050    2519.0  \n",
       "320                   Abe    5182.0  \n",
       "346                bigbug    7865.0  \n",
       "357                   PhE    1988.0  \n",
       "398                 jbssm    2620.0  \n",
       "412                  fred    2342.0  \n",
       "414                  fred    2342.0  \n",
       "426              dmvianna    5535.0  \n",
       "434            dantes_419     119.0  \n",
       "465                  Abhi    1824.0  \n",
       "473                 Einar    1561.0  \n",
       "547          Calvin Cheng   16132.0  \n",
       "619              dmvianna    5535.0  \n",
       "631             durden2.0    2784.0  \n",
       "701              dmvianna    5535.0  \n",
       "718           user1917577      21.0  \n",
       "723            nom-mon-ir    1538.0  \n",
       "794           Andy Hayden  131029.0  \n",
       "832              wiseveri     131.0  \n",
       "...                   ...       ...  \n",
       "53712          Amin Kiany       6.0  \n",
       "53727   Gabriela Catalina      20.0  \n",
       "53749         Suhaib Qazi      21.0  \n",
       "53768            karakumy      18.0  \n",
       "53968           subash707      15.0  \n",
       "54059              eszter       8.0  \n",
       "54078          ruipacheco    3547.0  \n",
       "54176     Henry Henrinson    2419.0  \n",
       "54273            Matthias    1614.0  \n",
       "54283              Robert       8.0  \n",
       "54373          piRSquared  102658.0  \n",
       "54380               Knifa     185.0  \n",
       "54510      chocol8milkman     126.0  \n",
       "54641              Adonis    2215.0  \n",
       "54666                ajsp     506.0  \n",
       "54697        captain shai     387.0  \n",
       "54792           cs   51675.0  \n",
       "54887     Aurora_Titanium     184.0  \n",
       "54930           durbachit     506.0  \n",
       "54999        Joseph Berry      83.0  \n",
       "55195   Artem Yevtushenko      86.0  \n",
       "55377  Ladenkov Vladislav     336.0  \n",
       "55454       Christopher_M      43.0  \n",
       "55466               Blake     151.0  \n",
       "55689             Toutsos      25.0  \n",
       "55767            SaishB93      18.0  \n",
       "55777             Nord112       3.0  \n",
       "55781               solub      79.0  \n",
       "55987                hall      15.0  \n",
       "56175               Chris      13.0  \n",
       "\n",
       "[1512 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[so['quest_name'] == so['ans_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions that don't have an accepted answer, but have a score of more than 100</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, creationdate, score, viewcount, title, answercount, commentcount, favoritecount, quest_name, quest_rep, ans_name, ans_rep]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[so['ans_name'].isnull() & so['score'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions where the reputation of the person asking the question is higher than the person answering it. Then find the percentage of times this happens</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id         creationdate  score  viewcount  \\\n",
      "26      9588331  2012-03-06 17:01:47     22      10038   \n",
      "51      9962114  2012-04-01 05:25:20      9       8079   \n",
      "99     10636024  2012-05-17 12:48:00     36      30386   \n",
      "101    10671227  2012-05-20 06:14:57      0        473   \n",
      "112    10760364  2012-05-25 19:33:39      8       2977   \n",
      "123    10867028  2012-06-03 00:38:37     28      25115   \n",
      "134    11004088  2012-06-12 20:11:53      5       2008   \n",
      "137    11015974  2012-06-13 13:32:55      0        546   \n",
      "182    11348183  2012-07-05 15:59:54     18      26272   \n",
      "211    11586989  2012-07-20 21:11:28      8       9161   \n",
      "218    11621165  2012-07-23 21:57:01      9      19512   \n",
      "221    11640243  2012-07-24 22:30:16     34      18986   \n",
      "255    11885916  2012-08-09 14:41:05      7        861   \n",
      "259    11918342  2012-08-11 23:01:25      3       4829   \n",
      "284    12047418  2012-08-21 01:41:25      3      19551   \n",
      "311    12183432  2012-08-29 17:30:24      3       2285   \n",
      "316    12190874  2012-08-30 06:12:46     59      61706   \n",
      "318    12200693  2012-08-30 15:45:26     36      31779   \n",
      "322    12217960  2012-08-31 15:00:12      5        992   \n",
      "331    12255179  2012-09-03 23:49:01      1       1212   \n",
      "333    12269158  2012-09-04 18:14:35      2       4120   \n",
      "345    12326641  2012-09-07 23:27:20      4        998   \n",
      "352    12370349  2012-09-11 13:02:00      1        660   \n",
      "356    12382197  2012-09-12 06:16:15      1        170   \n",
      "358    12389898  2012-09-12 13:58:12     23      20817   \n",
      "361    12393387  2012-09-12 17:23:17      2       2000   \n",
      "362    12406162  2012-09-13 12:23:23     17      10715   \n",
      "370    12425602  2012-09-14 13:29:30      2       1988   \n",
      "372    12429279  2012-09-14 17:28:29      0        261   \n",
      "374    12433076  2012-09-14 23:06:15     38      87134   \n",
      "...         ...                  ...    ...        ...   \n",
      "54500  47450931  2017-11-23 08:38:50      0         13   \n",
      "54517  47170923  2017-11-08 03:05:09      0         30   \n",
      "54615  47207713  2017-11-09 17:06:18      0         60   \n",
      "54621  47160992  2017-11-07 14:59:13      2         48   \n",
      "54639  47388570  2017-11-20 09:20:48      0         41   \n",
      "54680  47442778  2017-11-22 19:45:04      0         38   \n",
      "54722  47459464  2017-11-23 16:02:05      0         32   \n",
      "54746  47440270  2017-11-22 17:03:55     -1         49   \n",
      "54770  47536129  2017-11-28 16:13:45      0         29   \n",
      "54787  47135742  2017-11-06 11:18:21      2         62   \n",
      "54788  47299082  2017-11-15 03:53:24      0         42   \n",
      "54791  47304847  2017-11-15 10:22:57      2         47   \n",
      "54813  47442581  2017-11-22 19:33:45      0         17   \n",
      "54823  47320572  2017-11-16 02:29:37      0         34   \n",
      "54829  47558374  2017-11-29 17:24:55      0         31   \n",
      "54885  47570593  2017-11-30 10:00:11      2         50   \n",
      "54944  47540944  2017-11-28 21:07:30      3         24   \n",
      "54952  47476809  2017-11-24 16:09:33      3        120   \n",
      "54975  47419659  2017-11-21 17:57:48     -1         52   \n",
      "55048  47515950  2017-11-27 16:48:35      0         22   \n",
      "55097  47480584  2017-11-24 22:09:52      0         58   \n",
      "55189  47594661  2017-12-01 13:38:53      1         16   \n",
      "55227  47377896  2017-11-19 14:21:25     -2         27   \n",
      "55259  47181073  2017-11-08 13:32:28      1         42   \n",
      "55329  47584876  2017-12-01 00:32:37      0         27   \n",
      "55334  47375680  2017-11-19 10:07:28      1         40   \n",
      "55359  47142887  2017-11-06 17:51:11      0         59   \n",
      "55449  47235829  2017-11-11 08:11:06      0         36   \n",
      "55484  47147749  2017-11-06 23:48:54      0         39   \n",
      "55815  47421139  2017-11-21 19:28:09      0         23   \n",
      "\n",
      "                                                   title  answercount  \\\n",
      "26                     Simple cross-tabulation in pandas            2   \n",
      "51                              Control Charts in Python            1   \n",
      "99     Python / Pandas - GUI for viewing a DataFrame ...           15   \n",
      "101                           Pandas FloatingPoint Error            1   \n",
      "112                  \"Zebra Tables\" in IPython Notebook?            3   \n",
      "123    Get pandas.read_csv to read empty values as em...            3   \n",
      "134                          indexing a pandas DataFrame            1   \n",
      "137     Vectorize High Frequency Data, Calculate Spread,            1   \n",
      "182    Pandas bar plot with specific colors and legen...            2   \n",
      "211    pandas, matplotlib, use dataframe index as axi...            3   \n",
      "218               Indexing a pandas dataframe by integer            1   \n",
      "221                          PANDAS plot multiple Y axes            1   \n",
      "255    Joining a Pandas series with a hierarchical in...            2   \n",
      "259                       Converting date/time in Pandas            3   \n",
      "284    How do I really use the `ix` method of a panda...            1   \n",
      "311    Typecasting before division (or any other math...            2   \n",
      "316                         Pandas: Sampling a DataFrame            5   \n",
      "318    Python Pandas How to assign groupby operation ...            5   \n",
      "322    How to replace&add the dataframe element by an...            4   \n",
      "331    numpy/pandas: How to convert a series of strin...            2   \n",
      "333    Python Pandas idiom for converting TimeSeries ...            1   \n",
      "345    Calculate speed from timestamped positions in ...            1   \n",
      "352    Reasoning about consecutive data points withou...            4   \n",
      "356    Generating a boolean mask indexing one array i...            3   \n",
      "358    Python Pandas: how to add a totally new column...            1   \n",
      "361    Python Pandas: How to broadcast an operation u...            3   \n",
      "362    KeyError when plotting a sliced pandas datafra...            3   \n",
      "370    Python package recommendation for data analysi...            2   \n",
      "372    Design strategy for managing and processing da...            1   \n",
      "374    Download history stock prices automatically fr...            4   \n",
      "...                                                  ...          ...   \n",
      "54500  Print pandas data frame for reproducible examp...            1   \n",
      "54517   Subset Dataframe for even split in column values            2   \n",
      "54615  python pandas: A value is trying to be set on ...            1   \n",
      "54621  pandas: how to write to an Excel sheet without...            1   \n",
      "54639  pandas dataframe to_csv works with sep='\\n' bu...            3   \n",
      "54680  Accuracy of learning algorithm drops after ave...            2   \n",
      "54722  Dividing a very large dataframe into n random ...            1   \n",
      "54746              Python: Removing backslash in string?            1   \n",
      "54770                Numpy equal to not working properly            1   \n",
      "54787  How to parse and evaluate a math expression wi...            2   \n",
      "54788  Individual plots worked but once added subplot...            2   \n",
      "54791       Custom pandas groupby on a list of intervals            2   \n",
      "54813                     Averaging a pivot table column            1   \n",
      "54823                          Pandas, groupby and count            1   \n",
      "54829  Django keeps adding ' character to first cell ...            2   \n",
      "54885  pandas: Get an average value of sales for a da...            1   \n",
      "54944  Python / Pandas - Merging on index with multip...            1   \n",
      "54952        Polar chart with limit and anomalous points            2   \n",
      "54975                       Pandas filtering not working            2   \n",
      "55048  Can't get ride of the index column of my excel...            1   \n",
      "55097     Calculate mean numpy array in pandas DataFrame            1   \n",
      "55189  Add a column from a csv file in a dataframe in...            1   \n",
      "55227  correcting data and replace the new data in pa...            1   \n",
      "55259                            Weighted average pandas            2   \n",
      "55329  Plotting percentage of totals with pandas grou...            2   \n",
      "55334                        Counter for words and emoji            2   \n",
      "55359  How to create a heatmap with discrete color le...            2   \n",
      "55449  BeautifulSoup identifying only few elements in...            2   \n",
      "55484                  Data calculation in pandas python            1   \n",
      "55815  How to get some rows from a DataFrame to build...            1   \n",
      "\n",
      "       commentcount  favoritecount               quest_name  quest_rep  \\\n",
      "26                3            5.0             Jon Clements    85944.0   \n",
      "51                0            3.0                     John     8807.0   \n",
      "99                6           27.0                   Ross R     1562.0   \n",
      "101               5            NaN                  tshauck     5957.0   \n",
      "112               0            4.0                  JD Long    33098.0   \n",
      "123               0            5.0                 BrenBarn   136870.0   \n",
      "134               0            1.0                   elyase    19551.0   \n",
      "137               4            NaN                   Andrew      248.0   \n",
      "182               3            7.0                    Shane    69835.0   \n",
      "211               0            4.0                      tbc      886.0   \n",
      "218               0            9.0                   SiggyF    10726.0   \n",
      "221               0           11.0            Joran Beasley    63361.0   \n",
      "255               0            3.0                  JD Long    33098.0   \n",
      "259               1            1.0                 vgoklani     1752.0   \n",
      "284               0            4.0                   Paul H    22389.0   \n",
      "311               0            2.0                  Navneet     1791.0   \n",
      "316               1           24.0                  Blender   180189.0   \n",
      "318               3           20.0                      ely    26102.0   \n",
      "322               2            1.0                   bigbug     7865.0   \n",
      "331               0            NaN                      Abe     5182.0   \n",
      "333               0            NaN                      ely    26102.0   \n",
      "345               0            1.0              heltonbiker    11594.0   \n",
      "352               2            0.0                  codeape    62467.0   \n",
      "356               4            NaN            Daniel Velkov    16272.0   \n",
      "358               3           10.0                      ely    26102.0   \n",
      "361               4            NaN                      ely    26102.0   \n",
      "362               1            3.0                    joris    44714.0   \n",
      "370               3            1.0              user1491915      622.0   \n",
      "372               0            NaN              heltonbiker    11594.0   \n",
      "374               1           43.0                      Bob     2037.0   \n",
      "...             ...            ...                      ...        ...   \n",
      "54500             0            NaN  Yehoshaphat Schellekens      940.0   \n",
      "54517             2            NaN              user3476463      428.0   \n",
      "54615            10            NaN               iamsterdam      456.0   \n",
      "54621             0            NaN     Pythonista anonymous     1018.0   \n",
      "54639             3            NaN                      Jan      436.0   \n",
      "54680             1            NaN                   Bolboa     2116.0   \n",
      "54722             4            NaN       Antonio Lpez Ruiz      312.0   \n",
      "54746             5            NaN              Christopher      178.0   \n",
      "54770            14            NaN                  Bharath    12877.0   \n",
      "54787             5            NaN                  ChesuCR     2679.0   \n",
      "54788             5            1.0               George Liu      871.0   \n",
      "54791             0            NaN                cs    51675.0   \n",
      "54813             0            NaN                   Stacey      688.0   \n",
      "54823             0            NaN            Alexander Yau     3286.0   \n",
      "54829             3            NaN               Davtho1983      538.0   \n",
      "54885             1            NaN                    Paddy      722.0   \n",
      "54944             7            NaN            abutremutante      857.0   \n",
      "54952             3            NaN                    Sotos    20502.0   \n",
      "54975             8            NaN                  LMGagne      234.0   \n",
      "55048             0            NaN                 Emixam23      608.0   \n",
      "55097             3            NaN                 yellow01      354.0   \n",
      "55189             0            0.0                 Andriana       39.0   \n",
      "55227             1            NaN                    armin       52.0   \n",
      "55259             3            NaN                     BERA      199.0   \n",
      "55329             0            NaN               Kelli-Jean      960.0   \n",
      "55334             0            NaN                sheldonzy     1033.0   \n",
      "55359             0            NaN              Dinosaurius     1718.0   \n",
      "55449             4            NaN              Akhil Reddy      221.0   \n",
      "55484             1            NaN               magicsword      317.0   \n",
      "55815             0            NaN             thomas2013ch       38.0   \n",
      "\n",
      "                   ans_name  ans_rep  \n",
      "26        Jeff Hammerbacher   3172.0  \n",
      "51              Josh Hemann    590.0  \n",
      "99              user1319128    555.0  \n",
      "101                  Karmel   2870.0  \n",
      "112                   minrk  22244.0  \n",
      "123            Wes McKinney  43310.0  \n",
      "134                  diliop   5952.0  \n",
      "137                 Pavel T    154.0  \n",
      "182            Wes McKinney  43310.0  \n",
      "211                     PJW    331.0  \n",
      "218      Michelle Lynn Gill    786.0  \n",
      "221               Chang She   8528.0  \n",
      "255        Wouter Overmeire  20078.0  \n",
      "259                jdmarino    196.0  \n",
      "284        Wouter Overmeire  20078.0  \n",
      "311           Eero Aaltonen   1766.0  \n",
      "316        Wouter Overmeire  20078.0  \n",
      "318        Wouter Overmeire  20078.0  \n",
      "322                  Def_Os   2775.0  \n",
      "331         Henry Gomersall   4841.0  \n",
      "333               Chang She   8528.0  \n",
      "345               Chang She   8528.0  \n",
      "352               Pierre GM  12141.0  \n",
      "356               Pierre GM  12141.0  \n",
      "358               Chang She   8528.0  \n",
      "361                  Avaris  21067.0  \n",
      "362        Wouter Overmeire  20078.0  \n",
      "370          Thomas Vincent     73.0  \n",
      "372               Chang She   8528.0  \n",
      "374                  Joe C.   1405.0  \n",
      "...                     ...      ...  \n",
      "54500            David Dale    748.0  \n",
      "54517                jaguar     92.0  \n",
      "54615                Georgy     88.0  \n",
      "54621         patrickjlong1    524.0  \n",
      "54639        Tomohiro Egawa     46.0  \n",
      "54680              Harry_pb    625.0  \n",
      "54722             user32185    308.0  \n",
      "54746          DeathCamel57     72.0  \n",
      "54770          Brad Solomon   5113.0  \n",
      "54787                uuazed    524.0  \n",
      "54788                   Joe    174.0  \n",
      "54791               Bharath  12877.0  \n",
      "54813         Tasko Olevski    186.0  \n",
      "54823                   WNG   1935.0  \n",
      "54829                 Wayne     66.0  \n",
      "54885                  talz     26.0  \n",
      "54944              MisterJT     86.0  \n",
      "54952      Reblochon Masque   9784.0  \n",
      "54975                 Peter    146.0  \n",
      "55048           user8834780    134.0  \n",
      "55097                 dgumo    174.0  \n",
      "55189           GeneticsGuy     26.0  \n",
      "55227                  SCKU     36.0  \n",
      "55259  Martin Alexandersson    131.0  \n",
      "55329         offwhitelotus    412.0  \n",
      "55334                 con--    422.0  \n",
      "55359              akilat90    795.0  \n",
      "55449                  Siva     88.0  \n",
      "55484            datagarret     26.0  \n",
      "55815             madmapper     26.0  \n",
      "\n",
      "[2240 rows x 12 columns] 3.9717720486542074\n"
     ]
    }
   ],
   "source": [
    "rs = so[so['quest_rep'] > so['ans_rep']]\n",
    "perc = (len(rs)/len(so))*100\n",
    "print(rs,perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "<span  style=\"color:green; font-size:16px\">Find all the questions where the number of answers is between 5 and 10 inclusive, and the number of views is less than 1,000.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>13580875</td>\n",
       "      <td>2012-11-27 09:19:07</td>\n",
       "      <td>2</td>\n",
       "      <td>963</td>\n",
       "      <td>Running average / frequency of time series data?</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Prof. Falken</td>\n",
       "      <td>15061.0</td>\n",
       "      <td>Victor K</td>\n",
       "      <td>332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>14742893</td>\n",
       "      <td>2013-02-07 03:13:31</td>\n",
       "      <td>2</td>\n",
       "      <td>598</td>\n",
       "      <td>Interpolation Function</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eWizardII</td>\n",
       "      <td>886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>21315997</td>\n",
       "      <td>2014-01-23 18:02:57</td>\n",
       "      <td>2</td>\n",
       "      <td>716</td>\n",
       "      <td>Python Pandas vs R. Transformation Code Concis...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>user2684301</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>62248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>19892107</td>\n",
       "      <td>2013-11-10 16:28:50</td>\n",
       "      <td>5</td>\n",
       "      <td>385</td>\n",
       "      <td>Updating csv with data from a csv with differe...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OliverSteph</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>21040578</td>\n",
       "      <td>2014-01-10 09:33:09</td>\n",
       "      <td>-1</td>\n",
       "      <td>175</td>\n",
       "      <td>combining mutiple csv file</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user104853</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>27000092</td>\n",
       "      <td>2014-11-18 17:14:40</td>\n",
       "      <td>7</td>\n",
       "      <td>744</td>\n",
       "      <td>Count how many times each row is present in nu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Akavall</td>\n",
       "      <td>30059.0</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>42996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10525</th>\n",
       "      <td>29535163</td>\n",
       "      <td>2015-04-09 09:49:14</td>\n",
       "      <td>9</td>\n",
       "      <td>669</td>\n",
       "      <td>What dtype to use for money representation in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>userqwerty1</td>\n",
       "      <td>362.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10934</th>\n",
       "      <td>29407945</td>\n",
       "      <td>2015-04-02 08:04:51</td>\n",
       "      <td>8</td>\n",
       "      <td>997</td>\n",
       "      <td>Find and replace multiple values in python</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>blaz</td>\n",
       "      <td>945.0</td>\n",
       "      <td>Ashwini Chaudhary</td>\n",
       "      <td>154575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13789</th>\n",
       "      <td>30638568</td>\n",
       "      <td>2015-06-04 08:20:35</td>\n",
       "      <td>5</td>\n",
       "      <td>349</td>\n",
       "      <td>python if statement returns value error</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hb.klein</td>\n",
       "      <td>151.0</td>\n",
       "      <td>EdChum</td>\n",
       "      <td>124367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14219</th>\n",
       "      <td>32724146</td>\n",
       "      <td>2015-09-22 18:22:24</td>\n",
       "      <td>2</td>\n",
       "      <td>395</td>\n",
       "      <td>Replacing zero values in dataframe using anoth...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user308827</td>\n",
       "      <td>2529.0</td>\n",
       "      <td>EdChum</td>\n",
       "      <td>124367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>32988269</td>\n",
       "      <td>2015-10-07 09:12:04</td>\n",
       "      <td>5</td>\n",
       "      <td>889</td>\n",
       "      <td>Speedup MSD calculation in Python</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HadiM</td>\n",
       "      <td>173.0</td>\n",
       "      <td>thomasfermi</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14750</th>\n",
       "      <td>31872659</td>\n",
       "      <td>2015-08-07 08:07:41</td>\n",
       "      <td>0</td>\n",
       "      <td>740</td>\n",
       "      <td>Python &amp; Pandas: How to do conditional calcula...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cqcn1991</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>DeepSpace</td>\n",
       "      <td>23882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14891</th>\n",
       "      <td>32576398</td>\n",
       "      <td>2015-09-15 01:44:36</td>\n",
       "      <td>4</td>\n",
       "      <td>185</td>\n",
       "      <td>How to transform list of dictionaries with jag...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ben</td>\n",
       "      <td>4449.0</td>\n",
       "      <td>Ben</td>\n",
       "      <td>4449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16024</th>\n",
       "      <td>33407223</td>\n",
       "      <td>2015-10-29 06:21:06</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>Pandas Dataframe: count number of IDs based on...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sachin saxena</td>\n",
       "      <td>528.0</td>\n",
       "      <td>Zero</td>\n",
       "      <td>25935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16064</th>\n",
       "      <td>33134804</td>\n",
       "      <td>2015-10-14 20:17:36</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>Skip every specified line before importing to ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leb</td>\n",
       "      <td>6623.0</td>\n",
       "      <td>Padraic Cunningham</td>\n",
       "      <td>121352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>33531507</td>\n",
       "      <td>2015-11-04 20:36:08</td>\n",
       "      <td>3</td>\n",
       "      <td>908</td>\n",
       "      <td>reading a matrix and fetch row and column name...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gthm</td>\n",
       "      <td>605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17127</th>\n",
       "      <td>34297319</td>\n",
       "      <td>2015-12-15 19:02:14</td>\n",
       "      <td>5</td>\n",
       "      <td>918</td>\n",
       "      <td>Finding top N columns for each row in data frame</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Diego</td>\n",
       "      <td>20300.0</td>\n",
       "      <td>Padraic Cunningham</td>\n",
       "      <td>121352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18672</th>\n",
       "      <td>34759318</td>\n",
       "      <td>2016-01-13 05:52:52</td>\n",
       "      <td>2</td>\n",
       "      <td>210</td>\n",
       "      <td>Creating new column using output of if else st...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haimen</td>\n",
       "      <td>635.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18706</th>\n",
       "      <td>34616439</td>\n",
       "      <td>2016-01-05 16:24:11</td>\n",
       "      <td>8</td>\n",
       "      <td>417</td>\n",
       "      <td>Filtering pandas or numpy arrays for continuou...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pho</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Divakar</td>\n",
       "      <td>128094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18998</th>\n",
       "      <td>33750947</td>\n",
       "      <td>2015-11-17 07:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>grouping of dataframe find the count,sum on co...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Satya</td>\n",
       "      <td>882.0</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>39006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>34338693</td>\n",
       "      <td>2015-12-17 15:49:03</td>\n",
       "      <td>3</td>\n",
       "      <td>549</td>\n",
       "      <td>How to parse csv file and compute stats based ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thy</td>\n",
       "      <td>41.0</td>\n",
       "      <td>janrn</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20980</th>\n",
       "      <td>35329206</td>\n",
       "      <td>2016-02-11 01:25:41</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>Strip all characters from column header before...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stefano Potter</td>\n",
       "      <td>932.0</td>\n",
       "      <td>DSM</td>\n",
       "      <td>164692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21227</th>\n",
       "      <td>36072686</td>\n",
       "      <td>2016-03-17 22:17:17</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>If a string is present in the word, make it NA...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Observer</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21313</th>\n",
       "      <td>36431659</td>\n",
       "      <td>2016-04-05 16:09:46</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>filter numpy array of datetimes by frequency o...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WRJ</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21404</th>\n",
       "      <td>36148386</td>\n",
       "      <td>2016-03-22 07:24:39</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>check if one string contains another substring...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M PAUL</td>\n",
       "      <td>528.0</td>\n",
       "      <td>Kaustav Datta</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21431</th>\n",
       "      <td>35344622</td>\n",
       "      <td>2016-02-11 16:21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>calculate duplicate average python</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Condo_programmer</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Goyo</td>\n",
       "      <td>5275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>35212206</td>\n",
       "      <td>2016-02-04 21:43:11</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>How to fill an array \"column\" with calculated ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DyTech</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21462</th>\n",
       "      <td>36382248</td>\n",
       "      <td>2016-04-03 06:21:33</td>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>How to find rows with column values having a p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satya</td>\n",
       "      <td>882.0</td>\n",
       "      <td>Sergey Bushmanov</td>\n",
       "      <td>2279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22320</th>\n",
       "      <td>36926119</td>\n",
       "      <td>2016-04-28 21:51:14</td>\n",
       "      <td>9</td>\n",
       "      <td>392</td>\n",
       "      <td>Get date quantiles in pandas</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>37490717</td>\n",
       "      <td>2016-05-27 19:08:50</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>Pandas: apply operation to repetitive columns ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FooBar</td>\n",
       "      <td>5143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50452</th>\n",
       "      <td>46229738</td>\n",
       "      <td>2017-09-14 23:49:29</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>Adding rows based on previous condition in ano...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SalN85</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50580</th>\n",
       "      <td>46349345</td>\n",
       "      <td>2017-09-21 16:56:20</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Compare two columns and get unique values in p...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcos Santana</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Alexey Trofimov</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50615</th>\n",
       "      <td>46007571</td>\n",
       "      <td>2017-09-01 20:26:23</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>with python, select repeated elements longer t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jonathan Pacheco</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50704</th>\n",
       "      <td>46185965</td>\n",
       "      <td>2017-09-12 22:01:39</td>\n",
       "      <td>11</td>\n",
       "      <td>657</td>\n",
       "      <td>How can I map the headers to columns in pandas?</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sunny</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50735</th>\n",
       "      <td>46303356</td>\n",
       "      <td>2017-09-19 14:41:18</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>pandas - Count streak of values higher/lower t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bruno Vieira</td>\n",
       "      <td>32.0</td>\n",
       "      <td>benjwadams</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50803</th>\n",
       "      <td>46331210</td>\n",
       "      <td>2017-09-20 20:25:34</td>\n",
       "      <td>8</td>\n",
       "      <td>253</td>\n",
       "      <td>How to assign count of unique values to the re...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Doubt Dhanabalu</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Vaishali</td>\n",
       "      <td>10335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51148</th>\n",
       "      <td>46148302</td>\n",
       "      <td>2017-09-11 04:41:31</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>What is the best way to access values in a dat...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chrisckwong821</td>\n",
       "      <td>417.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>46281209</td>\n",
       "      <td>2017-09-18 13:59:48</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>Return All Values of Column A and Put them in ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EEPBAH</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Divakar</td>\n",
       "      <td>128094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51257</th>\n",
       "      <td>46201618</td>\n",
       "      <td>2017-09-13 15:37:03</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>Pandas: The best way to create new Frame by sp...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renton</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Zero</td>\n",
       "      <td>25935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51654</th>\n",
       "      <td>46870692</td>\n",
       "      <td>2017-10-22 05:09:30</td>\n",
       "      <td>8</td>\n",
       "      <td>555</td>\n",
       "      <td>How to find first local maximum for every group?</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>user1357015</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51798</th>\n",
       "      <td>46653647</td>\n",
       "      <td>2017-10-09 19:26:05</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "      <td>Pandas: filter on multiple columns</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M. K. Hunter</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51821</th>\n",
       "      <td>46912379</td>\n",
       "      <td>2017-10-24 13:53:38</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>DataFrame transpose from List</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josh</td>\n",
       "      <td>118.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51968</th>\n",
       "      <td>46655202</td>\n",
       "      <td>2017-10-09 21:24:37</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>Probability of a Pandas value</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Seano314</td>\n",
       "      <td>336.0</td>\n",
       "      <td>piRSquared</td>\n",
       "      <td>102658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52013</th>\n",
       "      <td>47061564</td>\n",
       "      <td>2017-11-01 18:40:36</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>How to create strings from dataframe columns e...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hernanavella</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Scott Boston</td>\n",
       "      <td>23611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52254</th>\n",
       "      <td>46898334</td>\n",
       "      <td>2017-10-23 20:52:59</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>How do I avoid a loop with Python/Pandas to bu...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GC123</td>\n",
       "      <td>40.0</td>\n",
       "      <td>GC123</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52273</th>\n",
       "      <td>47055259</td>\n",
       "      <td>2017-11-01 12:48:36</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>Python dict group and sum multiple values</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ajay Kumar</td>\n",
       "      <td>178.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52904</th>\n",
       "      <td>46958559</td>\n",
       "      <td>2017-10-26 15:44:10</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>Finding a maximum value in a dictionary, and d...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Altheman</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Yuriy Savchenko</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52967</th>\n",
       "      <td>46816226</td>\n",
       "      <td>2017-10-18 17:48:28</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>Selecting single values from pandas dataframe ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>edager</td>\n",
       "      <td>81.0</td>\n",
       "      <td>MaxU</td>\n",
       "      <td>83732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53088</th>\n",
       "      <td>46519539</td>\n",
       "      <td>2017-10-02 04:31:57</td>\n",
       "      <td>6</td>\n",
       "      <td>186</td>\n",
       "      <td>How to select all non-NaN columns and non-NaN ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fang</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Bharath</td>\n",
       "      <td>12877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53365</th>\n",
       "      <td>46697440</td>\n",
       "      <td>2017-10-11 20:57:28</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Add Virgula in front of each word</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rivaldo Hater</td>\n",
       "      <td>18.0</td>\n",
       "      <td>MedAli</td>\n",
       "      <td>5232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53418</th>\n",
       "      <td>46499582</td>\n",
       "      <td>2017-09-30 04:30:26</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>How to make list of list from dataframe pandas?</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Satrio Adi Prabowo</td>\n",
       "      <td>98.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53423</th>\n",
       "      <td>46585640</td>\n",
       "      <td>2017-10-05 12:28:22</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>Get one or more column values as a list from P...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pyd</td>\n",
       "      <td>416.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53433</th>\n",
       "      <td>47028601</td>\n",
       "      <td>2017-10-31 05:45:19</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>how to remove 0's in a datacolumn in a datafra...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pyd</td>\n",
       "      <td>416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>46557074</td>\n",
       "      <td>2017-10-04 04:33:51</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Grouping similar values in a dictionary</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ConstantLearner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jeremy McGibbon</td>\n",
       "      <td>1121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53983</th>\n",
       "      <td>46882557</td>\n",
       "      <td>2017-10-23 05:36:29</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>How to split columns faster in python?</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Xu</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Akshay Hegde</td>\n",
       "      <td>11362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54384</th>\n",
       "      <td>47542980</td>\n",
       "      <td>2017-11-29 00:05:31</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Pandas groupby - set of different values</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baron Yugovich</td>\n",
       "      <td>260.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54463</th>\n",
       "      <td>47334404</td>\n",
       "      <td>2017-11-16 16:16:03</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Empty DataFrame doesn't admit its empty</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legit Stack</td>\n",
       "      <td>402.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54475</th>\n",
       "      <td>47117982</td>\n",
       "      <td>2017-11-05 03:49:11</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>insert missing category for each group in pand...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>muon</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>cs</td>\n",
       "      <td>51675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55444</th>\n",
       "      <td>47213771</td>\n",
       "      <td>2017-11-10 00:13:38</td>\n",
       "      <td>1</td>\n",
       "      <td>247</td>\n",
       "      <td>column operation in csv [python]</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alex</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Bharath</td>\n",
       "      <td>12877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55879</th>\n",
       "      <td>47147414</td>\n",
       "      <td>2017-11-06 23:13:02</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>Filter Pandas Dataframe using an arbitrary num...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>speedyturkey</td>\n",
       "      <td>41.0</td>\n",
       "      <td>James</td>\n",
       "      <td>7279.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         creationdate  score  viewcount  \\\n",
       "620    13580875  2012-11-27 09:19:07      2        963   \n",
       "1316   14742893  2013-02-07 03:13:31      2        598   \n",
       "4816   21315997  2014-01-23 18:02:57      2        716   \n",
       "4958   19892107  2013-11-10 16:28:50      5        385   \n",
       "5339   21040578  2014-01-10 09:33:09     -1        175   \n",
       "8842   27000092  2014-11-18 17:14:40      7        744   \n",
       "10525  29535163  2015-04-09 09:49:14      9        669   \n",
       "10934  29407945  2015-04-02 08:04:51      8        997   \n",
       "13789  30638568  2015-06-04 08:20:35      5        349   \n",
       "14219  32724146  2015-09-22 18:22:24      2        395   \n",
       "14274  32988269  2015-10-07 09:12:04      5        889   \n",
       "14750  31872659  2015-08-07 08:07:41      0        740   \n",
       "14891  32576398  2015-09-15 01:44:36      4        185   \n",
       "16024  33407223  2015-10-29 06:21:06      3         95   \n",
       "16064  33134804  2015-10-14 20:17:36      2        559   \n",
       "17111  33531507  2015-11-04 20:36:08      3        908   \n",
       "17127  34297319  2015-12-15 19:02:14      5        918   \n",
       "18672  34759318  2016-01-13 05:52:52      2        210   \n",
       "18706  34616439  2016-01-05 16:24:11      8        417   \n",
       "18998  33750947  2015-11-17 07:00:31      0         83   \n",
       "19251  34338693  2015-12-17 15:49:03      3        549   \n",
       "20980  35329206  2016-02-11 01:25:41      2         91   \n",
       "21227  36072686  2016-03-17 22:17:17      0        113   \n",
       "21313  36431659  2016-04-05 16:09:46      0        134   \n",
       "21404  36148386  2016-03-22 07:24:39      0        374   \n",
       "21431  35344622  2016-02-11 16:21:30      1        143   \n",
       "21442  35212206  2016-02-04 21:43:11      0        149   \n",
       "21462  36382248  2016-04-03 06:21:33      1        314   \n",
       "22320  36926119  2016-04-28 21:51:14      9        392   \n",
       "22415  37490717  2016-05-27 19:08:50      3         96   \n",
       "...         ...                  ...    ...        ...   \n",
       "50452  46229738  2017-09-14 23:49:29      2         40   \n",
       "50580  46349345  2017-09-21 16:56:20      0         60   \n",
       "50615  46007571  2017-09-01 20:26:23      8        115   \n",
       "50704  46185965  2017-09-12 22:01:39     11        657   \n",
       "50735  46303356  2017-09-19 14:41:18      2        162   \n",
       "50803  46331210  2017-09-20 20:25:34      8        253   \n",
       "51148  46148302  2017-09-11 04:41:31      1         65   \n",
       "51198  46281209  2017-09-18 13:59:48      2         54   \n",
       "51257  46201618  2017-09-13 15:37:03      3         45   \n",
       "51654  46870692  2017-10-22 05:09:30      8        555   \n",
       "51798  46653647  2017-10-09 19:26:05      1        349   \n",
       "51821  46912379  2017-10-24 13:53:38      2         48   \n",
       "51968  46655202  2017-10-09 21:24:37      4         62   \n",
       "52013  47061564  2017-11-01 18:40:36      5         60   \n",
       "52254  46898334  2017-10-23 20:52:59      0         62   \n",
       "52273  47055259  2017-11-01 12:48:36      3         83   \n",
       "52904  46958559  2017-10-26 15:44:10      0         70   \n",
       "52967  46816226  2017-10-18 17:48:28      7        122   \n",
       "53088  46519539  2017-10-02 04:31:57      6        186   \n",
       "53365  46697440  2017-10-11 20:57:28      2         43   \n",
       "53418  46499582  2017-09-30 04:30:26      2         75   \n",
       "53423  46585640  2017-10-05 12:28:22      1         47   \n",
       "53433  47028601  2017-10-31 05:45:19      2         38   \n",
       "53752  46557074  2017-10-04 04:33:51      0         61   \n",
       "53983  46882557  2017-10-23 05:36:29      3         87   \n",
       "54384  47542980  2017-11-29 00:05:31      2         43   \n",
       "54463  47334404  2017-11-16 16:16:03      0         31   \n",
       "54475  47117982  2017-11-05 03:49:11      1         86   \n",
       "55444  47213771  2017-11-10 00:13:38      1        247   \n",
       "55879  47147414  2017-11-06 23:13:02      0         44   \n",
       "\n",
       "                                                   title  answercount  \\\n",
       "620     Running average / frequency of time series data?            5   \n",
       "1316                              Interpolation Function            5   \n",
       "4816   Python Pandas vs R. Transformation Code Concis...            5   \n",
       "4958   Updating csv with data from a csv with differe...            6   \n",
       "5339                          combining mutiple csv file            8   \n",
       "8842   Count how many times each row is present in nu...            5   \n",
       "10525  What dtype to use for money representation in ...            5   \n",
       "10934         Find and replace multiple values in python            9   \n",
       "13789            python if statement returns value error            5   \n",
       "14219  Replacing zero values in dataframe using anoth...            5   \n",
       "14274                  Speedup MSD calculation in Python            5   \n",
       "14750  Python & Pandas: How to do conditional calcula...            5   \n",
       "14891  How to transform list of dictionaries with jag...            5   \n",
       "16024  Pandas Dataframe: count number of IDs based on...            5   \n",
       "16064  Skip every specified line before importing to ...            5   \n",
       "17111  reading a matrix and fetch row and column name...            5   \n",
       "17127   Finding top N columns for each row in data frame            5   \n",
       "18672  Creating new column using output of if else st...            5   \n",
       "18706  Filtering pandas or numpy arrays for continuou...            5   \n",
       "18998  grouping of dataframe find the count,sum on co...            5   \n",
       "19251  How to parse csv file and compute stats based ...            5   \n",
       "20980  Strip all characters from column header before...            7   \n",
       "21227  If a string is present in the word, make it NA...            5   \n",
       "21313  filter numpy array of datetimes by frequency o...            5   \n",
       "21404  check if one string contains another substring...            5   \n",
       "21431                 calculate duplicate average python            5   \n",
       "21442  How to fill an array \"column\" with calculated ...            6   \n",
       "21462  How to find rows with column values having a p...            5   \n",
       "22320                       Get date quantiles in pandas            6   \n",
       "22415  Pandas: apply operation to repetitive columns ...            5   \n",
       "...                                                  ...          ...   \n",
       "50452  Adding rows based on previous condition in ano...            5   \n",
       "50580  Compare two columns and get unique values in p...            5   \n",
       "50615  with python, select repeated elements longer t...            5   \n",
       "50704    How can I map the headers to columns in pandas?            5   \n",
       "50735  pandas - Count streak of values higher/lower t...            5   \n",
       "50803  How to assign count of unique values to the re...            5   \n",
       "51148  What is the best way to access values in a dat...            5   \n",
       "51198  Return All Values of Column A and Put them in ...            7   \n",
       "51257  Pandas: The best way to create new Frame by sp...            5   \n",
       "51654   How to find first local maximum for every group?            5   \n",
       "51798                 Pandas: filter on multiple columns            5   \n",
       "51821                      DataFrame transpose from List            5   \n",
       "51968                      Probability of a Pandas value            5   \n",
       "52013  How to create strings from dataframe columns e...            5   \n",
       "52254  How do I avoid a loop with Python/Pandas to bu...            5   \n",
       "52273          Python dict group and sum multiple values            5   \n",
       "52904  Finding a maximum value in a dictionary, and d...            6   \n",
       "52967  Selecting single values from pandas dataframe ...            5   \n",
       "53088  How to select all non-NaN columns and non-NaN ...            5   \n",
       "53365                  Add Virgula in front of each word            5   \n",
       "53418    How to make list of list from dataframe pandas?            5   \n",
       "53423  Get one or more column values as a list from P...            5   \n",
       "53433  how to remove 0's in a datacolumn in a datafra...            5   \n",
       "53752            Grouping similar values in a dictionary            5   \n",
       "53983             How to split columns faster in python?            5   \n",
       "54384           Pandas groupby - set of different values            5   \n",
       "54463            Empty DataFrame doesn't admit its empty            6   \n",
       "54475  insert missing category for each group in pand...            6   \n",
       "55444                   column operation in csv [python]            5   \n",
       "55879  Filter Pandas Dataframe using an arbitrary num...            6   \n",
       "\n",
       "       commentcount  favoritecount          quest_name  quest_rep  \\\n",
       "620               9            1.0        Prof. Falken    15061.0   \n",
       "1316              0            NaN           eWizardII      886.0   \n",
       "4816              2            2.0         user2684301     1465.0   \n",
       "4958              0            1.0         OliverSteph       32.0   \n",
       "5339              2            NaN          user104853       16.0   \n",
       "8842              1            4.0             Akavall    30059.0   \n",
       "10525             5            NaN         userqwerty1      362.0   \n",
       "10934             1            1.0                blaz      945.0   \n",
       "13789             0            NaN            hb.klein      151.0   \n",
       "14219             2            NaN          user308827     2529.0   \n",
       "14274             6            1.0               HadiM      173.0   \n",
       "14750             0            NaN            cqcn1991     3290.0   \n",
       "14891             0            NaN                 Ben     4449.0   \n",
       "16024             3            NaN       sachin saxena      528.0   \n",
       "16064            11            NaN                 Leb     6623.0   \n",
       "17111             1            NaN                gthm      605.0   \n",
       "17127             3            1.0               Diego    20300.0   \n",
       "18672             4            NaN              haimen      635.0   \n",
       "18706             2            NaN                 pho      105.0   \n",
       "18998             2            1.0               Satya      882.0   \n",
       "19251             3            NaN                 Thy       41.0   \n",
       "20980             0            NaN      Stefano Potter      932.0   \n",
       "21227             2            NaN            Observer      176.0   \n",
       "21313             3            NaN                 WRJ       98.0   \n",
       "21404             1            NaN              M PAUL      528.0   \n",
       "21431             2            1.0    Condo_programmer       82.0   \n",
       "21442             0            NaN              DyTech       36.0   \n",
       "21462             1            NaN               Satya      882.0   \n",
       "22320             2            NaN              Jeremy      728.0   \n",
       "22415             0            1.0              FooBar     5143.0   \n",
       "...             ...            ...                 ...        ...   \n",
       "50452             1            NaN              SalN85       41.0   \n",
       "50580             0            NaN      Marcos Santana       75.0   \n",
       "50615             0            2.0    Jonathan Pacheco       88.0   \n",
       "50704             0            3.0               sunny       93.0   \n",
       "50735             0            1.0        Bruno Vieira       32.0   \n",
       "50803             0            4.0     Doubt Dhanabalu      113.0   \n",
       "51148             0            0.0      chrisckwong821      417.0   \n",
       "51198             0            NaN              EEPBAH       47.0   \n",
       "51257             0            NaN              Renton       34.0   \n",
       "51654             3            3.0         user1357015     2853.0   \n",
       "51798             3            1.0        M. K. Hunter     1127.0   \n",
       "51821             0            NaN                Josh      118.0   \n",
       "51968             1            1.0            Seano314      336.0   \n",
       "52013             0            NaN        hernanavella     1890.0   \n",
       "52254             3            NaN               GC123       40.0   \n",
       "52273             7            1.0          Ajay Kumar      178.0   \n",
       "52904             0            NaN            Altheman       33.0   \n",
       "52967             2            NaN              edager       81.0   \n",
       "53088             0            NaN                Fang      308.0   \n",
       "53365             1            NaN       Rivaldo Hater       18.0   \n",
       "53418             0            NaN  Satrio Adi Prabowo       98.0   \n",
       "53423             0            NaN                 pyd      416.0   \n",
       "53433             5            NaN                 pyd      416.0   \n",
       "53752             0            NaN     ConstantLearner        3.0   \n",
       "53983             2            NaN            Steve Xu       23.0   \n",
       "54384             0            NaN      Baron Yugovich      260.0   \n",
       "54463             2            NaN         Legit Stack      402.0   \n",
       "54475             3            1.0                muon     1514.0   \n",
       "55444            13            1.0                Alex       17.0   \n",
       "55879             2            NaN        speedyturkey       41.0   \n",
       "\n",
       "                 ans_name   ans_rep  \n",
       "620              Victor K     332.0  \n",
       "1316                  NaN       NaN  \n",
       "4816                 Jeff   62248.0  \n",
       "4958                  NaN       NaN  \n",
       "5339                  NaN       NaN  \n",
       "8842                Jaime   42996.0  \n",
       "10525                 NaN       NaN  \n",
       "10934   Ashwini Chaudhary  154575.0  \n",
       "13789              EdChum  124367.0  \n",
       "14219              EdChum  124367.0  \n",
       "14274         thomasfermi     558.0  \n",
       "14750           DeepSpace   23882.0  \n",
       "14891                 Ben    4449.0  \n",
       "16024                Zero   25935.0  \n",
       "16064  Padraic Cunningham  121352.0  \n",
       "17111                 NaN       NaN  \n",
       "17127  Padraic Cunningham  121352.0  \n",
       "18672             jezrael  186894.0  \n",
       "18706             Divakar  128094.0  \n",
       "18998           Alexander   39006.0  \n",
       "19251               janrn      53.0  \n",
       "20980                 DSM  164692.0  \n",
       "21227                 NaN       NaN  \n",
       "21313                 NaN       NaN  \n",
       "21404       Kaustav Datta     359.0  \n",
       "21431                Goyo    5275.0  \n",
       "21442                 NaN       NaN  \n",
       "21462    Sergey Bushmanov    2279.0  \n",
       "22320                 NaN       NaN  \n",
       "22415                 NaN       NaN  \n",
       "...                   ...       ...  \n",
       "50452                 NaN       NaN  \n",
       "50580     Alexey Trofimov     533.0  \n",
       "50615                 NaN       NaN  \n",
       "50704                 NaN       NaN  \n",
       "50735          benjwadams     750.0  \n",
       "50803            Vaishali   10335.0  \n",
       "51148           cs   51675.0  \n",
       "51198             Divakar  128094.0  \n",
       "51257                Zero   25935.0  \n",
       "51654          piRSquared  102658.0  \n",
       "51798                 NaN       NaN  \n",
       "51821             jezrael  186894.0  \n",
       "51968          piRSquared  102658.0  \n",
       "52013        Scott Boston   23611.0  \n",
       "52254               GC123      40.0  \n",
       "52273           cs   51675.0  \n",
       "52904     Yuriy Savchenko     106.0  \n",
       "52967                MaxU   83732.0  \n",
       "53088             Bharath   12877.0  \n",
       "53365              MedAli    5232.0  \n",
       "53418             jezrael  186894.0  \n",
       "53423             jezrael  186894.0  \n",
       "53433                 NaN       NaN  \n",
       "53752     Jeremy McGibbon    1121.0  \n",
       "53983        Akshay Hegde   11362.0  \n",
       "54384             jezrael  186894.0  \n",
       "54463           cs   51675.0  \n",
       "54475           cs   51675.0  \n",
       "55444             Bharath   12877.0  \n",
       "55879               James    7279.0  \n",
       "\n",
       "[187 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[(so['answercount'].between(5,10)) & (so['viewcount'] < 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "<span  style=\"color:green; font-size:16px\">Find the inverse of exercise 6. Verify your results by adding the rows of both returned Series to see if it matches the number of rows of the original</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>score</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>title</th>\n",
       "      <th>answercount</th>\n",
       "      <th>commentcount</th>\n",
       "      <th>favoritecount</th>\n",
       "      <th>quest_name</th>\n",
       "      <th>quest_rep</th>\n",
       "      <th>ans_name</th>\n",
       "      <th>ans_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5486226</td>\n",
       "      <td>2011-03-30 12:26:50</td>\n",
       "      <td>4</td>\n",
       "      <td>2113</td>\n",
       "      <td>Rolling median in python</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yueerhu</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Mike Pennington</td>\n",
       "      <td>26995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5515021</td>\n",
       "      <td>2011-04-01 14:50:44</td>\n",
       "      <td>8</td>\n",
       "      <td>7015</td>\n",
       "      <td>Compute a compounded return series in Python</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Jason Strimpel</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>Mike Pennington</td>\n",
       "      <td>26995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5558607</td>\n",
       "      <td>2011-04-05 21:13:50</td>\n",
       "      <td>2</td>\n",
       "      <td>7392</td>\n",
       "      <td>Sort a pandas DataMatrix in ascending order</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jason Strimpel</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6467832</td>\n",
       "      <td>2011-06-24 12:31:45</td>\n",
       "      <td>9</td>\n",
       "      <td>13056</td>\n",
       "      <td>How to get the correlation between two timeser...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>user814005</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7577546</td>\n",
       "      <td>2011-09-28 01:58:38</td>\n",
       "      <td>9</td>\n",
       "      <td>2488</td>\n",
       "      <td>Using pandas, how do I subsample a large DataF...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Uri Laserson</td>\n",
       "      <td>958.0</td>\n",
       "      <td>HYRY</td>\n",
       "      <td>54137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7766400</td>\n",
       "      <td>2011-10-14 10:33:54</td>\n",
       "      <td>2</td>\n",
       "      <td>977</td>\n",
       "      <td>Pandas + Django + mod_wsgi + virtualenv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Evan Davey</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7776679</td>\n",
       "      <td>2011-10-15 08:21:17</td>\n",
       "      <td>25</td>\n",
       "      <td>28159</td>\n",
       "      <td>append two data frame with pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jean-Pat</td>\n",
       "      <td>882.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7813132</td>\n",
       "      <td>2011-10-18 20:16:12</td>\n",
       "      <td>10</td>\n",
       "      <td>18917</td>\n",
       "      <td>Convert array of string (category) to array of...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Jean-Pat</td>\n",
       "      <td>882.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7837722</td>\n",
       "      <td>2011-10-20 14:46:14</td>\n",
       "      <td>201</td>\n",
       "      <td>223746</td>\n",
       "      <td>What is the most efficient way to loop through...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Muppet</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>Nick Crawford</td>\n",
       "      <td>2779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8270129</td>\n",
       "      <td>2011-11-25 13:55:02</td>\n",
       "      <td>1</td>\n",
       "      <td>891</td>\n",
       "      <td>Pandas Panel for share portfolio</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evan Davey</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8273092</td>\n",
       "      <td>2011-11-25 18:39:02</td>\n",
       "      <td>1</td>\n",
       "      <td>2333</td>\n",
       "      <td>python: pandas install errors</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>codingknob</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>codingknob</td>\n",
       "      <td>2279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8451327</td>\n",
       "      <td>2011-12-09 20:27:24</td>\n",
       "      <td>1</td>\n",
       "      <td>2435</td>\n",
       "      <td>Python map() function output into Pandas DataF...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>briant57</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8842114</td>\n",
       "      <td>2012-01-12 20:52:41</td>\n",
       "      <td>8</td>\n",
       "      <td>4009</td>\n",
       "      <td>How to apply slicing on pandas Series of strings</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>davidbrai</td>\n",
       "      <td>934.0</td>\n",
       "      <td>Rob Wouters</td>\n",
       "      <td>10083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8914992</td>\n",
       "      <td>2012-01-18 18:00:16</td>\n",
       "      <td>4</td>\n",
       "      <td>961</td>\n",
       "      <td>indexing several csv files with pandas from re...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>user248237dfsf</td>\n",
       "      <td>19244.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8916302</td>\n",
       "      <td>2012-01-18 19:41:27</td>\n",
       "      <td>29</td>\n",
       "      <td>20614</td>\n",
       "      <td>selecting across multiple columns with python ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>user248237dfsf</td>\n",
       "      <td>19244.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8957175</td>\n",
       "      <td>2012-01-21 22:12:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>DataFrame to Panel indexed by nonunique column...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacob Mick</td>\n",
       "      <td>215.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8966871</td>\n",
       "      <td>2012-01-23 03:21:00</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>Running Python/Numpy/Pandas on older secure co...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casey</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8991709</td>\n",
       "      <td>2012-01-24 17:59:53</td>\n",
       "      <td>136</td>\n",
       "      <td>16783</td>\n",
       "      <td>Why are pandas merges in python faster than da...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Zach</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>Matt Dowle</td>\n",
       "      <td>41275.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9189425</td>\n",
       "      <td>2012-02-08 07:42:11</td>\n",
       "      <td>2</td>\n",
       "      <td>1514</td>\n",
       "      <td>Pandas DataFrame serialization</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rezusr</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9283166</td>\n",
       "      <td>2012-02-14 19:42:19</td>\n",
       "      <td>3</td>\n",
       "      <td>8766</td>\n",
       "      <td>Plotting a stock chart with Pandas in IPython</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ben McCann</td>\n",
       "      <td>8712.0</td>\n",
       "      <td>Appleman1234</td>\n",
       "      <td>13272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9339184</td>\n",
       "      <td>2012-02-18 06:26:50</td>\n",
       "      <td>2</td>\n",
       "      <td>1234</td>\n",
       "      <td>Python: Pandas, Dataframe, Convert 1column dat...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>notilas</td>\n",
       "      <td>330.0</td>\n",
       "      <td>jfs</td>\n",
       "      <td>222208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9421412</td>\n",
       "      <td>2012-02-23 21:14:19</td>\n",
       "      <td>2</td>\n",
       "      <td>892</td>\n",
       "      <td>Initializing pandas dataframes with and withou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>benjaminmgross</td>\n",
       "      <td>828.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9516422</td>\n",
       "      <td>2012-03-01 12:40:33</td>\n",
       "      <td>2</td>\n",
       "      <td>1106</td>\n",
       "      <td>nan, floats and ints</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Blanca</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9550867</td>\n",
       "      <td>2012-03-03 23:42:13</td>\n",
       "      <td>5</td>\n",
       "      <td>4148</td>\n",
       "      <td>Python Pandas Pivot Table</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>user1026987</td>\n",
       "      <td>45.0</td>\n",
       "      <td>BioGeek</td>\n",
       "      <td>9974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9555635</td>\n",
       "      <td>2012-03-04 14:25:36</td>\n",
       "      <td>19</td>\n",
       "      <td>6604</td>\n",
       "      <td>Open source Enthought Python alternative</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>tshauck</td>\n",
       "      <td>5957.0</td>\n",
       "      <td>ogrisel</td>\n",
       "      <td>24990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9556892</td>\n",
       "      <td>2012-03-04 16:58:45</td>\n",
       "      <td>6</td>\n",
       "      <td>5217</td>\n",
       "      <td>Pandas DataFrame - desired index has duplicate...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>kavu</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9588331</td>\n",
       "      <td>2012-03-06 17:01:47</td>\n",
       "      <td>22</td>\n",
       "      <td>10038</td>\n",
       "      <td>Simple cross-tabulation in pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jon Clements</td>\n",
       "      <td>85944.0</td>\n",
       "      <td>Jeff Hammerbacher</td>\n",
       "      <td>3172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9597681</td>\n",
       "      <td>2012-03-07 07:56:37</td>\n",
       "      <td>3</td>\n",
       "      <td>3060</td>\n",
       "      <td>read_csv converters for unkown columns</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Blanca</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9621362</td>\n",
       "      <td>2012-03-08 16:42:30</td>\n",
       "      <td>7</td>\n",
       "      <td>6417</td>\n",
       "      <td>how do I compute a weighted moving average usi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thatshowthe</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Wes McKinney</td>\n",
       "      <td>43310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9641916</td>\n",
       "      <td>2012-03-09 22:36:52</td>\n",
       "      <td>7</td>\n",
       "      <td>5519</td>\n",
       "      <td>Python Pandas: can't find numpy.core.multiarra...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dylan Cutler</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56368</th>\n",
       "      <td>47561788</td>\n",
       "      <td>2017-11-29 21:05:57</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>How to perform an operation on specific column...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spc963</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56369</th>\n",
       "      <td>47561901</td>\n",
       "      <td>2017-11-29 21:12:22</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Python Pandas Combining 2 df by keys</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TylerNG</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Wen</td>\n",
       "      <td>21789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56370</th>\n",
       "      <td>47580397</td>\n",
       "      <td>2017-11-30 18:35:15</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>join/combine similar columns in python</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TylerNG</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Wen</td>\n",
       "      <td>21789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56371</th>\n",
       "      <td>47604151</td>\n",
       "      <td>2017-12-02 03:03:39</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Annotating bar chart in pandas</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56372</th>\n",
       "      <td>47603274</td>\n",
       "      <td>2017-12-02 00:20:02</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Plotting a bar chart comparing years in pandas</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3.0</td>\n",
       "      <td>user32185</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56373</th>\n",
       "      <td>47610875</td>\n",
       "      <td>2017-12-02 18:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Sorting float values in a groupby in ascending...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56374</th>\n",
       "      <td>47613361</td>\n",
       "      <td>2017-12-02 22:38:38</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>How to remove duplicate markers in gmaps in pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56375</th>\n",
       "      <td>47565631</td>\n",
       "      <td>2017-11-30 03:58:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>28</td>\n",
       "      <td>compare a timestamp index with a fixed date in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ian_chan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56376</th>\n",
       "      <td>47566201</td>\n",
       "      <td>2017-11-30 05:00:47</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Issue with Python while converting excel into ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nihanth reddy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>alex h</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56377</th>\n",
       "      <td>47570069</td>\n",
       "      <td>2017-11-30 09:34:05</td>\n",
       "      <td>-4</td>\n",
       "      <td>28</td>\n",
       "      <td>Python-How to partition these data in DataFrame?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Data_Miner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56378</th>\n",
       "      <td>47571309</td>\n",
       "      <td>2017-11-30 10:35:46</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Pandas - Compare two dataframes and replace va...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PyuPyuPyu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56379</th>\n",
       "      <td>47572121</td>\n",
       "      <td>2017-11-30 11:15:01</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Dropping rows in a pandas dataframe</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>melania</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56380</th>\n",
       "      <td>47573928</td>\n",
       "      <td>2017-11-30 12:48:40</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Secondary x and y axes when merging 2 chart ty...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Golanu Delamare</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56381</th>\n",
       "      <td>47577303</td>\n",
       "      <td>2017-11-30 15:46:37</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>pandas DataFrame: Get previous month value whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Somchai Kira</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Wen</td>\n",
       "      <td>21789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56382</th>\n",
       "      <td>47581808</td>\n",
       "      <td>2017-11-30 20:12:18</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Fill Down a value in Pandas once it has occurred</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dani Freidus</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Scott Boston</td>\n",
       "      <td>23611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56383</th>\n",
       "      <td>47578774</td>\n",
       "      <td>2017-11-30 17:01:19</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>Python: How to efficiently do operations using...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alejandro pareja</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56384</th>\n",
       "      <td>47584263</td>\n",
       "      <td>2017-11-30 23:22:32</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>Slicing a pandas dataframe into rows with a ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larry</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Abhishek</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56385</th>\n",
       "      <td>47585554</td>\n",
       "      <td>2017-12-01 02:00:10</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>How to separate out nested json values in pand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gotham_tramp</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56386</th>\n",
       "      <td>47592169</td>\n",
       "      <td>2017-12-01 11:13:26</td>\n",
       "      <td>-4</td>\n",
       "      <td>27</td>\n",
       "      <td>Regex replacement does not work on pandas data...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Judit Anna Trendl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56387</th>\n",
       "      <td>47592512</td>\n",
       "      <td>2017-12-01 11:35:31</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Adding column in pandas with several condition...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Henry Blauth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56388</th>\n",
       "      <td>47593883</td>\n",
       "      <td>2017-12-01 12:55:05</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Trying to populate a column in a dataframe wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bamb0ocha</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jezrael</td>\n",
       "      <td>186894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56389</th>\n",
       "      <td>47594932</td>\n",
       "      <td>2017-12-01 13:53:15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Row-wise Interpolation in dataframe using inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rolo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56390</th>\n",
       "      <td>47600529</td>\n",
       "      <td>2017-12-01 19:50:19</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Mean of values in pandas dataframe</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bartek Leks</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lucas Dresl</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56391</th>\n",
       "      <td>47601533</td>\n",
       "      <td>2017-12-01 21:09:16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Getting a crime 'count' from pandas big dataset</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leena</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56392</th>\n",
       "      <td>47610316</td>\n",
       "      <td>2017-12-02 17:02:03</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>python module 'pandas' has no attribute 'plott...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56393</th>\n",
       "      <td>47606711</td>\n",
       "      <td>2017-12-02 10:07:13</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>slow loop using panda</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xxyy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>user32185</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56394</th>\n",
       "      <td>47607549</td>\n",
       "      <td>2017-12-02 11:41:59</td>\n",
       "      <td>-1</td>\n",
       "      <td>41</td>\n",
       "      <td>Convert Numeric percentage values into String</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ajeet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56395</th>\n",
       "      <td>47609325</td>\n",
       "      <td>2017-12-02 15:16:26</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>Filtering for criteria in Pandas Dataframe Python</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NthA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56396</th>\n",
       "      <td>47609598</td>\n",
       "      <td>2017-12-02 15:45:40</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Python Multi index function with order preserv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fan LUO</td>\n",
       "      <td>13.0</td>\n",
       "      <td>erocoar</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56397</th>\n",
       "      <td>47611969</td>\n",
       "      <td>2017-12-02 19:59:09</td>\n",
       "      <td>-6</td>\n",
       "      <td>19</td>\n",
       "      <td>Converting Pandas Dataframe to R object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soorya Paturi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56211 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         creationdate  score  viewcount  \\\n",
       "0       5486226  2011-03-30 12:26:50      4       2113   \n",
       "1       5515021  2011-04-01 14:50:44      8       7015   \n",
       "2       5558607  2011-04-05 21:13:50      2       7392   \n",
       "3       6467832  2011-06-24 12:31:45      9      13056   \n",
       "4       7577546  2011-09-28 01:58:38      9       2488   \n",
       "5       7766400  2011-10-14 10:33:54      2        977   \n",
       "6       7776679  2011-10-15 08:21:17     25      28159   \n",
       "7       7813132  2011-10-18 20:16:12     10      18917   \n",
       "8       7837722  2011-10-20 14:46:14    201     223746   \n",
       "9       8270129  2011-11-25 13:55:02      1        891   \n",
       "10      8273092  2011-11-25 18:39:02      1       2333   \n",
       "11      8451327  2011-12-09 20:27:24      1       2435   \n",
       "12      8842114  2012-01-12 20:52:41      8       4009   \n",
       "13      8914992  2012-01-18 18:00:16      4        961   \n",
       "14      8916302  2012-01-18 19:41:27     29      20614   \n",
       "15      8957175  2012-01-21 22:12:10      1       1134   \n",
       "16      8966871  2012-01-23 03:21:00      0        287   \n",
       "17      8991709  2012-01-24 17:59:53    136      16783   \n",
       "18      9189425  2012-02-08 07:42:11      2       1514   \n",
       "19      9283166  2012-02-14 19:42:19      3       8766   \n",
       "20      9339184  2012-02-18 06:26:50      2       1234   \n",
       "21      9421412  2012-02-23 21:14:19      2        892   \n",
       "22      9516422  2012-03-01 12:40:33      2       1106   \n",
       "23      9550867  2012-03-03 23:42:13      5       4148   \n",
       "24      9555635  2012-03-04 14:25:36     19       6604   \n",
       "25      9556892  2012-03-04 16:58:45      6       5217   \n",
       "26      9588331  2012-03-06 17:01:47     22      10038   \n",
       "27      9597681  2012-03-07 07:56:37      3       3060   \n",
       "28      9621362  2012-03-08 16:42:30      7       6417   \n",
       "29      9641916  2012-03-09 22:36:52      7       5519   \n",
       "...         ...                  ...    ...        ...   \n",
       "56368  47561788  2017-11-29 21:05:57      2         20   \n",
       "56369  47561901  2017-11-29 21:12:22      0         30   \n",
       "56370  47580397  2017-11-30 18:35:15      1         30   \n",
       "56371  47604151  2017-12-02 03:03:39      0         24   \n",
       "56372  47603274  2017-12-02 00:20:02      0         36   \n",
       "56373  47610875  2017-12-02 18:00:31      0         16   \n",
       "56374  47613361  2017-12-02 22:38:38      0          8   \n",
       "56375  47565631  2017-11-30 03:58:37     -1         28   \n",
       "56376  47566201  2017-11-30 05:00:47      0         17   \n",
       "56377  47570069  2017-11-30 09:34:05     -4         28   \n",
       "56378  47571309  2017-11-30 10:35:46      0         32   \n",
       "56379  47572121  2017-11-30 11:15:01      0         23   \n",
       "56380  47573928  2017-11-30 12:48:40      1         28   \n",
       "56381  47577303  2017-11-30 15:46:37      1         18   \n",
       "56382  47581808  2017-11-30 20:12:18      3         27   \n",
       "56383  47578774  2017-11-30 17:01:19      0         15   \n",
       "56384  47584263  2017-11-30 23:22:32      1         27   \n",
       "56385  47585554  2017-12-01 02:00:10      2         14   \n",
       "56386  47592169  2017-12-01 11:13:26     -4         27   \n",
       "56387  47592512  2017-12-01 11:35:31      0         17   \n",
       "56388  47593883  2017-12-01 12:55:05      1         14   \n",
       "56389  47594932  2017-12-01 13:53:15      0         18   \n",
       "56390  47600529  2017-12-01 19:50:19      0         29   \n",
       "56391  47601533  2017-12-01 21:09:16      1         22   \n",
       "56392  47610316  2017-12-02 17:02:03      1         23   \n",
       "56393  47606711  2017-12-02 10:07:13      0         17   \n",
       "56394  47607549  2017-12-02 11:41:59     -1         41   \n",
       "56395  47609325  2017-12-02 15:16:26      0         33   \n",
       "56396  47609598  2017-12-02 15:45:40      2         18   \n",
       "56397  47611969  2017-12-02 19:59:09     -6         19   \n",
       "\n",
       "                                                   title  answercount  \\\n",
       "0                               Rolling median in python            3   \n",
       "1           Compute a compounded return series in Python            3   \n",
       "2            Sort a pandas DataMatrix in ascending order            2   \n",
       "3      How to get the correlation between two timeser...            1   \n",
       "4      Using pandas, how do I subsample a large DataF...            1   \n",
       "5                Pandas + Django + mod_wsgi + virtualenv            1   \n",
       "6                      append two data frame with pandas            2   \n",
       "7      Convert array of string (category) to array of...            3   \n",
       "8      What is the most efficient way to loop through...            8   \n",
       "9                       Pandas Panel for share portfolio            1   \n",
       "10                         python: pandas install errors            2   \n",
       "11     Python map() function output into Pandas DataF...            1   \n",
       "12      How to apply slicing on pandas Series of strings            3   \n",
       "13     indexing several csv files with pandas from re...            1   \n",
       "14     selecting across multiple columns with python ...            3   \n",
       "15     DataFrame to Panel indexed by nonunique column...            1   \n",
       "16     Running Python/Numpy/Pandas on older secure co...            0   \n",
       "17     Why are pandas merges in python faster than da...            3   \n",
       "18                        Pandas DataFrame serialization            1   \n",
       "19         Plotting a stock chart with Pandas in IPython            2   \n",
       "20     Python: Pandas, Dataframe, Convert 1column dat...            2   \n",
       "21     Initializing pandas dataframes with and withou...            1   \n",
       "22                                  nan, floats and ints            1   \n",
       "23                             Python Pandas Pivot Table            2   \n",
       "24              Open source Enthought Python alternative            8   \n",
       "25     Pandas DataFrame - desired index has duplicate...            1   \n",
       "26                     Simple cross-tabulation in pandas            2   \n",
       "27                read_csv converters for unkown columns            1   \n",
       "28     how do I compute a weighted moving average usi...            1   \n",
       "29     Python Pandas: can't find numpy.core.multiarra...            4   \n",
       "...                                                  ...          ...   \n",
       "56368  How to perform an operation on specific column...            2   \n",
       "56369               Python Pandas Combining 2 df by keys            1   \n",
       "56370             join/combine similar columns in python            2   \n",
       "56371                     Annotating bar chart in pandas            2   \n",
       "56372     Plotting a bar chart comparing years in pandas            1   \n",
       "56373  Sorting float values in a groupby in ascending...            1   \n",
       "56374  How to remove duplicate markers in gmaps in pa...            0   \n",
       "56375  compare a timestamp index with a fixed date in...            1   \n",
       "56376  Issue with Python while converting excel into ...            1   \n",
       "56377   Python-How to partition these data in DataFrame?            0   \n",
       "56378  Pandas - Compare two dataframes and replace va...            1   \n",
       "56379                Dropping rows in a pandas dataframe            1   \n",
       "56380  Secondary x and y axes when merging 2 chart ty...            0   \n",
       "56381  pandas DataFrame: Get previous month value whe...            1   \n",
       "56382   Fill Down a value in Pandas once it has occurred            1   \n",
       "56383  Python: How to efficiently do operations using...            2   \n",
       "56384  Slicing a pandas dataframe into rows with a ce...            1   \n",
       "56385  How to separate out nested json values in pand...            0   \n",
       "56386  Regex replacement does not work on pandas data...            0   \n",
       "56387  Adding column in pandas with several condition...            1   \n",
       "56388  Trying to populate a column in a dataframe wit...            1   \n",
       "56389  Row-wise Interpolation in dataframe using inte...            1   \n",
       "56390                 Mean of values in pandas dataframe            3   \n",
       "56391    Getting a crime 'count' from pandas big dataset            1   \n",
       "56392  python module 'pandas' has no attribute 'plott...            1   \n",
       "56393                              slow loop using panda            1   \n",
       "56394      Convert Numeric percentage values into String            1   \n",
       "56395  Filtering for criteria in Pandas Dataframe Python            2   \n",
       "56396  Python Multi index function with order preserv...            1   \n",
       "56397            Converting Pandas Dataframe to R object            0   \n",
       "\n",
       "       commentcount  favoritecount         quest_name  quest_rep  \\\n",
       "0                 4            1.0            yueerhu      125.0   \n",
       "1                 6            7.0     Jason Strimpel     3301.0   \n",
       "2                 0            1.0     Jason Strimpel     3301.0   \n",
       "3                 0            7.0         user814005      117.0   \n",
       "4                 0            5.0       Uri Laserson      958.0   \n",
       "5                 2            1.0         Evan Davey      100.0   \n",
       "6                 7            4.0           Jean-Pat      882.0   \n",
       "7                 0            6.0           Jean-Pat      882.0   \n",
       "8                 3          115.0             Muppet     1563.0   \n",
       "9                 0            NaN         Evan Davey      100.0   \n",
       "10                0            NaN         codingknob     2279.0   \n",
       "11                0            1.0           briant57        6.0   \n",
       "12                2            1.0          davidbrai      934.0   \n",
       "13                1            1.0     user248237dfsf    19244.0   \n",
       "14                0           14.0     user248237dfsf    19244.0   \n",
       "15                4            NaN         Jacob Mick      215.0   \n",
       "16                3            NaN              Casey       16.0   \n",
       "17               16           60.0               Zach    12484.0   \n",
       "18                0            NaN             rezusr       33.0   \n",
       "19                1            1.0         Ben McCann     8712.0   \n",
       "20                0            1.0            notilas      330.0   \n",
       "21                0            1.0     benjaminmgross      828.0   \n",
       "22                0            NaN        Jose Blanca       60.0   \n",
       "23                0            4.0        user1026987       45.0   \n",
       "24                5            6.0            tshauck     5957.0   \n",
       "25                0            3.0               kavu       55.0   \n",
       "26                3            5.0       Jon Clements    85944.0   \n",
       "27                0            NaN        Jose Blanca       60.0   \n",
       "28                2            1.0        thatshowthe      100.0   \n",
       "29                2            NaN       Dylan Cutler       41.0   \n",
       "...             ...            ...                ...        ...   \n",
       "56368             0            NaN             spc963       11.0   \n",
       "56369             0            NaN            TylerNG       10.0   \n",
       "56370             0            NaN            TylerNG       10.0   \n",
       "56371             1            NaN              Sarah        3.0   \n",
       "56372            12            NaN              Sarah        3.0   \n",
       "56373             0            NaN              Sarah        3.0   \n",
       "56374             0            NaN              Sarah        3.0   \n",
       "56375             1            NaN           ian_chan        1.0   \n",
       "56376             1            NaN      Nihanth reddy        3.0   \n",
       "56377             1            1.0         Data_Miner        1.0   \n",
       "56378             1            NaN          PyuPyuPyu        1.0   \n",
       "56379             4            NaN            melania        1.0   \n",
       "56380             3            NaN    Golanu Delamare        6.0   \n",
       "56381             1            1.0       Somchai Kira        8.0   \n",
       "56382             1            0.0       Dani Freidus       18.0   \n",
       "56383             1            NaN   alejandro pareja        1.0   \n",
       "56384             2            NaN              Larry        8.0   \n",
       "56385             0            NaN       gotham_tramp       11.0   \n",
       "56386             9            NaN  Judit Anna Trendl        1.0   \n",
       "56387             0            NaN       Henry Blauth        3.0   \n",
       "56388             0            NaN          bamb0ocha        8.0   \n",
       "56389             0            NaN               Rolo        1.0   \n",
       "56390             3            NaN        Bartek Leks        3.0   \n",
       "56391             1            NaN              Leena        6.0   \n",
       "56392             1            NaN              Harry        6.0   \n",
       "56393             1            NaN               xxyy        3.0   \n",
       "56394             2            NaN              Ajeet        1.0   \n",
       "56395             4            NaN               NthA        1.0   \n",
       "56396             0            NaN            Fan LUO       13.0   \n",
       "56397             0            NaN      Soorya Paturi        1.0   \n",
       "\n",
       "                ans_name   ans_rep  \n",
       "0        Mike Pennington   26995.0  \n",
       "1        Mike Pennington   26995.0  \n",
       "2           Wes McKinney   43310.0  \n",
       "3           Wes McKinney   43310.0  \n",
       "4                   HYRY   54137.0  \n",
       "5                    NaN       NaN  \n",
       "6           Wes McKinney   43310.0  \n",
       "7           Wes McKinney   43310.0  \n",
       "8          Nick Crawford    2779.0  \n",
       "9           Wes McKinney   43310.0  \n",
       "10            codingknob    2279.0  \n",
       "11                   NaN       NaN  \n",
       "12           Rob Wouters   10083.0  \n",
       "13          Wes McKinney   43310.0  \n",
       "14          Wes McKinney   43310.0  \n",
       "15          Wes McKinney   43310.0  \n",
       "16                   NaN       NaN  \n",
       "17            Matt Dowle   41275.0  \n",
       "18          Wes McKinney   43310.0  \n",
       "19          Appleman1234   13272.0  \n",
       "20                   jfs  222208.0  \n",
       "21          Wes McKinney   43310.0  \n",
       "22          Wes McKinney   43310.0  \n",
       "23               BioGeek    9974.0  \n",
       "24               ogrisel   24990.0  \n",
       "25          Wes McKinney   43310.0  \n",
       "26     Jeff Hammerbacher    3172.0  \n",
       "27          Wes McKinney   43310.0  \n",
       "28          Wes McKinney   43310.0  \n",
       "29                   NaN       NaN  \n",
       "...                  ...       ...  \n",
       "56368                NaN       NaN  \n",
       "56369                Wen   21789.0  \n",
       "56370                Wen   21789.0  \n",
       "56371                NaN       NaN  \n",
       "56372          user32185     308.0  \n",
       "56373                NaN       NaN  \n",
       "56374                NaN       NaN  \n",
       "56375                NaN       NaN  \n",
       "56376             alex h      91.0  \n",
       "56377                NaN       NaN  \n",
       "56378                NaN       NaN  \n",
       "56379                NaN       NaN  \n",
       "56380                NaN       NaN  \n",
       "56381                Wen   21789.0  \n",
       "56382       Scott Boston   23611.0  \n",
       "56383                NaN       NaN  \n",
       "56384           Abhishek     126.0  \n",
       "56385                NaN       NaN  \n",
       "56386                NaN       NaN  \n",
       "56387            jezrael  186894.0  \n",
       "56388            jezrael  186894.0  \n",
       "56389                NaN       NaN  \n",
       "56390        Lucas Dresl      59.0  \n",
       "56391                NaN       NaN  \n",
       "56392                NaN       NaN  \n",
       "56393          user32185     308.0  \n",
       "56394                NaN       NaN  \n",
       "56395                NaN       NaN  \n",
       "56396            erocoar     209.0  \n",
       "56397                NaN       NaN  \n",
       "\n",
       "[56211 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so[~(so['answercount'].between(5,10) & (so['viewcount'] < 1000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the employee data for the rest of the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIBRARY ASSISTANT</td>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>2010-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "      <td>1991-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRICIAN</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-06-19</td>\n",
       "      <td>1994-10-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                POSITION_TITLE                     DEPARTMENT  BASE_SALARY  \\\n",
       "0  ASSISTANT DIRECTOR (EX LVL)    Municipal Courts Department     121862.0   \n",
       "1            LIBRARY ASSISTANT                        Library      26125.0   \n",
       "2               POLICE OFFICER  Houston Police Department-HPD      45279.0   \n",
       "3            ENGINEER/OPERATOR  Houston Fire Department (HFD)      63166.0   \n",
       "4                  ELECTRICIAN    General Services Department      56347.0   \n",
       "\n",
       "              RACE EMPLOYMENT_TYPE  GENDER   HIRE_DATE    JOB_DATE  \n",
       "0  Hispanic/Latino       Full Time  Female  2006-06-12  2012-10-13  \n",
       "1  Hispanic/Latino       Full Time  Female  2000-07-19  2010-09-18  \n",
       "2            White       Full Time    Male  2015-02-03  2015-02-03  \n",
       "3            White       Full Time    Male  1982-02-08  1991-05-25  \n",
       "4            White       Full Time    Male  1989-06-19  1994-10-22  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee = pd.read_csv('employee.csv')\n",
    "employee.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "<span  style=\"color:green; font-size:16px\">Find all the **`Black or African American`** females that work in the **`Houston Police Department-HPD`**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-11-26</td>\n",
       "      <td>2005-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHIEF PHYSICIAN,MD</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-05-22</td>\n",
       "      <td>1999-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>2015-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PUBLIC HEALTH INVESTIGATOR SUPERVISOR</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>55269.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-10-20</td>\n",
       "      <td>2001-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-06-04</td>\n",
       "      <td>2015-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-01-30</td>\n",
       "      <td>2015-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>57815.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-20</td>\n",
       "      <td>2003-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43264.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>52514.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>2011-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UTILITY WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>29557.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SENIOR ACCOUNTANT</td>\n",
       "      <td>Finance</td>\n",
       "      <td>46963.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-02-11</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DENTAL ASSISTANT</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>34923.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-04-05</td>\n",
       "      <td>1990-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>INVENTORY MANAGEMENT SUPERVISOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>38168.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-09-08</td>\n",
       "      <td>2015-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FIELD SUPERVISOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43597.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-06-30</td>\n",
       "      <td>2013-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CUSTOMER SERVICE SUPERVISOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43618.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2007-12-15</td>\n",
       "      <td>2015-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ADMINISTRATIVE ASSOCIATE</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>34757.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-05-11</td>\n",
       "      <td>2008-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SEMI-SKILLED LABORER</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>27622.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>LABORER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>28163.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-08-19</td>\n",
       "      <td>2013-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>IT PROJECT MANAGER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>96668.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-04-07</td>\n",
       "      <td>2006-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>LABORER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2001-05-21</td>\n",
       "      <td>2001-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-07-31</td>\n",
       "      <td>2012-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>55939.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-12-19</td>\n",
       "      <td>2013-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>SENIOR SIDELOADER OPERATOR</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>38459.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-09-07</td>\n",
       "      <td>2005-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1999-09-27</td>\n",
       "      <td>2007-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Fleet Management Department</td>\n",
       "      <td>50249.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2007-04-30</td>\n",
       "      <td>2012-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>LICENSED VOCATIONAL NURSE</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>48984.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-12-27</td>\n",
       "      <td>2000-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SENIOR CONTRACT ADMINISTRATOR</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>79143.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-09-08</td>\n",
       "      <td>2009-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>FIELD SUPERVISOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>53373.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1996-03-04</td>\n",
       "      <td>2005-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9-1-1 TELECOMMUNICATOR</td>\n",
       "      <td>Houston Emergency Center (HEC)</td>\n",
       "      <td>32240.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>2006-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CUSTODIAN</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-10-02</td>\n",
       "      <td>1993-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-04-11</td>\n",
       "      <td>2011-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>LABORER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2007-08-13</td>\n",
       "      <td>2007-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>HUMAN RESOURCES MANAGER</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>74435.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2004-10-11</td>\n",
       "      <td>2015-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>SENIOR CUSTOMER SERVICE CLERK</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>33550.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>CUSTOMER SERVICE CLERK</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>26250.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2007-09-14</td>\n",
       "      <td>2007-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>SENIOR PLAN ANALYST</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>51584.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>2015-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>2008-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>FIELD SUPERVISOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>41267.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2006-07-10</td>\n",
       "      <td>2015-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>DIVISION MANAGER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>93089.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-05-16</td>\n",
       "      <td>2014-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>56489.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-10-16</td>\n",
       "      <td>2004-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>47650.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2013-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>9-1-1 TELECOMMUNICATOR</td>\n",
       "      <td>Houston Emergency Center (HEC)</td>\n",
       "      <td>39104.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>2005-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>JAIL ATTENDANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>37461.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2008-06-02</td>\n",
       "      <td>2008-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>UTILITY WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>37606.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2006-01-30</td>\n",
       "      <td>2006-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2007-02-12</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43264.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>2015-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>SENIOR COMMUNITY LIAISON</td>\n",
       "      <td>Library</td>\n",
       "      <td>51542.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>2015-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>47996.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2009-11-16</td>\n",
       "      <td>2016-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>STAFF ANALYST</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>CUSTOMER SERVICE CLERK</td>\n",
       "      <td>Library</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-08-05</td>\n",
       "      <td>2013-08-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-04-12</td>\n",
       "      <td>2013-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>POLICE SERVICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>27914.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-10-14</td>\n",
       "      <td>2014-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>70181.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-08-29</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>2005-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Admn. &amp; Regulatory Affairs</td>\n",
       "      <td>55172.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-10-16</td>\n",
       "      <td>2006-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>TRUCK DRIVER</td>\n",
       "      <td>Fleet Management Department</td>\n",
       "      <td>30222.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>EQUIPMENT WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-12-11</td>\n",
       "      <td>2004-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>BUILDING MAINTENANCE SUPERVISOR</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-14</td>\n",
       "      <td>2010-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>POLICE CAPTAIN</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>104455.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-02-07</td>\n",
       "      <td>2004-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>COMMUNICATIONS CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>66523.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2003-09-02</td>\n",
       "      <td>2013-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             POSITION_TITLE                      DEPARTMENT  \\\n",
       "5                     SENIOR POLICE OFFICER   Houston Police Department-HPD   \n",
       "11                       CHIEF PHYSICIAN,MD         Health & Human Services   \n",
       "12        CUSTOMER SERVICE REPRESENTATIVE I  Public Works & Engineering-PWE   \n",
       "13    PUBLIC HEALTH INVESTIGATOR SUPERVISOR         Health & Human Services   \n",
       "14                          POLICE SERGEANT   Houston Police Department-HPD   \n",
       "15                    SENIOR POLICE OFFICER   Houston Police Department-HPD   \n",
       "21                             FIRE FIGHTER   Houston Fire Department (HFD)   \n",
       "22                                INSPECTOR  Public Works & Engineering-PWE   \n",
       "24                           POLICE OFFICER   Houston Police Department-HPD   \n",
       "29                           UTILITY WORKER  Public Works & Engineering-PWE   \n",
       "32                        SENIOR ACCOUNTANT                         Finance   \n",
       "35                         DENTAL ASSISTANT         Health & Human Services   \n",
       "39          INVENTORY MANAGEMENT SUPERVISOR  Public Works & Engineering-PWE   \n",
       "46                         FIELD SUPERVISOR  Public Works & Engineering-PWE   \n",
       "47              CUSTOMER SERVICE SUPERVISOR  Public Works & Engineering-PWE   \n",
       "55                 ADMINISTRATIVE ASSOCIATE   Houston Police Department-HPD   \n",
       "57                     SEMI-SKILLED LABORER          Solid Waste Management   \n",
       "59                                  LABORER    Houston Airport System (HAS)   \n",
       "61                       IT PROJECT MANAGER   Houston Fire Department (HFD)   \n",
       "63                                  LABORER  Public Works & Engineering-PWE   \n",
       "69                    SENIOR POLICE OFFICER   Houston Police Department-HPD   \n",
       "73                ADMINISTRATIVE SPECIALIST           Human Resources Dept.   \n",
       "74               SENIOR SIDELOADER OPERATOR          Solid Waste Management   \n",
       "79        CUSTOMER SERVICE REPRESENTATIVE I  Public Works & Engineering-PWE   \n",
       "80                ADMINISTRATIVE SPECIALIST     Fleet Management Department   \n",
       "84                LICENSED VOCATIONAL NURSE         Health & Human Services   \n",
       "87            SENIOR CONTRACT ADMINISTRATOR     Municipal Courts Department   \n",
       "88                         FIELD SUPERVISOR  Public Works & Engineering-PWE   \n",
       "90                   9-1-1 TELECOMMUNICATOR  Houston Emergency Center (HEC)   \n",
       "92                                CUSTODIAN              Parks & Recreation   \n",
       "...                                     ...                             ...   \n",
       "1929                        POLICE SERGEANT   Houston Police Department-HPD   \n",
       "1930                                LABORER    Houston Airport System (HAS)   \n",
       "1933                HUMAN RESOURCES MANAGER           Human Resources Dept.   \n",
       "1934          SENIOR CUSTOMER SERVICE CLERK   Houston Police Department-HPD   \n",
       "1937                 CUSTOMER SERVICE CLERK   Houston Police Department-HPD   \n",
       "1939                    SENIOR PLAN ANALYST  Public Works & Engineering-PWE   \n",
       "1940                  SENIOR POLICE OFFICER   Houston Police Department-HPD   \n",
       "1941                       FIELD SUPERVISOR  Public Works & Engineering-PWE   \n",
       "1944                       DIVISION MANAGER  Public Works & Engineering-PWE   \n",
       "1947              ADMINISTRATIVE SPECIALIST  Public Works & Engineering-PWE   \n",
       "1949                         POLICE OFFICER   Houston Police Department-HPD   \n",
       "1952                 9-1-1 TELECOMMUNICATOR  Houston Emergency Center (HEC)   \n",
       "1955                         JAIL ATTENDANT   Houston Police Department-HPD   \n",
       "1956                         UTILITY WORKER  Public Works & Engineering-PWE   \n",
       "1959              ADMINISTRATIVE SPECIALIST   Houston Fire Department (HFD)   \n",
       "1960                              INSPECTOR  Public Works & Engineering-PWE   \n",
       "1963               SENIOR COMMUNITY LIAISON                         Library   \n",
       "1964              ADMINISTRATIVE SPECIALIST   Houston Police Department-HPD   \n",
       "1967                          STAFF ANALYST           Human Resources Dept.   \n",
       "1968                 CUSTOMER SERVICE CLERK                         Library   \n",
       "1974                  SENIOR POLICE OFFICER   Houston Police Department-HPD   \n",
       "1978                 POLICE SERVICE OFFICER   Houston Police Department-HPD   \n",
       "1981                                CAPTAIN   Houston Fire Department (HFD)   \n",
       "1982                           FIRE FIGHTER   Houston Fire Department (HFD)   \n",
       "1983              ADMINISTRATIVE SPECIALIST      Admn. & Regulatory Affairs   \n",
       "1985                           TRUCK DRIVER     Fleet Management Department   \n",
       "1989                       EQUIPMENT WORKER  Public Works & Engineering-PWE   \n",
       "1990        BUILDING MAINTENANCE SUPERVISOR              Parks & Recreation   \n",
       "1994                         POLICE CAPTAIN   Houston Police Department-HPD   \n",
       "1996                 COMMUNICATIONS CAPTAIN   Houston Fire Department (HFD)   \n",
       "\n",
       "      BASE_SALARY                       RACE EMPLOYMENT_TYPE  GENDER  \\\n",
       "5         66614.0  Black or African American       Full Time    Male   \n",
       "11       180416.0  Black or African American       Full Time    Male   \n",
       "12        30347.0  Black or African American       Full Time    Male   \n",
       "13        55269.0  Black or African American       Full Time    Male   \n",
       "14        77076.0  Black or African American       Full Time    Male   \n",
       "15            NaN  Black or African American       Full Time    Male   \n",
       "21        57815.0  Black or African American       Full Time    Male   \n",
       "22        43264.0  Black or African American       Full Time    Male   \n",
       "24        52514.0  Black or African American       Full Time    Male   \n",
       "29        29557.0  Black or African American       Full Time    Male   \n",
       "32        46963.0  Black or African American       Full Time    Male   \n",
       "35        34923.0  Black or African American       Full Time  Female   \n",
       "39        38168.0  Black or African American       Full Time    Male   \n",
       "46        43597.0  Black or African American       Full Time    Male   \n",
       "47        43618.0  Black or African American       Full Time  Female   \n",
       "55        34757.0  Black or African American       Full Time  Female   \n",
       "57        27622.0  Black or African American       Full Time    Male   \n",
       "59        28163.0  Black or African American       Full Time    Male   \n",
       "61        96668.0  Black or African American       Full Time  Female   \n",
       "63        26125.0  Black or African American       Full Time  Female   \n",
       "69        66614.0  Black or African American       Full Time    Male   \n",
       "73        55939.0  Black or African American       Full Time  Female   \n",
       "74        38459.0  Black or African American       Full Time    Male   \n",
       "79        30347.0  Black or African American       Full Time  Female   \n",
       "80        50249.0  Black or African American       Full Time  Female   \n",
       "84        48984.0  Black or African American       Full Time  Female   \n",
       "87        79143.0  Black or African American       Full Time    Male   \n",
       "88        53373.0  Black or African American       Full Time    Male   \n",
       "90        32240.0  Black or African American       Full Time    Male   \n",
       "92        26125.0  Black or African American       Full Time  Female   \n",
       "...           ...                        ...             ...     ...   \n",
       "1929      81239.0  Black or African American       Full Time    Male   \n",
       "1930      26125.0  Black or African American       Full Time  Female   \n",
       "1933      74435.0  Black or African American       Full Time  Female   \n",
       "1934      33550.0  Black or African American       Full Time  Female   \n",
       "1937      26250.0  Black or African American       Full Time  Female   \n",
       "1939      51584.0  Black or African American       Full Time    Male   \n",
       "1940      66614.0  Black or African American       Full Time  Female   \n",
       "1941      41267.0  Black or African American       Full Time    Male   \n",
       "1944      93089.0  Black or African American       Full Time  Female   \n",
       "1947      56489.0  Black or African American       Full Time    Male   \n",
       "1949      47650.0  Black or African American       Full Time  Female   \n",
       "1952      39104.0  Black or African American       Full Time  Female   \n",
       "1955      37461.0  Black or African American       Full Time  Female   \n",
       "1956      37606.0  Black or African American       Full Time    Male   \n",
       "1959      52000.0  Black or African American       Full Time  Female   \n",
       "1960      43264.0  Black or African American       Full Time    Male   \n",
       "1963      51542.0  Black or African American       Full Time  Female   \n",
       "1964      47996.0  Black or African American       Full Time  Female   \n",
       "1967      65000.0  Black or African American       Full Time  Female   \n",
       "1968          NaN  Black or African American       Part Time  Female   \n",
       "1974      66614.0  Black or African American       Full Time    Male   \n",
       "1978      27914.0  Black or African American       Full Time  Female   \n",
       "1981      70181.0  Black or African American       Full Time    Male   \n",
       "1982      55437.0  Black or African American       Full Time    Male   \n",
       "1983      55172.0  Black or African American       Full Time  Female   \n",
       "1985      30222.0  Black or African American       Full Time    Male   \n",
       "1989      37211.0  Black or African American       Full Time    Male   \n",
       "1990      30347.0  Black or African American       Full Time  Female   \n",
       "1994     104455.0  Black or African American       Full Time    Male   \n",
       "1996      66523.0  Black or African American       Full Time    Male   \n",
       "\n",
       "       HIRE_DATE    JOB_DATE  \n",
       "5     1984-11-26  2005-03-26  \n",
       "11    1987-05-22  1999-08-28  \n",
       "12    2015-11-16  2015-11-16  \n",
       "13    1999-10-20  2001-05-19  \n",
       "14    2001-06-04  2015-05-25  \n",
       "15    1995-01-30  2015-02-14  \n",
       "21    2001-03-20  2003-01-04  \n",
       "22    2015-01-05  2015-01-05  \n",
       "24    2010-03-29  2011-03-29  \n",
       "29    2014-01-21  2014-01-21  \n",
       "32    1991-02-11  2016-02-13  \n",
       "35    1982-04-05  1990-11-03  \n",
       "39    2008-09-08  2015-04-11  \n",
       "46    2008-06-30  2013-05-25  \n",
       "47    2007-12-15  2015-11-07  \n",
       "55    2005-05-11  2008-05-17  \n",
       "57    2015-08-31  2015-08-31  \n",
       "59    2013-08-19  2013-08-19  \n",
       "61    1998-04-07  2006-01-28  \n",
       "63    2001-05-21  2001-05-21  \n",
       "69    1991-07-31  2012-02-04  \n",
       "73    2011-12-19  2013-11-23  \n",
       "74    2004-09-07  2005-07-09  \n",
       "79    1999-09-27  2007-02-27  \n",
       "80    2007-04-30  2012-09-29  \n",
       "84    2000-12-27  2000-12-27  \n",
       "87    2009-09-08  2009-09-08  \n",
       "88    1996-03-04  2005-04-16  \n",
       "90    2006-06-26  2006-06-26  \n",
       "92    1993-10-02  1993-10-02  \n",
       "...          ...         ...  \n",
       "1929  1994-04-11  2011-09-03  \n",
       "1930  2007-08-13  2007-08-13  \n",
       "1933  2004-10-11  2015-05-23  \n",
       "1934  2014-08-29  2014-08-29  \n",
       "1937  2007-09-14  2007-09-14  \n",
       "1939  2015-09-15  2015-09-15  \n",
       "1940  1995-11-06  2008-05-31  \n",
       "1941  2006-07-10  2015-09-12  \n",
       "1944  2005-05-16  2014-08-30  \n",
       "1947  2001-10-16  2004-02-07  \n",
       "1949  2012-04-16  2013-04-16  \n",
       "1952  2005-05-31  2005-05-31  \n",
       "1955  2008-06-02  2008-06-02  \n",
       "1956  2006-01-30  2006-01-30  \n",
       "1959  2007-02-12  2016-02-13  \n",
       "1960  2015-07-13  2015-07-13  \n",
       "1963  2015-11-02  2015-11-02  \n",
       "1964  2009-11-16  2016-01-30  \n",
       "1967  1995-10-30  2016-02-13  \n",
       "1968  2013-08-05  2013-08-05  \n",
       "1974  1993-04-12  2013-10-12  \n",
       "1978  2011-10-14  2014-03-01  \n",
       "1981  1994-08-29  2013-09-04  \n",
       "1982  2004-01-05  2005-01-14  \n",
       "1983  2006-10-16  2006-10-16  \n",
       "1985  2013-06-10  2015-08-01  \n",
       "1989  1984-12-11  2004-09-18  \n",
       "1990  1995-10-14  2010-03-20  \n",
       "1994  1983-02-07  2004-07-08  \n",
       "1996  2003-09-02  2013-10-06  \n",
       "\n",
       "[700 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee[employee['RACE'] == 'Black or African American']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "<span  style=\"color:green; font-size:16px\">Find the females that have a salary over 100,000 OR males with salary under 50,000</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PUBLIC HEALTH DENTIST,DDS</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>100791.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>2015-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>ASSISTANT DIRECTOR (EXECUTIVE LEVEL)</td>\n",
       "      <td>Admn. &amp; Regulatory Affairs</td>\n",
       "      <td>130416.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2002-05-24</td>\n",
       "      <td>2013-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "      <td>Mayor's Office</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>2014-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>110686.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-11-07</td>\n",
       "      <td>2011-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>SENIOR STAFF ANALYST</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>105503.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1991-08-05</td>\n",
       "      <td>2015-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>DEPUTY DIRECTOR (EXECUTIVE LEVEL)</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>150416.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2013-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>150416.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2012-06-11</td>\n",
       "      <td>2013-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>DIVISION MANAGER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>100873.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-10-12</td>\n",
       "      <td>2005-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>126115.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1996-10-30</td>\n",
       "      <td>2004-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>JUDGE OF MUNICIPAL COURTS</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>103756.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2008-11-12</td>\n",
       "      <td>2011-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>ASSISTANT DIRECTOR-PUBLIC WORKS (EXECUTI</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>146141.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-07-20</td>\n",
       "      <td>2014-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>POLICE CAPTAIN</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>104455.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1991-08-05</td>\n",
       "      <td>2011-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "      <td>Library</td>\n",
       "      <td>107763.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-11-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>DEPUTY DIRECTOR-PUBLIC WORKS (EXECUTIVE</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>178331.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1991-02-12</td>\n",
       "      <td>2005-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>BUREAU CHIEF,PUBLIC HEALTH</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>103270.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1985-10-30</td>\n",
       "      <td>2015-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>122220.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>2012-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>DIVISION MANAGER</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>110547.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-01-29</td>\n",
       "      <td>2010-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>JUDGE OF MUNICIPAL COURTS</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>117176.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1999-09-25</td>\n",
       "      <td>2010-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>ASSISTANT DIRECTOR (EXECUTIVE LEVEL)</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>128606.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-02-22</td>\n",
       "      <td>2004-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>117831.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-07-18</td>\n",
       "      <td>2012-07-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                POSITION_TITLE  \\\n",
       "0                  ASSISTANT DIRECTOR (EX LVL)   \n",
       "66                   PUBLIC HEALTH DENTIST,DDS   \n",
       "237       ASSISTANT DIRECTOR (EXECUTIVE LEVEL)   \n",
       "366   DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV   \n",
       "522         DEPUTY ASSISTANT DIRECTOR (EX LVL)   \n",
       "591                       SENIOR STAFF ANALYST   \n",
       "605          DEPUTY DIRECTOR (EXECUTIVE LEVEL)   \n",
       "742          SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "793                           DIVISION MANAGER   \n",
       "815          SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "1055                 JUDGE OF MUNICIPAL COURTS   \n",
       "1067  ASSISTANT DIRECTOR-PUBLIC WORKS (EXECUTI   \n",
       "1118                            POLICE CAPTAIN   \n",
       "1165  DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV   \n",
       "1232   DEPUTY DIRECTOR-PUBLIC WORKS (EXECUTIVE   \n",
       "1437                BUREAU CHIEF,PUBLIC HEALTH   \n",
       "1560         SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "1778                          DIVISION MANAGER   \n",
       "1784                 JUDGE OF MUNICIPAL COURTS   \n",
       "1943      ASSISTANT DIRECTOR (EXECUTIVE LEVEL)   \n",
       "1946         SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "\n",
       "                          DEPARTMENT  BASE_SALARY                       RACE  \\\n",
       "0        Municipal Courts Department     121862.0            Hispanic/Latino   \n",
       "66           Health & Human Services     100791.0                      White   \n",
       "237       Admn. & Regulatory Affairs     130416.0     Asian/Pacific Islander   \n",
       "366                   Mayor's Office     110000.0                      White   \n",
       "522     Houston Airport System (HAS)     110686.0  Black or African American   \n",
       "591   Public Works & Engineering-PWE     105503.0                      White   \n",
       "605     Houston Airport System (HAS)     150416.0  Black or African American   \n",
       "742                 Legal Department     150416.0                      White   \n",
       "793     Houston Airport System (HAS)     100873.0                      White   \n",
       "815                 Legal Department     126115.0            Hispanic/Latino   \n",
       "1055     Municipal Courts Department     103756.0                      White   \n",
       "1067  Public Works & Engineering-PWE     146141.0                      White   \n",
       "1118   Houston Police Department-HPD     104455.0                      White   \n",
       "1165                         Library     107763.0  Black or African American   \n",
       "1232  Public Works & Engineering-PWE     178331.0                      White   \n",
       "1437         Health & Human Services     103270.0  Black or African American   \n",
       "1560                Legal Department     122220.0                      White   \n",
       "1778           Human Resources Dept.     110547.0     Asian/Pacific Islander   \n",
       "1784     Municipal Courts Department     117176.0                      White   \n",
       "1943    Houston Airport System (HAS)     128606.0                      White   \n",
       "1946                Legal Department     117831.0     Asian/Pacific Islander   \n",
       "\n",
       "     EMPLOYMENT_TYPE  GENDER   HIRE_DATE    JOB_DATE  \n",
       "0          Full Time  Female  2006-06-12  2012-10-13  \n",
       "66         Full Time  Female  2015-12-28  2015-12-28  \n",
       "237        Full Time  Female  2002-05-24  2013-07-20  \n",
       "366        Full Time  Female  2014-05-13  2014-05-13  \n",
       "522        Full Time  Female  2011-11-07  2011-11-07  \n",
       "591        Full Time  Female  1991-08-05  2015-05-23  \n",
       "605        Full Time  Female  2013-06-10  2013-06-10  \n",
       "742        Full Time  Female  2012-06-11  2013-07-06  \n",
       "793        Full Time  Female  2005-10-12  2005-10-12  \n",
       "815        Full Time  Female  1996-10-30  2004-10-02  \n",
       "1055       Full Time  Female  2008-11-12  2011-04-16  \n",
       "1067       Full Time  Female  1998-07-20  2014-12-20  \n",
       "1118       Full Time  Female  1991-08-05  2011-10-05  \n",
       "1165       Full Time  Female  1993-11-16  2014-03-15  \n",
       "1232       Full Time  Female  1991-02-12  2005-05-14  \n",
       "1437       Full Time  Female  1985-10-30  2015-12-05  \n",
       "1560       Full Time  Female  2005-09-12  2012-07-21  \n",
       "1778       Full Time  Female  2000-01-29  2010-12-25  \n",
       "1784       Full Time  Female  1999-09-25  2010-11-13  \n",
       "1943       Full Time  Female  1993-02-22  2004-09-04  \n",
       "1946       Full Time  Female  2005-07-18  2012-07-21  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee[(employee['GENDER'] == 'Female') & (employee['BASE_SALARY'] > 100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "<span  style=\"color:green; font-size:16px\">Find the females in the following departments with salary over 60,000 (Parks & Recreation, Solid Waste Management, Fleet Management Department, Library)  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SOLID WASTE SUPERVISOR</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>61428.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-09-18</td>\n",
       "      <td>2004-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>STAFF ANALYST</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>75041.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-10-21</td>\n",
       "      <td>2015-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>ADMINISTRATIVE COORDINATOR</td>\n",
       "      <td>Library</td>\n",
       "      <td>79302.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2003-12-22</td>\n",
       "      <td>2005-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ADMINISTRATIVE SUPERVISOR</td>\n",
       "      <td>Library</td>\n",
       "      <td>60632.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-05-10</td>\n",
       "      <td>2014-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>ASSISTANT DIRECTOR (EXECUTIVE LEVEL)</td>\n",
       "      <td>Fleet Management Department</td>\n",
       "      <td>125884.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-08-24</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>LIBRARIAN III</td>\n",
       "      <td>Library</td>\n",
       "      <td>61454.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-11-02</td>\n",
       "      <td>2002-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "      <td>Library</td>\n",
       "      <td>107763.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-11-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>SUPERINTENDENT</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>72280.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-03-21</td>\n",
       "      <td>2011-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>ADMINISTRATION MANAGER</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>77966.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-11-12</td>\n",
       "      <td>2011-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>DIVISION MANAGER</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>85055.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1997-06-10</td>\n",
       "      <td>2013-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>SENIOR STAFF ANALYST (EXECUTIVE LEVEL)</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>83916.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1999-07-26</td>\n",
       "      <td>2013-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXE LEV)</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>110005.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2005-10-03</td>\n",
       "      <td>2011-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>WEB DESIGNER</td>\n",
       "      <td>Library</td>\n",
       "      <td>60840.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-06-23</td>\n",
       "      <td>2006-06-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                POSITION_TITLE                   DEPARTMENT  \\\n",
       "124                     SOLID WASTE SUPERVISOR       Solid Waste Management   \n",
       "249                              STAFF ANALYST       Solid Waste Management   \n",
       "412                 ADMINISTRATIVE COORDINATOR                      Library   \n",
       "476                  ADMINISTRATIVE SUPERVISOR                      Library   \n",
       "561       ASSISTANT DIRECTOR (EXECUTIVE LEVEL)  Fleet Management Department   \n",
       "892                              LIBRARIAN III                      Library   \n",
       "1165  DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV                      Library   \n",
       "1197                            SUPERINTENDENT           Parks & Recreation   \n",
       "1256                    ADMINISTRATION MANAGER       Solid Waste Management   \n",
       "1469                          DIVISION MANAGER           Parks & Recreation   \n",
       "1484    SENIOR STAFF ANALYST (EXECUTIVE LEVEL)           Parks & Recreation   \n",
       "1559       DEPUTY ASSISTANT DIRECTOR (EXE LEV)       Solid Waste Management   \n",
       "1666                              WEB DESIGNER                      Library   \n",
       "\n",
       "      BASE_SALARY                       RACE EMPLOYMENT_TYPE  GENDER  \\\n",
       "124       61428.0  Black or African American       Full Time    Male   \n",
       "249       75041.0            Hispanic/Latino       Full Time  Female   \n",
       "412       79302.0            Hispanic/Latino       Full Time  Female   \n",
       "476       60632.0  Black or African American       Full Time  Female   \n",
       "561      125884.0                      White       Full Time    Male   \n",
       "892       61454.0                      White       Full Time  Female   \n",
       "1165     107763.0  Black or African American       Full Time  Female   \n",
       "1197      72280.0            Hispanic/Latino       Full Time    Male   \n",
       "1256      77966.0                      White       Full Time    Male   \n",
       "1469      85055.0                      White       Full Time    Male   \n",
       "1484      83916.0            Hispanic/Latino       Full Time  Female   \n",
       "1559     110005.0  Black or African American       Full Time    Male   \n",
       "1666      60840.0  Black or African American       Full Time    Male   \n",
       "\n",
       "       HIRE_DATE    JOB_DATE  \n",
       "124   1990-09-18  2004-12-11  \n",
       "249   1992-10-21  2015-07-18  \n",
       "412   2003-12-22  2005-04-02  \n",
       "476   1993-05-10  2014-11-08  \n",
       "561   2009-08-24  2016-02-13  \n",
       "892   1998-11-02  2002-06-15  \n",
       "1165  1993-11-16  2014-03-15  \n",
       "1197  1994-03-21  2011-08-06  \n",
       "1256  1991-11-12  2011-11-12  \n",
       "1469  1997-06-10  2013-04-13  \n",
       "1484  1999-07-26  2013-08-31  \n",
       "1559  2005-10-03  2011-10-01  \n",
       "1666  1999-06-23  2006-06-10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee[(employee['BASE_SALARY'] > 60000) & (employee['DEPARTMENT'].isin(['Parks & Recreation', 'Solid Waste Management', 'Fleet Management Department', 'Library']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "<span  style=\"color:green; font-size:16px\">Find all the males with salary over 100,000. Return only the race, gender and salary columns</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>107962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>180416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>165216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>120916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>210588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>110881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>102019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>141948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>100228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>104455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>125884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>130585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>120750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>163228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>199596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>186192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>126343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>105354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>120799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>142006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>102297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>103686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>124861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>104389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>113930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>140416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>110005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>104455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>103776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>103427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>104455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>114671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Male</td>\n",
       "      <td>115416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>124115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>104455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RACE GENDER  BASE_SALARY\n",
       "8                         White   Male     107962.0\n",
       "11    Black or African American   Male     180416.0\n",
       "43              Hispanic/Latino   Male     165216.0\n",
       "169                       White   Male     120916.0\n",
       "178                       White   Male     210588.0\n",
       "186                       White   Male     110881.0\n",
       "217      Asian/Pacific Islander   Male     102019.0\n",
       "297                       White   Male     141948.0\n",
       "299   Black or African American   Male     100228.0\n",
       "416                       White   Male     104455.0\n",
       "561                       White   Male     125884.0\n",
       "593   Black or African American   Male     275000.0\n",
       "708   Black or African American   Male     130585.0\n",
       "713                       White   Male     120750.0\n",
       "719      Asian/Pacific Islander   Male     163228.0\n",
       "767                       White   Male     199596.0\n",
       "855   Black or African American   Male     186192.0\n",
       "867                       White   Male     126343.0\n",
       "899                       White   Male     105354.0\n",
       "1030                      White   Male     120799.0\n",
       "1072            Hispanic/Latino   Male     142006.0\n",
       "1090     Asian/Pacific Islander   Male     102297.0\n",
       "1100                      White   Male     103686.0\n",
       "1166     Asian/Pacific Islander   Male     124861.0\n",
       "1234  Black or African American   Male     104389.0\n",
       "1372     Asian/Pacific Islander   Male     113930.0\n",
       "1494                      White   Male     140416.0\n",
       "1559  Black or African American   Male     110005.0\n",
       "1660                      White   Male     104455.0\n",
       "1679                      White   Male     103776.0\n",
       "1724                      White   Male     103427.0\n",
       "1817                      White   Male     104455.0\n",
       "1832     Asian/Pacific Islander   Male     114671.0\n",
       "1873            Hispanic/Latino   Male     115416.0\n",
       "1988                      White   Male     124115.0\n",
       "1994  Black or African American   Male     104455.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.loc[(employee['GENDER'] == 'Male') & (employee['BASE_SALARY'] > 100000),['RACE','GENDER','BASE_SALARY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "<span  style=\"color:green; font-size:16px\">Select all salaries as a Series in a separate variable. From this series select all salaries under 25,000</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIBRARY ASSISTANT</td>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>2010-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "      <td>1991-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRICIAN</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-06-19</td>\n",
       "      <td>1994-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-11-26</td>\n",
       "      <td>2005-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENGINEER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2012-03-26</td>\n",
       "      <td>2012-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>2013-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>107962.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-11-15</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIRPORT OPERATIONS COORDINATOR</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>44616.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>2016-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>52644.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>2008-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHIEF PHYSICIAN,MD</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-05-22</td>\n",
       "      <td>1999-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>2015-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PUBLIC HEALTH INVESTIGATOR SUPERVISOR</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>55269.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-10-20</td>\n",
       "      <td>2001-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-06-04</td>\n",
       "      <td>2015-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-06-19</td>\n",
       "      <td>2007-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAINTENANCE MECHANIC III</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>40581.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-12-29</td>\n",
       "      <td>2008-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-02-17</td>\n",
       "      <td>2007-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SENIOR INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>61506.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>2015-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>57815.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-20</td>\n",
       "      <td>2003-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43264.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-03-15</td>\n",
       "      <td>2005-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>52514.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>2011-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>61643.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-08-23</td>\n",
       "      <td>2012-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-01-12</td>\n",
       "      <td>2004-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1978-03-13</td>\n",
       "      <td>1994-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UTILITY WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>29557.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>62540.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-03-15</td>\n",
       "      <td>2010-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FIRE FIGHTER TRAINEE</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>28024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>2016-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SENIOR ACCOUNTANT</td>\n",
       "      <td>Finance</td>\n",
       "      <td>46963.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-02-11</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>MANAGEMENT ANALYST IV</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>65338.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-10-28</td>\n",
       "      <td>2014-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>STAFF ANALYST</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-06-11</td>\n",
       "      <td>2002-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-10-14</td>\n",
       "      <td>2014-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-12-10</td>\n",
       "      <td>2001-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>SENIOR PROJECT MANAGER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>77325.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-08-04</td>\n",
       "      <td>2012-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-04-12</td>\n",
       "      <td>2013-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>GROUND TRANSPORTATION REPRESENTATIVE</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>32157.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>2000-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>SENIOR SIDELOADER OPERATOR</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>34466.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>2016-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2014-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>POLICE SERVICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>27914.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-10-14</td>\n",
       "      <td>2014-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2006-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>70181.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-08-29</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>2005-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Admn. &amp; Regulatory Affairs</td>\n",
       "      <td>55172.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-10-16</td>\n",
       "      <td>2006-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>61921.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2006-09-11</td>\n",
       "      <td>2014-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>TRUCK DRIVER</td>\n",
       "      <td>Fleet Management Department</td>\n",
       "      <td>30222.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>2010-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>124115.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>2013-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>EQUIPMENT WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-12-11</td>\n",
       "      <td>2004-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>BUILDING MAINTENANCE SUPERVISOR</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-14</td>\n",
       "      <td>2010-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>MOBILITY SERVICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>44429.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>2007-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>SECURITY OFFICER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>29286.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2011-12-12</td>\n",
       "      <td>2011-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-05-03</td>\n",
       "      <td>2011-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>POLICE CAPTAIN</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>104455.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-02-07</td>\n",
       "      <td>2004-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2015-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>COMMUNICATIONS CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>66523.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2003-09-02</td>\n",
       "      <td>2013-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>2015-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>55461.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>2011-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>51194.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                POSITION_TITLE  \\\n",
       "0                  ASSISTANT DIRECTOR (EX LVL)   \n",
       "1                            LIBRARY ASSISTANT   \n",
       "2                               POLICE OFFICER   \n",
       "3                            ENGINEER/OPERATOR   \n",
       "4                                  ELECTRICIAN   \n",
       "5                        SENIOR POLICE OFFICER   \n",
       "6                                     ENGINEER   \n",
       "7                                    CARPENTER   \n",
       "8     DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV   \n",
       "9               AIRPORT OPERATIONS COORDINATOR   \n",
       "10                                FIRE FIGHTER   \n",
       "11                          CHIEF PHYSICIAN,MD   \n",
       "12           CUSTOMER SERVICE REPRESENTATIVE I   \n",
       "13       PUBLIC HEALTH INVESTIGATOR SUPERVISOR   \n",
       "14                             POLICE SERGEANT   \n",
       "17                             POLICE SERGEANT   \n",
       "18                    MAINTENANCE MECHANIC III   \n",
       "19                       SENIOR POLICE OFFICER   \n",
       "20                            SENIOR INSPECTOR   \n",
       "21                                FIRE FIGHTER   \n",
       "22                                   INSPECTOR   \n",
       "23                                FIRE FIGHTER   \n",
       "24                              POLICE OFFICER   \n",
       "25                       SENIOR POLICE OFFICER   \n",
       "27                       SENIOR POLICE OFFICER   \n",
       "28                             POLICE SERGEANT   \n",
       "29                              UTILITY WORKER   \n",
       "30                           ENGINEER/OPERATOR   \n",
       "31                        FIRE FIGHTER TRAINEE   \n",
       "32                           SENIOR ACCOUNTANT   \n",
       "...                                        ...   \n",
       "1966                     MANAGEMENT ANALYST IV   \n",
       "1967                             STAFF ANALYST   \n",
       "1970                     SENIOR POLICE OFFICER   \n",
       "1971                            POLICE OFFICER   \n",
       "1972                         ENGINEER/OPERATOR   \n",
       "1973                    SENIOR PROJECT MANAGER   \n",
       "1974                     SENIOR POLICE OFFICER   \n",
       "1975      GROUND TRANSPORTATION REPRESENTATIVE   \n",
       "1976                SENIOR SIDELOADER OPERATOR   \n",
       "1977                            POLICE OFFICER   \n",
       "1978                    POLICE SERVICE OFFICER   \n",
       "1979                     SENIOR POLICE OFFICER   \n",
       "1981                                   CAPTAIN   \n",
       "1982                              FIRE FIGHTER   \n",
       "1983                 ADMINISTRATIVE SPECIALIST   \n",
       "1984                         ENGINEER/OPERATOR   \n",
       "1985                              TRUCK DRIVER   \n",
       "1986                           POLICE SERGEANT   \n",
       "1988         SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "1989                          EQUIPMENT WORKER   \n",
       "1990           BUILDING MAINTENANCE SUPERVISOR   \n",
       "1991                  MOBILITY SERVICE OFFICER   \n",
       "1992                          SECURITY OFFICER   \n",
       "1993                           POLICE SERGEANT   \n",
       "1994                            POLICE CAPTAIN   \n",
       "1995                            POLICE OFFICER   \n",
       "1996                    COMMUNICATIONS CAPTAIN   \n",
       "1997                            POLICE OFFICER   \n",
       "1998                            POLICE OFFICER   \n",
       "1999                              FIRE FIGHTER   \n",
       "\n",
       "                          DEPARTMENT  BASE_SALARY                       RACE  \\\n",
       "0        Municipal Courts Department     121862.0            Hispanic/Latino   \n",
       "1                            Library      26125.0            Hispanic/Latino   \n",
       "2      Houston Police Department-HPD      45279.0                      White   \n",
       "3      Houston Fire Department (HFD)      63166.0                      White   \n",
       "4        General Services Department      56347.0                      White   \n",
       "5      Houston Police Department-HPD      66614.0  Black or African American   \n",
       "6     Public Works & Engineering-PWE      71680.0     Asian/Pacific Islander   \n",
       "7       Houston Airport System (HAS)      42390.0                      White   \n",
       "8     Public Works & Engineering-PWE     107962.0                      White   \n",
       "9       Houston Airport System (HAS)      44616.0                        NaN   \n",
       "10     Houston Fire Department (HFD)      52644.0            Hispanic/Latino   \n",
       "11           Health & Human Services     180416.0  Black or African American   \n",
       "12    Public Works & Engineering-PWE      30347.0  Black or African American   \n",
       "13           Health & Human Services      55269.0  Black or African American   \n",
       "14     Houston Police Department-HPD      77076.0  Black or African American   \n",
       "17     Houston Police Department-HPD      81239.0                      White   \n",
       "18       General Services Department      40581.0            Hispanic/Latino   \n",
       "19     Houston Police Department-HPD      66614.0                      White   \n",
       "20    Public Works & Engineering-PWE      61506.0                      White   \n",
       "21     Houston Fire Department (HFD)      57815.0  Black or African American   \n",
       "22    Public Works & Engineering-PWE      43264.0  Black or African American   \n",
       "23     Houston Fire Department (HFD)      55437.0                      White   \n",
       "24     Houston Police Department-HPD      52514.0  Black or African American   \n",
       "25     Houston Police Department-HPD      61643.0                      White   \n",
       "27     Houston Police Department-HPD      66614.0                      White   \n",
       "28     Houston Police Department-HPD      81239.0                      White   \n",
       "29    Public Works & Engineering-PWE      29557.0  Black or African American   \n",
       "30     Houston Fire Department (HFD)      62540.0                      White   \n",
       "31     Houston Fire Department (HFD)      28024.0                        NaN   \n",
       "32                           Finance      46963.0  Black or African American   \n",
       "...                              ...          ...                        ...   \n",
       "1966         Health & Human Services      65338.0                      White   \n",
       "1967           Human Resources Dept.      65000.0  Black or African American   \n",
       "1970   Houston Police Department-HPD      66614.0            Hispanic/Latino   \n",
       "1971   Houston Police Department-HPD      45279.0            Hispanic/Latino   \n",
       "1972   Houston Fire Department (HFD)      63166.0                      White   \n",
       "1973  Public Works & Engineering-PWE      77325.0                      White   \n",
       "1974   Houston Police Department-HPD      66614.0  Black or African American   \n",
       "1975    Houston Airport System (HAS)      32157.0     Asian/Pacific Islander   \n",
       "1976          Solid Waste Management      34466.0            Hispanic/Latino   \n",
       "1977   Houston Police Department-HPD      45279.0                      White   \n",
       "1978   Houston Police Department-HPD      27914.0  Black or African American   \n",
       "1979   Houston Police Department-HPD      66614.0            Hispanic/Latino   \n",
       "1981   Houston Fire Department (HFD)      70181.0  Black or African American   \n",
       "1982   Houston Fire Department (HFD)      55437.0  Black or African American   \n",
       "1983      Admn. & Regulatory Affairs      55172.0  Black or African American   \n",
       "1984   Houston Fire Department (HFD)      61921.0                      White   \n",
       "1985     Fleet Management Department      30222.0  Black or African American   \n",
       "1986   Houston Police Department-HPD      77076.0                      White   \n",
       "1988                Legal Department     124115.0                      White   \n",
       "1989  Public Works & Engineering-PWE      37211.0  Black or African American   \n",
       "1990              Parks & Recreation      30347.0  Black or African American   \n",
       "1991   Houston Police Department-HPD      44429.0            Hispanic/Latino   \n",
       "1992    Houston Airport System (HAS)      29286.0            Hispanic/Latino   \n",
       "1993   Houston Police Department-HPD      81239.0                      White   \n",
       "1994   Houston Police Department-HPD     104455.0  Black or African American   \n",
       "1995   Houston Police Department-HPD      43443.0                      White   \n",
       "1996   Houston Fire Department (HFD)      66523.0  Black or African American   \n",
       "1997   Houston Police Department-HPD      43443.0                      White   \n",
       "1998   Houston Police Department-HPD      55461.0     Asian/Pacific Islander   \n",
       "1999   Houston Fire Department (HFD)      51194.0            Hispanic/Latino   \n",
       "\n",
       "     EMPLOYMENT_TYPE  GENDER   HIRE_DATE    JOB_DATE  \n",
       "0          Full Time  Female  2006-06-12  2012-10-13  \n",
       "1          Full Time  Female  2000-07-19  2010-09-18  \n",
       "2          Full Time    Male  2015-02-03  2015-02-03  \n",
       "3          Full Time    Male  1982-02-08  1991-05-25  \n",
       "4          Full Time    Male  1989-06-19  1994-10-22  \n",
       "5          Full Time    Male  1984-11-26  2005-03-26  \n",
       "6          Full Time    Male  2012-03-26  2012-03-26  \n",
       "7          Full Time    Male  2013-11-04  2013-11-04  \n",
       "8          Full Time    Male  1993-11-15  2013-01-05  \n",
       "9          Full Time    Male  2016-03-14  2016-03-14  \n",
       "10         Full Time    Male  2007-05-21  2008-11-15  \n",
       "11         Full Time    Male  1987-05-22  1999-08-28  \n",
       "12         Full Time    Male  2015-11-16  2015-11-16  \n",
       "13         Full Time    Male  1999-10-20  2001-05-19  \n",
       "14         Full Time    Male  2001-06-04  2015-05-25  \n",
       "17         Full Time    Male  1995-06-19  2007-03-03  \n",
       "18         Full Time    Male  2008-12-29  2008-12-29  \n",
       "19         Full Time    Male  1992-02-17  2007-07-28  \n",
       "20         Full Time    Male  2009-04-06  2015-04-11  \n",
       "21         Full Time    Male  2001-03-20  2003-01-04  \n",
       "22         Full Time    Male  2015-01-05  2015-01-05  \n",
       "23         Full Time    Male  2004-03-15  2005-03-26  \n",
       "24         Full Time    Male  2010-03-29  2011-03-29  \n",
       "25         Full Time    Male  1999-08-23  2012-03-31  \n",
       "27         Full Time    Male  1990-01-12  2004-07-03  \n",
       "28         Full Time    Male  1978-03-13  1994-09-10  \n",
       "29         Full Time    Male  2014-01-21  2014-01-21  \n",
       "30         Full Time    Male  2004-03-15  2010-08-11  \n",
       "31         Full Time    Male  2016-03-14  2016-03-14  \n",
       "32         Full Time    Male  1991-02-11  2016-02-13  \n",
       "...              ...     ...         ...         ...  \n",
       "1966       Full Time  Female  2013-10-28  2014-09-27  \n",
       "1967       Full Time  Female  1995-10-30  2016-02-13  \n",
       "1970       Full Time    Male  1990-06-11  2002-12-07  \n",
       "1971       Full Time  Female  2013-10-14  2014-10-14  \n",
       "1972       Full Time    Male  1990-12-10  2001-04-28  \n",
       "1973       Full Time    Male  2008-08-04  2012-07-07  \n",
       "1974       Full Time    Male  1993-04-12  2013-10-12  \n",
       "1975       Full Time  Female  1993-05-13  2000-07-15  \n",
       "1976       Full Time  Female  2015-07-20  2016-01-30  \n",
       "1977       Full Time    Male  2013-06-10  2014-06-10  \n",
       "1978       Full Time  Female  2011-10-14  2014-03-01  \n",
       "1979       Full Time    Male  1993-11-08  2006-06-03  \n",
       "1981       Full Time    Male  1994-08-29  2013-09-04  \n",
       "1982       Full Time    Male  2004-01-05  2005-01-14  \n",
       "1983       Full Time  Female  2006-10-16  2006-10-16  \n",
       "1984       Full Time    Male  2006-09-11  2014-06-11  \n",
       "1985       Full Time    Male  2013-06-10  2015-08-01  \n",
       "1986       Full Time    Male  2001-12-03  2010-12-10  \n",
       "1988       Full Time    Male  2013-01-23  2013-03-02  \n",
       "1989       Full Time    Male  1984-12-11  2004-09-18  \n",
       "1990       Full Time  Female  1995-10-14  2010-03-20  \n",
       "1991       Full Time  Female  2005-09-12  2007-06-02  \n",
       "1992       Full Time    Male  2011-12-12  2011-12-12  \n",
       "1993       Full Time    Male  1982-05-03  2011-09-03  \n",
       "1994       Full Time    Male  1983-02-07  2004-07-08  \n",
       "1995       Full Time    Male  2014-06-09  2015-06-09  \n",
       "1996       Full Time    Male  2003-09-02  2013-10-06  \n",
       "1997       Full Time    Male  2014-10-13  2015-10-13  \n",
       "1998       Full Time    Male  2009-01-20  2011-07-02  \n",
       "1999       Full Time    Male  2009-01-12  2010-07-12  \n",
       "\n",
       "[1885 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie = employee['BASE_SALARY']\n",
    "employee[serie >= 25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "<span  style=\"color:green; font-size:16px\">Get the same exact result as exercise 11, but make your selection from the employee DataFrame. Use only a single line of code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITION_TITLE</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>BASE_SALARY</th>\n",
       "      <th>RACE</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HIRE_DATE</th>\n",
       "      <th>JOB_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSISTANT DIRECTOR (EX LVL)</td>\n",
       "      <td>Municipal Courts Department</td>\n",
       "      <td>121862.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-06-12</td>\n",
       "      <td>2012-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIBRARY ASSISTANT</td>\n",
       "      <td>Library</td>\n",
       "      <td>26125.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2000-07-19</td>\n",
       "      <td>2010-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-02-08</td>\n",
       "      <td>1991-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELECTRICIAN</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>56347.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989-06-19</td>\n",
       "      <td>1994-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-11-26</td>\n",
       "      <td>2005-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENGINEER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>71680.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2012-03-26</td>\n",
       "      <td>2012-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-11-04</td>\n",
       "      <td>2013-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>107962.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-11-15</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIRPORT OPERATIONS COORDINATOR</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>44616.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>2016-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>52644.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2007-05-21</td>\n",
       "      <td>2008-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHIEF PHYSICIAN,MD</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>180416.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987-05-22</td>\n",
       "      <td>1999-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE I</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>2015-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PUBLIC HEALTH INVESTIGATOR SUPERVISOR</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>55269.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-10-20</td>\n",
       "      <td>2001-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-06-04</td>\n",
       "      <td>2015-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-06-19</td>\n",
       "      <td>2007-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAINTENANCE MECHANIC III</td>\n",
       "      <td>General Services Department</td>\n",
       "      <td>40581.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-12-29</td>\n",
       "      <td>2008-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-02-17</td>\n",
       "      <td>2007-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SENIOR INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>61506.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>2015-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>57815.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-03-20</td>\n",
       "      <td>2003-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>INSPECTOR</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>43264.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-03-15</td>\n",
       "      <td>2005-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>52514.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2010-03-29</td>\n",
       "      <td>2011-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>61643.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-08-23</td>\n",
       "      <td>2012-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-01-12</td>\n",
       "      <td>2004-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1978-03-13</td>\n",
       "      <td>1994-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UTILITY WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>29557.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>2014-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>62540.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-03-15</td>\n",
       "      <td>2010-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FIRE FIGHTER TRAINEE</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>28024.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2016-03-14</td>\n",
       "      <td>2016-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SENIOR ACCOUNTANT</td>\n",
       "      <td>Finance</td>\n",
       "      <td>46963.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-02-11</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>MANAGEMENT ANALYST IV</td>\n",
       "      <td>Health &amp; Human Services</td>\n",
       "      <td>65338.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-10-28</td>\n",
       "      <td>2014-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>STAFF ANALYST</td>\n",
       "      <td>Human Resources Dept.</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>2016-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-06-11</td>\n",
       "      <td>2002-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2013-10-14</td>\n",
       "      <td>2014-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>63166.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1990-12-10</td>\n",
       "      <td>2001-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>SENIOR PROJECT MANAGER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>77325.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2008-08-04</td>\n",
       "      <td>2012-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-04-12</td>\n",
       "      <td>2013-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>GROUND TRANSPORTATION REPRESENTATIVE</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>32157.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>2000-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>SENIOR SIDELOADER OPERATOR</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>34466.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>2016-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>45279.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2014-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>POLICE SERVICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>27914.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2011-10-14</td>\n",
       "      <td>2014-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>SENIOR POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>66614.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2006-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>70181.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994-08-29</td>\n",
       "      <td>2013-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>55437.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2004-01-05</td>\n",
       "      <td>2005-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>Admn. &amp; Regulatory Affairs</td>\n",
       "      <td>55172.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2006-10-16</td>\n",
       "      <td>2006-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>ENGINEER/OPERATOR</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>61921.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2006-09-11</td>\n",
       "      <td>2014-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>TRUCK DRIVER</td>\n",
       "      <td>Fleet Management Department</td>\n",
       "      <td>30222.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>2015-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>77076.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>2010-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>SENIOR ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>Legal Department</td>\n",
       "      <td>124115.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>2013-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>EQUIPMENT WORKER</td>\n",
       "      <td>Public Works &amp; Engineering-PWE</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984-12-11</td>\n",
       "      <td>2004-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>BUILDING MAINTENANCE SUPERVISOR</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>30347.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>1995-10-14</td>\n",
       "      <td>2010-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>MOBILITY SERVICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>44429.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Female</td>\n",
       "      <td>2005-09-12</td>\n",
       "      <td>2007-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>SECURITY OFFICER</td>\n",
       "      <td>Houston Airport System (HAS)</td>\n",
       "      <td>29286.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2011-12-12</td>\n",
       "      <td>2011-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>81239.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-05-03</td>\n",
       "      <td>2011-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>POLICE CAPTAIN</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>104455.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983-02-07</td>\n",
       "      <td>2004-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2015-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>COMMUNICATIONS CAPTAIN</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>66523.0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2003-09-02</td>\n",
       "      <td>2013-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>2015-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>Houston Police Department-HPD</td>\n",
       "      <td>55461.0</td>\n",
       "      <td>Asian/Pacific Islander</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>2011-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>FIRE FIGHTER</td>\n",
       "      <td>Houston Fire Department (HFD)</td>\n",
       "      <td>51194.0</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Male</td>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>2010-07-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                POSITION_TITLE  \\\n",
       "0                  ASSISTANT DIRECTOR (EX LVL)   \n",
       "1                            LIBRARY ASSISTANT   \n",
       "2                               POLICE OFFICER   \n",
       "3                            ENGINEER/OPERATOR   \n",
       "4                                  ELECTRICIAN   \n",
       "5                        SENIOR POLICE OFFICER   \n",
       "6                                     ENGINEER   \n",
       "7                                    CARPENTER   \n",
       "8     DEPUTY ASSISTANT DIRECTOR (EXECUTIVE LEV   \n",
       "9               AIRPORT OPERATIONS COORDINATOR   \n",
       "10                                FIRE FIGHTER   \n",
       "11                          CHIEF PHYSICIAN,MD   \n",
       "12           CUSTOMER SERVICE REPRESENTATIVE I   \n",
       "13       PUBLIC HEALTH INVESTIGATOR SUPERVISOR   \n",
       "14                             POLICE SERGEANT   \n",
       "17                             POLICE SERGEANT   \n",
       "18                    MAINTENANCE MECHANIC III   \n",
       "19                       SENIOR POLICE OFFICER   \n",
       "20                            SENIOR INSPECTOR   \n",
       "21                                FIRE FIGHTER   \n",
       "22                                   INSPECTOR   \n",
       "23                                FIRE FIGHTER   \n",
       "24                              POLICE OFFICER   \n",
       "25                       SENIOR POLICE OFFICER   \n",
       "27                       SENIOR POLICE OFFICER   \n",
       "28                             POLICE SERGEANT   \n",
       "29                              UTILITY WORKER   \n",
       "30                           ENGINEER/OPERATOR   \n",
       "31                        FIRE FIGHTER TRAINEE   \n",
       "32                           SENIOR ACCOUNTANT   \n",
       "...                                        ...   \n",
       "1966                     MANAGEMENT ANALYST IV   \n",
       "1967                             STAFF ANALYST   \n",
       "1970                     SENIOR POLICE OFFICER   \n",
       "1971                            POLICE OFFICER   \n",
       "1972                         ENGINEER/OPERATOR   \n",
       "1973                    SENIOR PROJECT MANAGER   \n",
       "1974                     SENIOR POLICE OFFICER   \n",
       "1975      GROUND TRANSPORTATION REPRESENTATIVE   \n",
       "1976                SENIOR SIDELOADER OPERATOR   \n",
       "1977                            POLICE OFFICER   \n",
       "1978                    POLICE SERVICE OFFICER   \n",
       "1979                     SENIOR POLICE OFFICER   \n",
       "1981                                   CAPTAIN   \n",
       "1982                              FIRE FIGHTER   \n",
       "1983                 ADMINISTRATIVE SPECIALIST   \n",
       "1984                         ENGINEER/OPERATOR   \n",
       "1985                              TRUCK DRIVER   \n",
       "1986                           POLICE SERGEANT   \n",
       "1988         SENIOR ASSISTANT CITY ATTORNEY II   \n",
       "1989                          EQUIPMENT WORKER   \n",
       "1990           BUILDING MAINTENANCE SUPERVISOR   \n",
       "1991                  MOBILITY SERVICE OFFICER   \n",
       "1992                          SECURITY OFFICER   \n",
       "1993                           POLICE SERGEANT   \n",
       "1994                            POLICE CAPTAIN   \n",
       "1995                            POLICE OFFICER   \n",
       "1996                    COMMUNICATIONS CAPTAIN   \n",
       "1997                            POLICE OFFICER   \n",
       "1998                            POLICE OFFICER   \n",
       "1999                              FIRE FIGHTER   \n",
       "\n",
       "                          DEPARTMENT  BASE_SALARY                       RACE  \\\n",
       "0        Municipal Courts Department     121862.0            Hispanic/Latino   \n",
       "1                            Library      26125.0            Hispanic/Latino   \n",
       "2      Houston Police Department-HPD      45279.0                      White   \n",
       "3      Houston Fire Department (HFD)      63166.0                      White   \n",
       "4        General Services Department      56347.0                      White   \n",
       "5      Houston Police Department-HPD      66614.0  Black or African American   \n",
       "6     Public Works & Engineering-PWE      71680.0     Asian/Pacific Islander   \n",
       "7       Houston Airport System (HAS)      42390.0                      White   \n",
       "8     Public Works & Engineering-PWE     107962.0                      White   \n",
       "9       Houston Airport System (HAS)      44616.0                        NaN   \n",
       "10     Houston Fire Department (HFD)      52644.0            Hispanic/Latino   \n",
       "11           Health & Human Services     180416.0  Black or African American   \n",
       "12    Public Works & Engineering-PWE      30347.0  Black or African American   \n",
       "13           Health & Human Services      55269.0  Black or African American   \n",
       "14     Houston Police Department-HPD      77076.0  Black or African American   \n",
       "17     Houston Police Department-HPD      81239.0                      White   \n",
       "18       General Services Department      40581.0            Hispanic/Latino   \n",
       "19     Houston Police Department-HPD      66614.0                      White   \n",
       "20    Public Works & Engineering-PWE      61506.0                      White   \n",
       "21     Houston Fire Department (HFD)      57815.0  Black or African American   \n",
       "22    Public Works & Engineering-PWE      43264.0  Black or African American   \n",
       "23     Houston Fire Department (HFD)      55437.0                      White   \n",
       "24     Houston Police Department-HPD      52514.0  Black or African American   \n",
       "25     Houston Police Department-HPD      61643.0                      White   \n",
       "27     Houston Police Department-HPD      66614.0                      White   \n",
       "28     Houston Police Department-HPD      81239.0                      White   \n",
       "29    Public Works & Engineering-PWE      29557.0  Black or African American   \n",
       "30     Houston Fire Department (HFD)      62540.0                      White   \n",
       "31     Houston Fire Department (HFD)      28024.0                        NaN   \n",
       "32                           Finance      46963.0  Black or African American   \n",
       "...                              ...          ...                        ...   \n",
       "1966         Health & Human Services      65338.0                      White   \n",
       "1967           Human Resources Dept.      65000.0  Black or African American   \n",
       "1970   Houston Police Department-HPD      66614.0            Hispanic/Latino   \n",
       "1971   Houston Police Department-HPD      45279.0            Hispanic/Latino   \n",
       "1972   Houston Fire Department (HFD)      63166.0                      White   \n",
       "1973  Public Works & Engineering-PWE      77325.0                      White   \n",
       "1974   Houston Police Department-HPD      66614.0  Black or African American   \n",
       "1975    Houston Airport System (HAS)      32157.0     Asian/Pacific Islander   \n",
       "1976          Solid Waste Management      34466.0            Hispanic/Latino   \n",
       "1977   Houston Police Department-HPD      45279.0                      White   \n",
       "1978   Houston Police Department-HPD      27914.0  Black or African American   \n",
       "1979   Houston Police Department-HPD      66614.0            Hispanic/Latino   \n",
       "1981   Houston Fire Department (HFD)      70181.0  Black or African American   \n",
       "1982   Houston Fire Department (HFD)      55437.0  Black or African American   \n",
       "1983      Admn. & Regulatory Affairs      55172.0  Black or African American   \n",
       "1984   Houston Fire Department (HFD)      61921.0                      White   \n",
       "1985     Fleet Management Department      30222.0  Black or African American   \n",
       "1986   Houston Police Department-HPD      77076.0                      White   \n",
       "1988                Legal Department     124115.0                      White   \n",
       "1989  Public Works & Engineering-PWE      37211.0  Black or African American   \n",
       "1990              Parks & Recreation      30347.0  Black or African American   \n",
       "1991   Houston Police Department-HPD      44429.0            Hispanic/Latino   \n",
       "1992    Houston Airport System (HAS)      29286.0            Hispanic/Latino   \n",
       "1993   Houston Police Department-HPD      81239.0                      White   \n",
       "1994   Houston Police Department-HPD     104455.0  Black or African American   \n",
       "1995   Houston Police Department-HPD      43443.0                      White   \n",
       "1996   Houston Fire Department (HFD)      66523.0  Black or African American   \n",
       "1997   Houston Police Department-HPD      43443.0                      White   \n",
       "1998   Houston Police Department-HPD      55461.0     Asian/Pacific Islander   \n",
       "1999   Houston Fire Department (HFD)      51194.0            Hispanic/Latino   \n",
       "\n",
       "     EMPLOYMENT_TYPE  GENDER   HIRE_DATE    JOB_DATE  \n",
       "0          Full Time  Female  2006-06-12  2012-10-13  \n",
       "1          Full Time  Female  2000-07-19  2010-09-18  \n",
       "2          Full Time    Male  2015-02-03  2015-02-03  \n",
       "3          Full Time    Male  1982-02-08  1991-05-25  \n",
       "4          Full Time    Male  1989-06-19  1994-10-22  \n",
       "5          Full Time    Male  1984-11-26  2005-03-26  \n",
       "6          Full Time    Male  2012-03-26  2012-03-26  \n",
       "7          Full Time    Male  2013-11-04  2013-11-04  \n",
       "8          Full Time    Male  1993-11-15  2013-01-05  \n",
       "9          Full Time    Male  2016-03-14  2016-03-14  \n",
       "10         Full Time    Male  2007-05-21  2008-11-15  \n",
       "11         Full Time    Male  1987-05-22  1999-08-28  \n",
       "12         Full Time    Male  2015-11-16  2015-11-16  \n",
       "13         Full Time    Male  1999-10-20  2001-05-19  \n",
       "14         Full Time    Male  2001-06-04  2015-05-25  \n",
       "17         Full Time    Male  1995-06-19  2007-03-03  \n",
       "18         Full Time    Male  2008-12-29  2008-12-29  \n",
       "19         Full Time    Male  1992-02-17  2007-07-28  \n",
       "20         Full Time    Male  2009-04-06  2015-04-11  \n",
       "21         Full Time    Male  2001-03-20  2003-01-04  \n",
       "22         Full Time    Male  2015-01-05  2015-01-05  \n",
       "23         Full Time    Male  2004-03-15  2005-03-26  \n",
       "24         Full Time    Male  2010-03-29  2011-03-29  \n",
       "25         Full Time    Male  1999-08-23  2012-03-31  \n",
       "27         Full Time    Male  1990-01-12  2004-07-03  \n",
       "28         Full Time    Male  1978-03-13  1994-09-10  \n",
       "29         Full Time    Male  2014-01-21  2014-01-21  \n",
       "30         Full Time    Male  2004-03-15  2010-08-11  \n",
       "31         Full Time    Male  2016-03-14  2016-03-14  \n",
       "32         Full Time    Male  1991-02-11  2016-02-13  \n",
       "...              ...     ...         ...         ...  \n",
       "1966       Full Time  Female  2013-10-28  2014-09-27  \n",
       "1967       Full Time  Female  1995-10-30  2016-02-13  \n",
       "1970       Full Time    Male  1990-06-11  2002-12-07  \n",
       "1971       Full Time  Female  2013-10-14  2014-10-14  \n",
       "1972       Full Time    Male  1990-12-10  2001-04-28  \n",
       "1973       Full Time    Male  2008-08-04  2012-07-07  \n",
       "1974       Full Time    Male  1993-04-12  2013-10-12  \n",
       "1975       Full Time  Female  1993-05-13  2000-07-15  \n",
       "1976       Full Time  Female  2015-07-20  2016-01-30  \n",
       "1977       Full Time    Male  2013-06-10  2014-06-10  \n",
       "1978       Full Time  Female  2011-10-14  2014-03-01  \n",
       "1979       Full Time    Male  1993-11-08  2006-06-03  \n",
       "1981       Full Time    Male  1994-08-29  2013-09-04  \n",
       "1982       Full Time    Male  2004-01-05  2005-01-14  \n",
       "1983       Full Time  Female  2006-10-16  2006-10-16  \n",
       "1984       Full Time    Male  2006-09-11  2014-06-11  \n",
       "1985       Full Time    Male  2013-06-10  2015-08-01  \n",
       "1986       Full Time    Male  2001-12-03  2010-12-10  \n",
       "1988       Full Time    Male  2013-01-23  2013-03-02  \n",
       "1989       Full Time    Male  1984-12-11  2004-09-18  \n",
       "1990       Full Time  Female  1995-10-14  2010-03-20  \n",
       "1991       Full Time  Female  2005-09-12  2007-06-02  \n",
       "1992       Full Time    Male  2011-12-12  2011-12-12  \n",
       "1993       Full Time    Male  1982-05-03  2011-09-03  \n",
       "1994       Full Time    Male  1983-02-07  2004-07-08  \n",
       "1995       Full Time    Male  2014-06-09  2015-06-09  \n",
       "1996       Full Time    Male  2003-09-02  2013-10-06  \n",
       "1997       Full Time    Male  2014-10-13  2015-10-13  \n",
       "1998       Full Time    Male  2009-01-20  2011-07-02  \n",
       "1999       Full Time    Male  2009-01-12  2010-07-12  \n",
       "\n",
       "[1885 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee[employee['BASE_SALARY'] >= 25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
